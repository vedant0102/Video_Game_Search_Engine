<!DOCTYPE html>
<html class="client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-0 vector-feature-client-preferences-disabled vector-feature-client-prefs-pinned-disabled vector-feature-night-mode-disabled skin-theme-clientpref-day vector-toc-available" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<title>3D scanning - Wikipedia</title>
<script>(function(){var className="client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-0 vector-feature-client-preferences-disabled vector-feature-client-prefs-pinned-disabled vector-feature-night-mode-disabled skin-theme-clientpref-day vector-toc-available";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\w+$|[^\w-]+/g,'')+'-clientpref-\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={"wgBreakFrames":false,"wgSeparatorTransformTable":["",""],
"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"9d3b1f90-c517-4b52-be2e-acd3439ca769","wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"3D_scanning","wgTitle":"3D scanning","wgCurRevisionId":1217300576,"wgRevisionId":1217300576,"wgArticleId":2714255,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: numeric names: authors list","Webarchive template wayback links","CS1 Spanish-language sources (es)","All articles with dead external links","Articles with dead external links from April 2023","Articles with permanently dead external links","CS1 German-language sources (de)","CS1 Japanese-language sources (ja)","Articles with short description","Short description is different from Wikidata",
"Articles to be expanded from March 2020","All articles to be expanded","Articles using small message boxes","All articles with unsourced statements","Articles with unsourced statements from April 2019","Articles containing video clips","3D scanners","Geodesy","Surveying","Cartography","Measurement","Computer vision","3D graphics software","3D computer graphics","3D imaging"],"wgPageViewLanguage":"en","wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"3D_scanning","wgRelevantArticleId":2714255,"wgIsProbablyEditable":true,"wgRelevantPageIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"3D_scanner","wgNoticeProject":"wikipedia","wgFlaggedRevsParams":{"tags":{"status":{"levels":1}}},"wgMediaViewerOnClick":true,"wgMediaViewerEnabledByDefault":true,"wgPopupsFlags":6,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":true,"watchlist"
:true,"tagline":false,"nearby":true},"wgWMESchemaEditAttemptStepOversample":false,"wgWMEPageLength":80000,"wgULSCurrentAutonym":"English","wgInternalRedirectTargetUrl":"/wiki/3D_scanning","wgCentralAuthMobileDomain":false,"wgEditSubmitButtonLabelPublish":true,"wgULSPosition":"interlanguage","wgULSisCompactLinksEnabled":false,"wgVector2022LanguageInHeader":true,"wgULSisLanguageSelectorEmpty":false,"wgWikibaseItemId":"Q94701573","wgCheckUserClientHintsHeadersJsApi":["architecture","bitness","brands","fullVersionList","mobile","model","platform","platformVersion"],"GEHomepageSuggestedEditsEnableTopics":true,"wgGETopicsMatchModeEnabled":false,"wgGEStructuredTaskRejectionReasonTextInputEnabled":false,"wgGELevelingUpEnabledForUser":false};RLSTATE={"skins.vector.user.styles":"ready","ext.globalCssJs.user.styles":"ready","site.styles":"ready","user.styles":"ready","skins.vector.user":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready",
"ext.math.styles":"ready","skins.vector.search.codex.styles":"ready","skins.vector.styles":"ready","skins.vector.icons":"ready","jquery.makeCollapsible.styles":"ready","ext.wikimediamessages.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","wikibase.client.init":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["mediawiki.action.view.redirect","ext.cite.ux-enhancements","mediawiki.page.media","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.js","ext.centralNotice.geoIP","ext.centralNotice.startUp","ext.gadget.ReferenceTooltips","ext.gadget.switcher","ext.urlShortener.toolbar","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.echo.centralauth","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.interface","ext.cx.eventlogging.campaigns",
"ext.cx.uls.quick.actions","wikibase.client.vector-2022","ext.checkUser.clientHints","ext.growthExperiments.SuggestedEditSession"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return["user.options@12s5i",function($,jQuery,require,module){mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
}];});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cext.wikimediamessages.styles%7Cjquery.makeCollapsible.styles%7Cskins.vector.icons%2Cstyles%7Cskins.vector.search.codex.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector-2022">
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector-2022"></script>
<meta name="ResourceLoaderDynamicStyles" content="">
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector-2022">
<meta name="generator" content="MediaWiki 1.43.0-wmf.1">
<meta name="referrer" content="origin">
<meta name="referrer" content="origin-when-cross-origin">
<meta name="robots" content="max-image-preview:standard">
<meta name="format-detection" content="telephone=no">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIUscan_handheld_3D_scanner_in_use.jpg/1200px-VIUscan_handheld_3D_scanner_in_use.jpg">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="798">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIUscan_handheld_3D_scanner_in_use.jpg/800px-VIUscan_handheld_3D_scanner_in_use.jpg">
<meta property="og:image:width" content="800">
<meta property="og:image:height" content="532">
<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIUscan_handheld_3D_scanner_in_use.jpg/640px-VIUscan_handheld_3D_scanner_in_use.jpg">
<meta property="og:image:width" content="640">
<meta property="og:image:height" content="425">
<meta name="viewport" content="width=1000">
<meta property="og:title" content="3D scanning - Wikipedia">
<meta property="og:type" content="website">
<link rel="preconnect" href="//upload.wikimedia.org">
<link rel="alternate" media="only screen and (max-width: 720px)" href="//en.m.wikipedia.org/wiki/3D_scanning">
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=3D_scanning&amp;action=edit">
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png">
<link rel="icon" href="/static/favicon/wikipedia.ico">
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)">
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd">
<link rel="canonical" href="https://en.wikipedia.org/wiki/3D_scanning">
<link rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom">
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<link rel="dns-prefetch" href="//login.wikimedia.org">
</head>
<body class="skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-3D_scanning rootpage-3D_scanning skin-vector-2022 action-view"><a class="mw-jump-link" href="#bodyContent">Jump to content</a>
<div class="vector-header-container">
	<header class="vector-header mw-header">
		<div class="vector-header-start">
			<nav class="vector-main-menu-landmark" aria-label="Site" role="navigation">
				
<div id="vector-main-menu-dropdown" class="vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right"  >
	<input type="checkbox" id="vector-main-menu-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-main-menu-dropdown" class="vector-dropdown-checkbox "  aria-label="Main menu"  >
	<label id="vector-main-menu-dropdown-label" for="vector-main-menu-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-menu mw-ui-icon-wikimedia-menu"></span>

<span class="vector-dropdown-label-text">Main menu</span>
	</label>
	<div class="vector-dropdown-content">


				<div id="vector-main-menu-unpinned-container" class="vector-unpinned-container">
		
<div id="vector-main-menu" class="vector-main-menu vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-main-menu-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="main-menu-pinned"
	data-pinnable-element-id="vector-main-menu"
	data-pinned-container-id="vector-main-menu-pinned-container"
	data-unpinned-container-id="vector-main-menu-unpinned-container"
>
	<div class="vector-pinnable-header-label">Main menu</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-main-menu.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-main-menu.unpin">hide</button>
</div>

	
<div id="p-navigation" class="vector-menu mw-portlet mw-portlet-navigation"  >
	<div class="vector-menu-heading">
		Navigation
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-mainpage-description" class="mw-list-item"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z"><span>Main page</span></a></li><li id="n-contents" class="mw-list-item"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia"><span>Contents</span></a></li><li id="n-currentevents" class="mw-list-item"><a href="/wiki/Portal:Current_events" title="Articles related to current events"><span>Current events</span></a></li><li id="n-randompage" class="mw-list-item"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x"><span>Random article</span></a></li><li id="n-aboutsite" class="mw-list-item"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works"><span>About Wikipedia</span></a></li><li id="n-contactpage" class="mw-list-item"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia"><span>Contact us</span></a></li><li id="n-sitesupport" class="mw-list-item"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation"><span>Donate</span></a></li>
		</ul>
		
	</div>
</div>

	
	
<div id="p-interaction" class="vector-menu mw-portlet mw-portlet-interaction"  >
	<div class="vector-menu-heading">
		Contribute
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="n-help" class="mw-list-item"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia"><span>Help</span></a></li><li id="n-introduction" class="mw-list-item"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia"><span>Learn to edit</span></a></li><li id="n-portal" class="mw-list-item"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors"><span>Community portal</span></a></li><li id="n-recentchanges" class="mw-list-item"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r"><span>Recent changes</span></a></li><li id="n-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_upload_wizard" title="Add images or other media for use on Wikipedia"><span>Upload file</span></a></li>
		</ul>
		
	</div>
</div>

</div>

				</div>

	</div>
</div>

		</nav>
			
<a href="/wiki/Main_Page" class="mw-logo">
	<img class="mw-logo-icon" src="/static/images/icons/wikipedia.png" alt="" aria-hidden="true" height="50" width="50">
	<span class="mw-logo-container">
		<img class="mw-logo-wordmark" alt="Wikipedia" src="/static/images/mobile/copyright/wikipedia-wordmark-en.svg" style="width: 7.5em; height: 1.125em;">
		<img class="mw-logo-tagline" alt="The Free Encyclopedia" src="/static/images/mobile/copyright/wikipedia-tagline-en.svg" width="117" height="13" style="width: 7.3125em; height: 0.8125em;">
	</span>
</a>

		</div>
		<div class="vector-header-end">
			
<div id="p-search" role="search" class="vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box">
	<a href="/wiki/Special:Search" class="cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only search-toggle" id="" title="Search Wikipedia [f]" accesskey="f"><span class="vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search"></span>

<span>Search</span>
	</a>
	<div class="vector-typeahead-search-container">
		<div class="cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width">
			<form action="/w/index.php" id="searchform" class="cdx-search-input cdx-search-input--has-end-button">
				<div id="simpleSearch" class="cdx-search-input__input-wrapper"  data-search-loc="header-moved">
					<div class="cdx-text-input cdx-text-input--has-start-icon">
						<input
							class="cdx-text-input__input"
							 type="search" name="search" placeholder="Search Wikipedia" aria-label="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [f]" accesskey="f" id="searchInput"
							>
						<span class="cdx-text-input__icon cdx-text-input__start-icon"></span>
					</div>
					<input type="hidden" name="title" value="Special:Search">
				</div>
				<button class="cdx-button cdx-search-input__end-button">Search</button>
			</form>
		</div>
	</div>
</div>

			<nav class="vector-user-links vector-user-links-wide" aria-label="Personal tools" role="navigation" >
	<div class="vector-user-links-main">
	
<div id="p-vector-user-menu-preferences" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-userpage" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	<nav class="vector-client-prefs-landmark" aria-label="Appearance">
		
		
	</nav>
	
<div id="p-vector-user-menu-notifications" class="vector-menu mw-portlet emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

	
<div id="p-vector-user-menu-overflow" class="vector-menu mw-portlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			<li id="pt-createaccount-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="/w/index.php?title=Special:CreateAccount&amp;returnto=3D+scanning" title="You are encouraged to create an account and log in; however, it is not mandatory" class=""><span>Create account</span></a>
</li>
<li id="pt-login-2" class="user-links-collapsible-item mw-list-item user-links-collapsible-item"><a data-mw="interface" href="/w/index.php?title=Special:UserLogin&amp;returnto=3D+scanning" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o" class=""><span>Log in</span></a>
</li>

			
		</ul>
		
	</div>
</div>

	</div>
	
<div id="vector-user-links-dropdown" class="vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out"  title="Log in and more options" >
	<input type="checkbox" id="vector-user-links-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-user-links-dropdown" class="vector-dropdown-checkbox "  aria-label="Personal tools"  >
	<label id="vector-user-links-dropdown-label" for="vector-user-links-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-ellipsis mw-ui-icon-wikimedia-ellipsis"></span>

<span class="vector-dropdown-label-text">Personal tools</span>
	</label>
	<div class="vector-dropdown-content">


		
<div id="p-personal" class="vector-menu mw-portlet mw-portlet-personal user-links-collapsible-item"  title="User menu" >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-createaccount" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=3D+scanning" title="You are encouraged to create an account and log in; however, it is not mandatory"><span class="vector-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd"></span> <span>Create account</span></a></li><li id="pt-login" class="user-links-collapsible-item mw-list-item"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=3D+scanning" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o"><span class="vector-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn"></span> <span>Log in</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-user-menu-anon-editor" class="vector-menu mw-portlet mw-portlet-user-menu-anon-editor"  >
	<div class="vector-menu-heading">
		Pages for logged out editors <a href="/wiki/Help:Introduction" aria-label="Learn more about editing"><span>learn more</span></a>
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="pt-anoncontribs" class="mw-list-item"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y"><span>Contributions</span></a></li><li id="pt-anontalk" class="mw-list-item"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

	
	</div>
</div>

</nav>

		</div>
	</header>
</div>
<div class="mw-page-container">
	<div class="mw-page-container-inner">
		<div class="vector-sitenotice-container">
			<div id="siteNotice"><!-- CentralNotice --></div>
		</div>
		<div class="vector-column-start">
			<div class="vector-main-menu-container">
		<div id="mw-navigation">
			<nav id="mw-panel" class="vector-main-menu-landmark" aria-label="Site" role="navigation">
				<div id="vector-main-menu-pinned-container" class="vector-pinned-container">
				
				</div>
		</nav>
		</div>
	</div>
	<div class="vector-sticky-pinned-container">
				<nav id="mw-panel-toc" role="navigation" aria-label="Contents" data-event-name="ui.sidebar-toc" class="mw-table-of-contents-container vector-toc-landmark">
					<div id="vector-toc-pinned-container" class="vector-pinned-container">
					<div id="vector-toc" class="vector-toc vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned"
	data-feature-name="toc-pinned"
	data-pinnable-element-id="vector-toc"
	
	
>
	<h2 class="vector-pinnable-header-label">Contents</h2>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-toc.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-toc.unpin">hide</button>
</div>


	<ul class="vector-toc-contents" id="mw-panel-toc-list">
		<li id="toc-mw-content-text"
			class="vector-toc-list-item vector-toc-level-1">
			<a href="#" class="vector-toc-link">
				<div class="vector-toc-text">(Top)</div>
			</a>
		</li>
		<li id="toc-Functionality"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Functionality">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">1</span>Functionality</div>
		</a>
		
		<ul id="toc-Functionality-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Technology"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Technology">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">2</span>Technology</div>
		</a>
		
			<button aria-controls="toc-Technology-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Technology subsection</span>
			</button>
		
		<ul id="toc-Technology-sublist" class="vector-toc-list">
			<li id="toc-Contact"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Contact">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.1</span>Contact</div>
			</a>
			
			<ul id="toc-Contact-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Non-contact_active"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Non-contact_active">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.2</span>Non-contact active</div>
			</a>
			
			<ul id="toc-Non-contact_active-sublist" class="vector-toc-list">
				<li id="toc-Time-of-flight"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Time-of-flight">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.2.1</span>Time-of-flight</div>
			</a>
			
			<ul id="toc-Time-of-flight-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Triangulation"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Triangulation">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.2.2</span>Triangulation</div>
			</a>
			
			<ul id="toc-Triangulation-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Strengths_and_weaknesses"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Strengths_and_weaknesses">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.2.3</span>Strengths and weaknesses</div>
			</a>
			
			<ul id="toc-Strengths_and_weaknesses-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Conoscopic_holography"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Conoscopic_holography">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.2.4</span>Conoscopic holography</div>
			</a>
			
			<ul id="toc-Conoscopic_holography-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Hand-held_laser_scanners"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Hand-held_laser_scanners">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.3</span>Hand-held laser scanners</div>
			</a>
			
			<ul id="toc-Hand-held_laser_scanners-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Structured_light"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Structured_light">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.4</span>Structured light</div>
			</a>
			
			<ul id="toc-Structured_light-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Modulated_light"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Modulated_light">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.5</span>Modulated light</div>
			</a>
			
			<ul id="toc-Modulated_light-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Volumetric_techniques"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Volumetric_techniques">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.6</span>Volumetric techniques</div>
			</a>
			
			<ul id="toc-Volumetric_techniques-sublist" class="vector-toc-list">
				<li id="toc-Medical"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Medical">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.6.1</span>Medical</div>
			</a>
			
			<ul id="toc-Medical-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Industrial"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Industrial">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.6.2</span>Industrial</div>
			</a>
			
			<ul id="toc-Industrial-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Non-contact_passive"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Non-contact_passive">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.7</span>Non-contact passive</div>
			</a>
			
			<ul id="toc-Non-contact_passive-sublist" class="vector-toc-list">
				<li id="toc-Photogrammetric_non-contact_passive_methods"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Photogrammetric_non-contact_passive_methods">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.7.1</span>Photogrammetric non-contact passive methods</div>
			</a>
			
			<ul id="toc-Photogrammetric_non-contact_passive_methods-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Acquisition_from_acquired_sensor_data"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Acquisition_from_acquired_sensor_data">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.8</span>Acquisition from acquired sensor data</div>
			</a>
			
			<ul id="toc-Acquisition_from_acquired_sensor_data-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Acquisition_from_on-site_sensors"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Acquisition_from_on-site_sensors">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.9</span>Acquisition from on-site sensors</div>
			</a>
			
			<ul id="toc-Acquisition_from_on-site_sensors-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Cost"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Cost">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">2.10</span>Cost</div>
			</a>
			
			<ul id="toc-Cost-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Reconstruction"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Reconstruction">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">3</span>Reconstruction</div>
		</a>
		
			<button aria-controls="toc-Reconstruction-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Reconstruction subsection</span>
			</button>
		
		<ul id="toc-Reconstruction-sublist" class="vector-toc-list">
			<li id="toc-From_point_clouds"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#From_point_clouds">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.1</span>From point clouds</div>
			</a>
			
			<ul id="toc-From_point_clouds-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-From_models"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#From_models">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.2</span>From models</div>
			</a>
			
			<ul id="toc-From_models-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-From_a_set_of_2D_slices"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#From_a_set_of_2D_slices">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.3</span>From a set of 2D slices</div>
			</a>
			
			<ul id="toc-From_a_set_of_2D_slices-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-From_laser_scans"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#From_laser_scans">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.4</span>From laser scans</div>
			</a>
			
			<ul id="toc-From_laser_scans-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-From_photographs"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#From_photographs">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">3.5</span>From photographs</div>
			</a>
			
			<ul id="toc-From_photographs-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Applications"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Applications">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">4</span>Applications</div>
		</a>
		
			<button aria-controls="toc-Applications-sublist" class="cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle">
				<span class="vector-icon vector-icon--x-small mw-ui-icon-wikimedia-expand"></span>
				<span>Toggle Applications subsection</span>
			</button>
		
		<ul id="toc-Applications-sublist" class="vector-toc-list">
			<li id="toc-Space_experiments"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Space_experiments">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.1</span>Space experiments</div>
			</a>
			
			<ul id="toc-Space_experiments-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Construction_industry_and_civil_engineering"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Construction_industry_and_civil_engineering">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.2</span>Construction industry and civil engineering</div>
			</a>
			
			<ul id="toc-Construction_industry_and_civil_engineering-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Design_process"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Design_process">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.3</span>Design process</div>
			</a>
			
			<ul id="toc-Design_process-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Entertainment"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Entertainment">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.4</span>Entertainment</div>
			</a>
			
			<ul id="toc-Entertainment-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-3D_photography"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#3D_photography">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.5</span>3D photography</div>
			</a>
			
			<ul id="toc-3D_photography-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Law_enforcement"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Law_enforcement">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.6</span>Law enforcement</div>
			</a>
			
			<ul id="toc-Law_enforcement-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Reverse_engineering"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Reverse_engineering">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.7</span>Reverse engineering</div>
			</a>
			
			<ul id="toc-Reverse_engineering-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Real_estate"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Real_estate">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.8</span>Real estate</div>
			</a>
			
			<ul id="toc-Real_estate-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Virtual/remote_tourism"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Virtual/remote_tourism">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.9</span>Virtual/remote tourism</div>
			</a>
			
			<ul id="toc-Virtual/remote_tourism-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Cultural_heritage"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Cultural_heritage">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10</span>Cultural heritage</div>
			</a>
			
			<ul id="toc-Cultural_heritage-sublist" class="vector-toc-list">
				<li id="toc-Michelangelo"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Michelangelo">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10.1</span>Michelangelo</div>
			</a>
			
			<ul id="toc-Michelangelo-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Monticello"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Monticello">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10.2</span>Monticello</div>
			</a>
			
			<ul id="toc-Monticello-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Cuneiform_tablets"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Cuneiform_tablets">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10.3</span>Cuneiform tablets</div>
			</a>
			
			<ul id="toc-Cuneiform_tablets-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Kasubi_Tombs"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Kasubi_Tombs">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10.4</span>Kasubi Tombs</div>
			</a>
			
			<ul id="toc-Kasubi_Tombs-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-&quot;Plastico_di_Roma_antica&quot;"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#&quot;Plastico_di_Roma_antica&quot;">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10.5</span>"Plastico di Roma antica"</div>
			</a>
			
			<ul id="toc-&quot;Plastico_di_Roma_antica&quot;-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Other_projects"
			class="vector-toc-list-item vector-toc-level-3">
			<a class="vector-toc-link" href="#Other_projects">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.10.6</span>Other projects</div>
			</a>
			
			<ul id="toc-Other_projects-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
		</li>
		<li id="toc-Medical_CAD/CAM"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Medical_CAD/CAM">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.11</span>Medical CAD/CAM</div>
			</a>
			
			<ul id="toc-Medical_CAD/CAM-sublist" class="vector-toc-list">
			</ul>
		</li>
		<li id="toc-Quality_assurance_and_industrial_metrology"
			class="vector-toc-list-item vector-toc-level-2">
			<a class="vector-toc-link" href="#Quality_assurance_and_industrial_metrology">
				<div class="vector-toc-text">
				<span class="vector-toc-numb">4.12</span>Quality assurance and industrial metrology</div>
			</a>
			
			<ul id="toc-Quality_assurance_and_industrial_metrology-sublist" class="vector-toc-list">
			</ul>
		</li>
	</ul>
	</li>
	<li id="toc-Object_reconstruction"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Object_reconstruction">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">5</span>Object reconstruction</div>
		</a>
		
		<ul id="toc-Object_reconstruction-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-Software"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#Software">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">6</span>Software</div>
		</a>
		
		<ul id="toc-Software-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-See_also"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#See_also">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">7</span>See also</div>
		</a>
		
		<ul id="toc-See_also-sublist" class="vector-toc-list">
		</ul>
	</li>
	<li id="toc-References"
		class="vector-toc-list-item vector-toc-level-1">
		<a class="vector-toc-link" href="#References">
			<div class="vector-toc-text">
			<span class="vector-toc-numb">8</span>References</div>
		</a>
		
		<ul id="toc-References-sublist" class="vector-toc-list">
		</ul>
	</li>
</ul>
</div>

					</div>
		</nav>
			</div>
		</div>
		<div class="mw-content-container">
			<main id="content" class="mw-body" role="main">
				<header class="mw-body-header vector-page-titlebar">
					<nav role="navigation" aria-label="Contents" class="vector-toc-landmark">
						
<div id="vector-page-titlebar-toc" class="vector-dropdown vector-page-titlebar-toc vector-button-flush-left"  >
	<input type="checkbox" id="vector-page-titlebar-toc-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-titlebar-toc" class="vector-dropdown-checkbox "  aria-label="Toggle the table of contents"  >
	<label id="vector-page-titlebar-toc-label" for="vector-page-titlebar-toc-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only " aria-hidden="true"  ><span class="vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet"></span>

<span class="vector-dropdown-label-text">Toggle the table of contents</span>
	</label>
	<div class="vector-dropdown-content">


							<div id="vector-page-titlebar-toc-unpinned-container" class="vector-unpinned-container">
			</div>
		
	</div>
</div>

					</nav>
					<h1 id="firstHeading" class="firstHeading mw-first-heading"><span class="mw-page-title-main">3D scanning</span></h1>
							
<div id="p-lang-btn" class="vector-dropdown mw-portlet mw-portlet-lang"  >
	<input type="checkbox" id="p-lang-btn-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-lang-btn" class="vector-dropdown-checkbox mw-interlanguage-selector" aria-label="Go to an article in another language. Available in 8 languages"   >
	<label id="p-lang-btn-label" for="p-lang-btn-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-8" aria-hidden="true"  ><span class="vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive"></span>

<span class="vector-dropdown-label-text">8 languages</span>
	</label>
	<div class="vector-dropdown-content">

		<div class="vector-menu-content">
			
			<ul class="vector-menu-content-list">
				
				<li class="interlanguage-link interwiki-ko mw-list-item"><a href="https://ko.wikipedia.org/wiki/3%EC%B0%A8%EC%9B%90_%EC%8A%A4%EC%BA%90%EB%8B%9D" title="3차원 스캐닝 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target"><span>한국어</span></a></li><li class="interlanguage-link interwiki-nl mw-list-item"><a href="https://nl.wikipedia.org/wiki/3D-laserscanning" title="3D-laserscanning – Dutch" lang="nl" hreflang="nl" class="interlanguage-link-target"><span>Nederlands</span></a></li><li class="interlanguage-link interwiki-ja mw-list-item"><a href="https://ja.wikipedia.org/wiki/3D%E3%82%B9%E3%82%AD%E3%83%A3%E3%83%8B%E3%83%B3%E3%82%B0" title="3Dスキャニング – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target"><span>日本語</span></a></li><li class="interlanguage-link interwiki-no mw-list-item"><a href="https://no.wikipedia.org/wiki/Laserskanning" title="Laserskanning – Norwegian Bokmål" lang="nb" hreflang="nb" class="interlanguage-link-target"><span>Norsk bokmål</span></a></li><li class="interlanguage-link interwiki-pt mw-list-item"><a href="https://pt.wikipedia.org/wiki/Escaneamento_3D" title="Escaneamento 3D – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target"><span>Português</span></a></li><li class="interlanguage-link interwiki-fi mw-list-item"><a href="https://fi.wikipedia.org/wiki/3D-skannaus" title="3D-skannaus – Finnish" lang="fi" hreflang="fi" class="interlanguage-link-target"><span>Suomi</span></a></li><li class="interlanguage-link interwiki-tr mw-list-item"><a href="https://tr.wikipedia.org/wiki/%C3%9C%C3%A7_boyutlu_tarama" title="Üç boyutlu tarama – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target"><span>Türkçe</span></a></li><li class="interlanguage-link interwiki-zh-yue mw-list-item"><a href="https://zh-yue.wikipedia.org/wiki/3D_%E6%8E%83%E7%9E%84" title="3D 掃瞄 – Cantonese" lang="yue" hreflang="yue" class="interlanguage-link-target"><span>粵語</span></a></li>
			</ul>
			<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q94701573#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
		</div>

	</div>
</div>
</header>
				<div class="vector-page-toolbar">
					<div class="vector-page-toolbar-container">
						<div id="left-navigation">
							<nav aria-label="Namespaces">
								
<div id="p-associated-pages" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-nstab-main" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/3D_scanning" title="View the content page [c]" accesskey="c"><span>Article</span></a></li><li id="ca-talk" class="vector-tab-noicon mw-list-item"><a href="/wiki/Talk:3D_scanning" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t"><span>Talk</span></a></li>
		</ul>
		
	</div>
</div>

								
<div id="p-variants" class="vector-dropdown emptyPortlet"  >
	<input type="checkbox" id="p-variants-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-p-variants" class="vector-dropdown-checkbox " aria-label="Change language variant"   >
	<label id="p-variants-label" for="p-variants-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">English</span>
	</label>
	<div class="vector-dropdown-content">


					
<div id="p-variants" class="vector-menu mw-portlet mw-portlet-variants emptyPortlet"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			
		</ul>
		
	</div>
</div>

				
	</div>
</div>

							</nav>
						</div>
						<div id="right-navigation" class="vector-collapsible">
							<nav aria-label="Views">
								
<div id="p-views" class="vector-menu vector-menu-tabs mw-portlet mw-portlet-views"  >
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-view" class="selected vector-tab-noicon mw-list-item"><a href="/wiki/3D_scanning"><span>Read</span></a></li><li id="ca-edit" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-history" class="vector-tab-noicon mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;action=history" title="Past revisions of this page [h]" accesskey="h"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

							</nav>
				
							<nav class="vector-page-tools-landmark" aria-label="Page tools">
								
<div id="vector-page-tools-dropdown" class="vector-dropdown vector-page-tools-dropdown"  >
	<input type="checkbox" id="vector-page-tools-dropdown-checkbox" role="button" aria-haspopup="true" data-event-name="ui.dropdown-vector-page-tools-dropdown" class="vector-dropdown-checkbox "  aria-label="Tools"  >
	<label id="vector-page-tools-dropdown-label" for="vector-page-tools-dropdown-checkbox" class="vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet" aria-hidden="true"  ><span class="vector-dropdown-label-text">Tools</span>
	</label>
	<div class="vector-dropdown-content">


									<div id="vector-page-tools-unpinned-container" class="vector-unpinned-container">
						
<div id="vector-page-tools" class="vector-page-tools vector-pinnable-element">
	<div
	class="vector-pinnable-header vector-page-tools-pinnable-header vector-pinnable-header-unpinned"
	data-feature-name="page-tools-pinned"
	data-pinnable-element-id="vector-page-tools"
	data-pinned-container-id="vector-page-tools-pinned-container"
	data-unpinned-container-id="vector-page-tools-unpinned-container"
>
	<div class="vector-pinnable-header-label">Tools</div>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-pin-button" data-event-name="pinnable-header.vector-page-tools.pin">move to sidebar</button>
	<button class="vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button" data-event-name="pinnable-header.vector-page-tools.unpin">hide</button>
</div>

	
<div id="p-cactions" class="vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items"  title="More options" >
	<div class="vector-menu-heading">
		Actions
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="ca-more-view" class="selected vector-more-collapsible-item mw-list-item"><a href="/wiki/3D_scanning"><span>Read</span></a></li><li id="ca-more-edit" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;action=edit" title="Edit this page [e]" accesskey="e"><span>Edit</span></a></li><li id="ca-more-history" class="vector-more-collapsible-item mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;action=history"><span>View history</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-tb" class="vector-menu mw-portlet mw-portlet-tb"  >
	<div class="vector-menu-heading">
		General
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="t-whatlinkshere" class="mw-list-item"><a href="/wiki/Special:WhatLinksHere/3D_scanning" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j"><span>What links here</span></a></li><li id="t-recentchangeslinked" class="mw-list-item"><a href="/wiki/Special:RecentChangesLinked/3D_scanning" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k"><span>Related changes</span></a></li><li id="t-upload" class="mw-list-item"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u"><span>Upload file</span></a></li><li id="t-specialpages" class="mw-list-item"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q"><span>Special pages</span></a></li><li id="t-permalink" class="mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;oldid=1217300576" title="Permanent link to this revision of this page"><span>Permanent link</span></a></li><li id="t-info" class="mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;action=info" title="More information about this page"><span>Page information</span></a></li><li id="t-cite" class="mw-list-item"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=3D_scanning&amp;id=1217300576&amp;wpFormIdentifier=titleform" title="Information on how to cite this page"><span>Cite this page</span></a></li><li id="t-urlshortener" class="mw-list-item"><a href="/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2F3D_scanning"><span>Get shortened URL</span></a></li><li id="t-urlshortener-qrcode" class="mw-list-item"><a href="/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2F3D_scanning"><span>Download QR code</span></a></li><li id="t-wikibase" class="mw-list-item"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q94701573" title="Structured data on this page hosted by Wikidata [g]" accesskey="g"><span>Wikidata item</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-coll-print_export" class="vector-menu mw-portlet mw-portlet-coll-print_export"  >
	<div class="vector-menu-heading">
		Print/export
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li id="coll-download-as-rl" class="mw-list-item"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=3D_scanning&amp;action=show-download-screen" title="Download this page as a PDF file"><span>Download as PDF</span></a></li><li id="t-print" class="mw-list-item"><a href="/w/index.php?title=3D_scanning&amp;printable=yes" title="Printable version of this page [p]" accesskey="p"><span>Printable version</span></a></li>
		</ul>
		
	</div>
</div>

<div id="p-wikibase-otherprojects" class="vector-menu mw-portlet mw-portlet-wikibase-otherprojects"  >
	<div class="vector-menu-heading">
		In other projects
	</div>
	<div class="vector-menu-content">
		
		<ul class="vector-menu-content-list">
			
			<li class="wb-otherproject-link wb-otherproject-commons mw-list-item"><a href="https://commons.wikimedia.org/wiki/Category:3D_scanning" hreflang="en"><span>Wikimedia Commons</span></a></li>
		</ul>
		
	</div>
</div>

</div>

									</div>
				
	</div>
</div>

							</nav>
						</div>
					</div>
				</div>
				<div class="vector-column-end">
					<div class="vector-sticky-pinned-container">
						<nav class="vector-page-tools-landmark" aria-label="Page tools">
							<div id="vector-page-tools-pinned-container" class="vector-pinned-container">
				
							</div>
		</nav>
						<nav class="vector-client-prefs-landmark" aria-label="Appearance">
						</nav>
					</div>
				</div>
				<div id="bodyContent" class="vector-body" aria-labelledby="firstHeading" data-mw-ve-target-container>
					<div class="vector-body-before-content">
							<div class="mw-indicators">
		</div>

						<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
					</div>
					<div id="contentSub"><div id="mw-content-subtitle"><span class="mw-redirectedfrom">(Redirected from <a href="/w/index.php?title=3D_scanner&amp;redirect=no" class="mw-redirect" title="3D scanner">3D scanner</a>)</span></div></div>
					
					
					<div id="mw-content-text" class="mw-body-content"><div class="mw-content-ltr mw-parser-output" lang="en" dir="ltr"><div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">Scanning of an object or environment to collect data on its shape</div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:VIUscan_handheld_3D_scanner_in_use.jpg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIUscan_handheld_3D_scanner_in_use.jpg/220px-VIUscan_handheld_3D_scanner_in_use.jpg" decoding="async" width="220" height="146" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIUscan_handheld_3D_scanner_in_use.jpg/330px-VIUscan_handheld_3D_scanner_in_use.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/26/VIUscan_handheld_3D_scanner_in_use.jpg/440px-VIUscan_handheld_3D_scanner_in_use.jpg 2x" data-file-width="2816" data-file-height="1872" /></a><figcaption>Making a 3D-model of a Viking belt buckle using a hand held VIUscan 3D laser scanner</figcaption></figure>
<p><b>3D scanning</b> is the process of analyzing a real-world object or environment to collect three dimensional data of its shape and possibly its appearance (e.g. color). The collected data can then be used to construct digital <a href="/wiki/3D_modelling" class="mw-redirect" title="3D modelling">3D models</a>.
</p><p>A <b>3D scanner</b> can be based on many different technologies, each with its own limitations, advantages and costs. Many limitations in the kind of objects that can be <a href="/wiki/Digitization" title="Digitization">digitised</a> are still present. For example, optical technology may encounter many difficulties with dark, shiny, reflective or transparent objects. For example, <a href="/wiki/Industrial_computed_tomography_scanning" class="mw-redirect" title="Industrial computed tomography scanning">industrial computed tomography scanning</a>, <a href="/wiki/Structured-light_3D_scanner" title="Structured-light 3D scanner">structured-light 3D scanners</a>, <a href="/wiki/Lidar" title="Lidar">LiDAR</a> and <a href="/wiki/Time-of-flight_camera" title="Time-of-flight camera">Time Of Flight</a> 3D Scanners can be used to construct digital <a href="/wiki/3D_modeling" title="3D modeling">3D models</a>, without <a href="/wiki/Non-destructive_testing" class="mw-redirect" title="Non-destructive testing">destructive testing</a>.
</p><p>Collected 3D data is useful for a wide variety of applications. These devices are used extensively by the entertainment industry in the production of movies and video games, including <a href="/wiki/Virtual_reality" title="Virtual reality">virtual reality</a>. Other common applications of this technology include <a href="/wiki/Augmented_reality" title="Augmented reality">augmented reality</a>,<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup> <a href="/wiki/Motion_capture" title="Motion capture">motion capture</a>,<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup><sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup> <a href="/wiki/Gesture_recognition" title="Gesture recognition">gesture recognition</a>,<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup> <a href="/wiki/Robotic_mapping" title="Robotic mapping">robotic mapping</a>,<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup> <a href="/wiki/Industrial_design" title="Industrial design">industrial design</a>, <a href="/wiki/Orthotics" title="Orthotics">orthotics</a> and <a href="/wiki/Prosthetics" class="mw-redirect" title="Prosthetics">prosthetics</a>,<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup> <a href="/wiki/Reverse_engineering" title="Reverse engineering">reverse engineering</a> and <a href="/wiki/Prototyping" class="mw-redirect" title="Prototyping">prototyping</a>, <a href="/wiki/Quality_control" title="Quality control">quality control</a>/inspection and the <a href="/wiki/Digitization" title="Digitization">digitization</a> of cultural artifacts.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup>
</p>
<meta property="mw:PageProp/toc" />
<h2><span class="mw-headline" id="Functionality">Functionality</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=1" title="Edit section: Functionality"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The purpose of a 3D scanner is usually to create a <a href="/wiki/3D_modelling" class="mw-redirect" title="3D modelling">3D model</a>. This 3D model consists of a <a href="/wiki/Polygon_mesh" title="Polygon mesh">polygon mesh</a> or <a href="/wiki/Point_cloud" title="Point cloud">point cloud</a> of geometric samples on the surface of the subject. These points can then be used to extrapolate the shape of the subject (a process called <a href="/wiki/3D_reconstruction" title="3D reconstruction">reconstruction</a>). If colour information is collected at each point, then the colours or textures on the surface of the subject can also be determined.
</p><p>3D scanners share several traits with cameras. Like most cameras, they have a cone-like <a href="/wiki/Field_of_view" title="Field of view">field of view</a>, and like cameras, they can only collect information about surfaces that are not obscured. While a camera collects colour information about surfaces within its <a href="/wiki/Field_of_view" title="Field of view">field of view</a>, a 3D scanner collects distance information about surfaces within its field of view. The "picture" produced by a 3D scanner describes the distance to a surface at each point in the picture. This allows the three dimensional position of each point in the picture to be identified.
</p><p>In some situations, a single scan will not produce a complete model of the subject. Multiple scans, from different directions are usually helpful to obtain information about all sides of the subject. These scans have to be brought into a common <a href="/wiki/Coordinate_system" title="Coordinate system">reference system</a>, a process that is usually called <i>alignment</i> or <i><a href="/wiki/Image_registration" title="Image registration">registration</a></i>, and then merged to create a complete 3D model. This whole process, going from the single range map to the whole model, is usually known as the 3D scanning pipeline.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup><sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup><sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup><sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup><sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Technology">Technology</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=2" title="Edit section: Technology"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>There are a variety of technologies for digitally acquiring the shape of a 3D object. The techniques work with most or all sensor types including optical, acoustic, laser scanning,<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup> radar, thermal,<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup> and seismic.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup><sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup> A well established classification<sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup> divides them into two types: contact and non-contact. Non-contact solutions can be further divided into two main categories, active and passive. There are a variety of technologies that fall under each of these categories.
</p>
<h3><span class="mw-headline" id="Contact">Contact</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=3" title="Edit section: Contact"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:5_Axis_Scanning_Coordinate_Measurement_Machine_(CMM).png" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/5_Axis_Scanning_Coordinate_Measurement_Machine_%28CMM%29.png/220px-5_Axis_Scanning_Coordinate_Measurement_Machine_%28CMM%29.png" decoding="async" width="220" height="165" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/5_Axis_Scanning_Coordinate_Measurement_Machine_%28CMM%29.png/330px-5_Axis_Scanning_Coordinate_Measurement_Machine_%28CMM%29.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9e/5_Axis_Scanning_Coordinate_Measurement_Machine_%28CMM%29.png/440px-5_Axis_Scanning_Coordinate_Measurement_Machine_%28CMM%29.png 2x" data-file-width="2048" data-file-height="1536" /></a><figcaption>A <a href="/wiki/Coordinate_measuring_machine" class="mw-redirect" title="Coordinate measuring machine">coordinate measuring machine</a> (CMM) with scanning head</figcaption></figure>
<p>Contact 3D scanners work by physically probing (touching) the part and recording the position of the sensor as the probe moves around the part.
</p><p>There are two main types of contact 3D scanners:
</p>
<ul><li><a href="/wiki/Coordinate-measuring_machine" title="Coordinate-measuring machine">Coordinate measuring machines (CMMs)</a> which traditionally have 3 perpendicular moving axis with a touch probe mounted on the Z axis. As the touch probe moves around the part, sensors on each axis record the position to generate XYZ coordinates. Modern CMMs are 5 axis systems, with the two extra axes provided by pivoting sensor heads. CMMs are the most accurate form of 3D measurement achieving micron precision. The greatest advantage of a CMM after accuracy is that it can be run in autonomous (CNC) mode or as a manual probing system. The disadvantage of CMMs is that their upfront cost and the technical knowledge required to operate them.</li>
<li>Articulated Arms which generally have multiple segments with polar sensors on each joint. As per the CMM, as the articulated arm moves around the part sensors record their position and the location of the end of the arm is calculated using complex math and the wrist rotation angle and hinge angle of each joint. While not usually as accurate as CMMs, articulated arms still achieve high accuracy and are cheaper and slightly easier to use. They do not usually have CNC options.</li></ul>
<p>Both modern CMMs and Articulated Arms can also be fitted with non-contact laser scanners instead of touch probes.
</p>
<h3><span class="mw-headline" id="Non-contact_active">Non-contact active</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=4" title="Edit section: Non-contact active"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Active scanners emit some kind of radiation or light and detect its reflection or radiation passing through object in order to probe an object or environment. Possible types of emissions used include light, <a href="/wiki/Non-Contact_Ultrasound" class="mw-redirect" title="Non-Contact Ultrasound">ultrasound</a> or x-ray.
</p>
<h4><span class="mw-headline" id="Time-of-flight">Time-of-flight</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=5" title="Edit section: Time-of-flight"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<figure class="mw-halign-right" typeof="mw:File/Thumb"><a href="/wiki/File:Lidar_P1270901.jpg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Lidar_P1270901.jpg/240px-Lidar_P1270901.jpg" decoding="async" width="240" height="320" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Lidar_P1270901.jpg/360px-Lidar_P1270901.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Lidar_P1270901.jpg/480px-Lidar_P1270901.jpg 2x" data-file-width="1920" data-file-height="2560" /></a><figcaption>This <a href="/wiki/Lidar" title="Lidar">lidar</a> scanner may be used to scan buildings, rock formations, etc., to produce a 3D model. The lidar can aim its laser beam in a wide range: its head rotates horizontally, a mirror flips vertically. The laser beam is used to measure the distance to the first object on its path.</figcaption></figure>
<p>The time-of-flight 3D laser scanner is an active scanner that uses laser light to probe the subject. At the heart of this type of scanner is a time-of-flight <a href="/wiki/Laser_range_finder" class="mw-redirect" title="Laser range finder">laser range finder</a>. The laser range finder finds the distance of a surface by timing the round-trip time of a pulse of light. A laser is used to emit a pulse of light and the amount of time before the reflected light is seen by a detector is measured. Since the <a href="/wiki/Speed_of_light" title="Speed of light">speed of light</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle c}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>c</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle c}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86a67b81c2de995bd608d5b2df50cd8cd7d92455" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:1.007ex; height:1.676ex;" alt="{\displaystyle c}"></span> is known, the round-trip time determines the travel distance of the light, which is twice the distance between the scanner and the surface. If <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="{\displaystyle t}"></span> is the round-trip time, then distance is equal to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \textstyle c\!\cdot \!t/2}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mstyle displaystyle="false" scriptlevel="0">
          <mi>c</mi>
          <mspace width="negativethinmathspace" />
          <mo>&#x22C5;<!-- ⋅ --></mo>
          <mspace width="negativethinmathspace" />
          <mi>t</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>/</mo>
          </mrow>
          <mn>2</mn>
        </mstyle>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \textstyle c\!\cdot \!t/2}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/62cbbad1bb40e1e2d9ce4ed26fdf0dc4ce02ef53" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.838ex; width:5.076ex; height:2.843ex;" alt="{\displaystyle \textstyle c\!\cdot \!t/2}"></span>. The accuracy of a time-of-flight 3D laser scanner depends on how precisely we can measure the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle t}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>t</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle t}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/65658b7b223af9e1acc877d848888ecdb4466560" class="mwe-math-fallback-image-inline mw-invert" aria-hidden="true" style="vertical-align: -0.338ex; width:0.84ex; height:2.009ex;" alt="{\displaystyle t}"></span> time: 3.3 <a href="/wiki/Picosecond" title="Picosecond">picoseconds</a> (approx.) is the time taken for light to travel 1 millimetre.
</p><p>The laser range finder only detects the distance of one point in its direction of view. Thus, the scanner scans its entire field of view one point at a time by changing the range finder's direction of view to scan different points. The view direction of the laser range finder can be changed either by rotating the range finder itself, or by using a system of rotating mirrors. The latter method is commonly used because mirrors are much lighter and can thus be rotated much faster and with greater accuracy. Typical time-of-flight 3D laser scanners can measure the distance of 10,000~100,000 points every second.
</p><p>Time-of-flight devices are also available in a 2D configuration. This is referred to as a <a href="/wiki/Time-of-flight_camera" title="Time-of-flight camera">time-of-flight camera</a>.<sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup>
</p>
<h4><span class="mw-headline" id="Triangulation">Triangulation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=6" title="Edit section: Triangulation"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<figure class="mw-halign-right" typeof="mw:File/Thumb"><a href="/wiki/File:Laserprofilometer_EN.svg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/2/24/Laserprofilometer_EN.svg/240px-Laserprofilometer_EN.svg.png" decoding="async" width="240" height="271" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/24/Laserprofilometer_EN.svg/360px-Laserprofilometer_EN.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/24/Laserprofilometer_EN.svg/480px-Laserprofilometer_EN.svg.png 2x" data-file-width="305" data-file-height="344" /></a><figcaption>Principle of a laser triangulation sensor. Two object positions are shown.</figcaption></figure>
<p><a href="/wiki/Triangulation_(computer_vision)" title="Triangulation (computer vision)">Triangulation</a> based 3D laser scanners are also active scanners that use laser light to probe the environment. With respect to time-of-flight 3D laser scanner the triangulation laser shines a laser on the subject and exploits a camera to look for the location of the laser dot. Depending on how far away the laser strikes a surface, the laser dot appears at different places in the camera's field of view. This technique is called triangulation because the laser dot, the camera and the laser emitter form a triangle. The length of one side of the triangle, the distance between the camera and the laser emitter is known. The angle of the laser emitter corner is also known. The angle of the camera corner can be determined by looking at the location of the laser dot in the camera's field of view. These three pieces of information fully determine the shape and size of the triangle and give the location of the laser dot corner of the triangle.<sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup> In most cases a laser stripe, instead of a single laser dot, is swept across the object to speed up the acquisition process. The use of <a href="/wiki/Triangulation" title="Triangulation">triangulation</a> to measure distances dates to antiquity.
</p>
<h4><span class="mw-headline" id="Strengths_and_weaknesses">Strengths and weaknesses</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=7" title="Edit section: Strengths and weaknesses"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Time-of-flight range finders are capable of operating over long distances on the order of kilometres. These scanners are thus suitable for scanning large structures like buildings or geographic features. A disadvantage is that, due to the high speed of light, measuring the round-trip time is difficult and so the accuracy of the distance measurement is relatively low, on the order of millimetres.
</p><p>Triangulation range finders, on the other hand, have a range of usually limited to a few meters for reasonably sized devices, but their accuracy is relatively high. The accuracy of triangulation range finders is on the order of tens of <a href="/wiki/Micrometers" class="mw-redirect" title="Micrometers">micrometers</a>.
</p><p>Time-of-flight scanners' accuracy can be lost when the laser hits the edge of an object because the information that is sent back to the scanner is from two different locations for one laser pulse. The coordinate relative to the scanner's position for a point that has hit the edge of an object will be calculated based on an average and therefore will put the point in the wrong place. When using a high resolution scan on an object the chances of the beam hitting an edge are increased and the resulting data will show noise just behind the edges of the object. Scanners with a smaller beam width will help to solve this problem but will be limited by range as the beam width will increase over distance. Software can also help by determining that the first object to be hit by the laser beam should cancel out the second.
</p><p>At a rate of 10,000 sample points per second, low resolution scans can take less than a second, but high resolution scans, requiring millions of samples, can take minutes for some time-of-flight scanners. The problem this creates is distortion from motion. Since each point is sampled at a different time, any motion in the subject or the scanner will distort the collected data. Thus, it is usually necessary to mount both the subject and the scanner on stable platforms and minimise vibration. Using these scanners to scan objects in motion is very difficult.
</p><p>Recently, there has been research on compensating for distortion from small amounts of vibration<sup id="cite_ref-20" class="reference"><a href="#cite_note-20">&#91;20&#93;</a></sup> and distortions due to motion and/or rotation.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup>
</p><p>Short-range laser scanners can not usually encompass a depth of field more than 1 meter.<sup id="cite_ref-22" class="reference"><a href="#cite_note-22">&#91;22&#93;</a></sup> When scanning in one position for any length of time slight movement can occur in the scanner position due to changes in temperature. If the scanner is set on a tripod and there is strong sunlight on one side of the scanner then that side of the tripod will expand and slowly distort the scan data from one side to another. Some laser scanners have level compensators built into them to counteract any movement of the scanner during the scan process.
</p>
<h4><span class="mw-headline" id="Conoscopic_holography">Conoscopic holography</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=8" title="Edit section: Conoscopic holography"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In a <a href="/wiki/Conoscopy" title="Conoscopy">conoscopic</a> system, a laser beam is projected onto the surface and then the immediate reflection along the same ray-path are put through a conoscopic crystal and projected onto a CCD. The result is a <a href="/wiki/Diffraction_pattern" class="mw-redirect" title="Diffraction pattern">diffraction pattern</a>, that can be <a href="/wiki/Frequency_analysis" title="Frequency analysis">frequency analyzed</a> to determine the distance to the measured surface. The main advantage with conoscopic holography is that only a single ray-path is needed for measuring, thus giving an opportunity to measure for instance the depth of a finely drilled hole.<sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Hand-held_laser_scanners">Hand-held laser scanners</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=9" title="Edit section: Hand-held laser scanners"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Hand-held laser scanners create a 3D image through the triangulation mechanism described above: a laser dot or line is projected onto an object from a hand-held device and a sensor (typically a <a href="/wiki/Charge-coupled_device" title="Charge-coupled device">charge-coupled device</a> or <a href="/wiki/Position_sensitive_device" title="Position sensitive device">position sensitive device</a>) measures the distance to the surface. Data is collected in relation to an internal coordinate system and therefore to collect data where the scanner is in motion the position of the scanner must be determined. The position can be determined by the scanner using reference features on the surface being scanned (typically adhesive reflective tabs, but natural features have been also used in research work)<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup><sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup> or by using an external tracking method. External tracking often takes the form of a <a href="/wiki/Laser_tracker" title="Laser tracker">laser tracker</a> (to provide the sensor position) with integrated camera (to determine the orientation of the scanner) or a <a href="/wiki/Photogrammetric" class="mw-redirect" title="Photogrammetric">photogrammetric</a> solution using 3 or more cameras providing the complete <a href="/wiki/Six_degrees_of_freedom" title="Six degrees of freedom">six degrees of freedom</a> of the scanner. Both techniques tend to use <a href="/wiki/Infrared" title="Infrared">infrared</a> <a href="/wiki/Light-emitting_diode" title="Light-emitting diode">light-emitting diodes</a> attached to the scanner which are seen by the camera(s) through filters providing resilience to ambient lighting.<sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup>
</p><p>Data is collected by a computer and recorded as data points within <a href="/wiki/Three-dimensional_space" title="Three-dimensional space">three-dimensional space</a>, with processing this can be converted into a triangulated mesh and then a <a href="/wiki/Computer-aided_design" title="Computer-aided design">computer-aided design</a> model, often as <a href="/wiki/Non-uniform_rational_B-spline" title="Non-uniform rational B-spline">non-uniform rational B-spline</a> surfaces. Hand-held laser scanners can combine this data with passive, visible-light sensors — which capture surface textures and colors — to build (or "<a href="/wiki/Reverse_engineer" class="mw-redirect" title="Reverse engineer">reverse engineer</a>") a full 3D model.
</p>
<h3><span class="mw-headline" id="Structured_light">Structured light</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=10" title="Edit section: Structured light"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Structured-light_3D_scanner" title="Structured-light 3D scanner">Structured-light 3D scanner</a></div>
<p>Structured-light 3D scanners project a pattern of light on the subject and look at the deformation of the pattern on the subject. The pattern is projected onto the subject using either an <a href="/wiki/LCD_projector" title="LCD projector">LCD projector</a> or other stable light source. A camera, offset slightly from the pattern projector, looks at the shape of the pattern and calculates the distance of every point in the field of view.
</p><p>Structured-light scanning is still a very active area of research with many research papers published each year. Perfect maps have also been proven useful as structured light patterns that solve the <a href="/wiki/Correspondence_problem" title="Correspondence problem">correspondence problem</a> and allow for error detection and error correction.<sup id="cite_ref-27" class="reference"><a href="#cite_note-27">&#91;27&#93;</a></sup>
</p><p>The advantage of structured-light 3D scanners is speed and precision. Instead of scanning one point at a time, structured light scanners scan multiple points or the entire field of view at once. Scanning an entire field of view in a fraction of a second reduces or eliminates the problem of distortion from motion. Some existing systems are capable of scanning moving objects in real-time. 
</p><p>A real-time scanner using digital fringe projection and phase-shifting technique (certain kinds of structured light methods) was developed, to capture, reconstruct, and render high-density details of dynamically deformable objects (such as facial expressions) at 40 frames per second.<sup id="cite_ref-28" class="reference"><a href="#cite_note-28">&#91;28&#93;</a></sup> Recently, another scanner has been developed. Different patterns can be applied to this system, and the frame rate for capturing and data processing achieves 120 frames per second. It can also scan isolated surfaces, for example two moving hands.<sup id="cite_ref-29" class="reference"><a href="#cite_note-29">&#91;29&#93;</a></sup> By utilising the binary defocusing technique, speed breakthroughs have been made that could reach hundreds<sup id="cite_ref-30" class="reference"><a href="#cite_note-30">&#91;30&#93;</a></sup> to thousands of frames per second.<sup id="cite_ref-31" class="reference"><a href="#cite_note-31">&#91;31&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Modulated_light">Modulated light</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=11" title="Edit section: Modulated light"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Modulated light 3D scanners shine a continually changing light at the subject. Usually the light source simply cycles its amplitude in a <a href="/wiki/Sinusoidal" class="mw-redirect" title="Sinusoidal">sinusoidal</a> pattern. A camera detects the reflected light and the amount the pattern is shifted by determines the distance the light travelled. Modulated light also allows the scanner to ignore light from sources other than a laser, so there is no interference.
</p>
<h3><span class="mw-headline" id="Volumetric_techniques">Volumetric techniques</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=12" title="Edit section: Volumetric techniques"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span class="mw-headline" id="Medical">Medical</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=13" title="Edit section: Medical"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p><a href="/wiki/Computed_tomography" class="mw-redirect" title="Computed tomography">Computed tomography</a> (CT) is a medical imaging method which generates a three-dimensional image of the inside of an object from a large series of two-dimensional X-ray images, similarly <a href="/wiki/Magnetic_resonance_imaging" title="Magnetic resonance imaging">magnetic resonance imaging</a> is another medical imaging technique that provides much greater contrast between the different soft tissues of the body than computed tomography (CT) does, making it especially useful in neurological (brain), musculoskeletal, cardiovascular, and oncological (cancer) imaging. These techniques produce a <a href="/wiki/Voxel" title="Voxel">discrete 3D volumetric representation</a> that can be directly <a href="/wiki/Volume_rendering" title="Volume rendering">visualised</a>, manipulated or converted to traditional 3D surface by mean of <a href="/wiki/Marching_cubes" title="Marching cubes">isosurface extraction algorithms</a>.
</p>
<h4><span class="mw-headline" id="Industrial">Industrial</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=14" title="Edit section: Industrial"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Although most common in medicine, <a href="/wiki/Industrial_computed_tomography" title="Industrial computed tomography">industrial computed tomography</a>, <a href="/wiki/Industrial_CT_Scanning" class="mw-redirect" title="Industrial CT Scanning">microtomography</a> and MRI are also used in other fields for acquiring a digital representation of an object and its interior, such as non destructive materials testing, <a href="/wiki/Reverse_engineering" title="Reverse engineering">reverse engineering</a>, or studying biological and paleontological specimens.
</p>
<h3><span class="mw-headline" id="Non-contact_passive">Non-contact passive</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=15" title="Edit section: Non-contact passive"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Passive 3D imaging solutions do not emit any kind of radiation themselves, but instead rely on detecting reflected ambient radiation. Most solutions of this type detect visible light because it is a readily available ambient radiation. Other types of radiation, such as infrared could also be used. Passive methods can be very cheap, because in most cases they do not need particular hardware but simple digital cameras.
</p>
<ul><li><i>Stereoscopic</i> systems usually employ two video cameras, slightly apart, looking at the same scene. By analysing the slight differences between the images seen by each camera, it is possible to determine the distance at each point in the images. This method is based on the same principles driving human <a href="/wiki/Stereoscopic_vision" class="mw-redirect" title="Stereoscopic vision">stereoscopic vision</a>.<sup id="cite_ref-32" class="reference"><a href="#cite_note-32">&#91;32&#93;</a></sup></li>
<li><i><a href="/wiki/Photometric_Stereo" class="mw-redirect" title="Photometric Stereo">Photometric</a></i> systems usually use a single camera, but take multiple images under varying lighting conditions. These techniques attempt to invert the image formation model in order to recover the surface orientation at each pixel.</li>
<li><i>Silhouette</i> techniques use outlines created from a sequence of photographs around a three-dimensional object against a well contrasted background. These <a href="/wiki/Silhouette" title="Silhouette">silhouettes</a> are extruded and intersected to form the <a href="/wiki/Visual_hull" title="Visual hull">visual hull</a> approximation of the object. With these approaches some concavities of an object (like the interior of a bowl) cannot be detected.</li></ul>
<h4><span class="mw-headline" id="Photogrammetric_non-contact_passive_methods">Photogrammetric non-contact passive methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=16" title="Edit section: Photogrammetric non-contact passive methods"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-Expand_section plainlinks metadata ambox mbox-small-left ambox-content" role="presentation"><tbody><tr><td class="mbox-image"><span typeof="mw:File"><a href="/wiki/File:Wiki_letter_w_cropped.svg" class="mw-file-description"><img alt="[icon]" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/20px-Wiki_letter_w_cropped.svg.png" decoding="async" width="20" height="14" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/30px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/40px-Wiki_letter_w_cropped.svg.png 2x" data-file-width="44" data-file-height="31" /></a></span></td><td class="mbox-text"><div class="mbox-text-span">This section <b>needs expansion</b>. You can help by <a class="external text" href="https://en.wikipedia.org/w/index.php?title=3D_scanning&amp;action=edit&amp;section=">adding to it</a>.  <span class="date-container"><i>(<span class="date">March 2020</span>)</i></span></div></td></tr></tbody></table>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Photogrammetry" title="Photogrammetry">Photogrammetry</a></div>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Camera_Array_Photogrammetry.svg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/1/10/Camera_Array_Photogrammetry.svg/220px-Camera_Array_Photogrammetry.svg.png" decoding="async" width="220" height="176" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/10/Camera_Array_Photogrammetry.svg/330px-Camera_Array_Photogrammetry.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/10/Camera_Array_Photogrammetry.svg/440px-Camera_Array_Photogrammetry.svg.png 2x" data-file-width="567" data-file-height="454" /></a><figcaption>Images taken from multiple perspectives such as a fixed camera array can be taken of a subject for a photogrammetric reconstruction pipeline to generate a 3D mesh or point cloud.</figcaption></figure>
<p><a href="/wiki/Photogrammetry" title="Photogrammetry">Photogrammetry</a> provides reliable information about 3D shapes of physical objects based on analysis of photographic images. The resulting 3D data is typically provided as a 3D point cloud, 3D mesh or 3D points.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup> Modern photogrammetry software applications automatically analyze a large number of digital images for 3D reconstruction, however manual interaction may be required if the software cannot automatically determine the 3D positions of the camera in the images which is an essential step in the reconstruction pipeline. Various software packages are available including <a href="/wiki/PhotoModeler" title="PhotoModeler">PhotoModeler</a>, <a href="/w/index.php?title=Geodetic_Systems&amp;action=edit&amp;redlink=1" class="new" title="Geodetic Systems (page does not exist)">Geodetic Systems</a>, <a href="/wiki/Autodesk_ReCap" class="mw-redirect" title="Autodesk ReCap">Autodesk ReCap</a>, <a href="/wiki/RealityCapture" title="RealityCapture">RealityCapture</a> and <a href="/wiki/Metashape" title="Metashape">Agisoft Metashape</a> (see <a href="/wiki/Comparison_of_photogrammetry_software" title="Comparison of photogrammetry software">comparison of photogrammetry software</a>).
</p>
<ul><li><i>Close range photogrammetry</i> typically uses a handheld camera such as a <a href="/wiki/Digital_single-lens_reflex_camera" title="Digital single-lens reflex camera">DSLR</a> with a <a href="/wiki/Prime_lens" title="Prime lens">fixed focal length lens</a> to capture images of objects for 3D reconstruction.<sup id="cite_ref-34" class="reference"><a href="#cite_note-34">&#91;34&#93;</a></sup> Subjects include smaller objects such as a <a href="/wiki/Facade" class="mw-redirect" title="Facade">building facade</a>, vehicles, sculptures, rocks, and shoes.</li>
<li><i>Camera Arrays</i> can be used to generate 3D point clouds or meshes of live objects such as people or pets by synchronizing multiple cameras to photograph a subject from multiple perspectives at the same time for 3D object reconstruction.<sup id="cite_ref-35" class="reference"><a href="#cite_note-35">&#91;35&#93;</a></sup></li>
<li><i>Wide angle photogrammetry</i> can be used to capture the interior of buildings or enclosed spaces using a <a href="/wiki/Wide-angle_lens" title="Wide-angle lens">wide angle lens</a> camera such as a <a href="/wiki/Omnidirectional_camera" class="mw-redirect" title="Omnidirectional camera">360 camera</a>.</li>
<li><i>Aerial photogrammetry</i> uses <a href="/wiki/Aerial_photography" title="Aerial photography">aerial images</a> acquired by satellite, commercial aircraft or <a href="/wiki/Miniature_UAV" title="Miniature UAV">UAV drone</a> to collect images of buildings, structures and terrain for 3D reconstruction into a point cloud or mesh.</li></ul>
<h3><span class="mw-headline" id="Acquisition_from_acquired_sensor_data">Acquisition from acquired sensor data</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=17" title="Edit section: Acquisition from acquired sensor data"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Semi-automatic building extraction from <a href="/wiki/Lidar" title="Lidar">lidar</a> data and high-resolution images is also a possibility. Again, this approach allows modelling without physically moving towards the location or object.<sup id="cite_ref-36" class="reference"><a href="#cite_note-36">&#91;36&#93;</a></sup> From airborne lidar data, digital surface model (DSM) can be generated and then the objects higher than the ground are automatically detected from the DSM. Based on general knowledge about buildings, geometric characteristics such as size, height and shape information are then used to separate the buildings from other objects. The extracted building outlines are then simplified using an orthogonal algorithm to obtain better cartographic quality. Watershed analysis can be conducted to extract the ridgelines of building roofs. The ridgelines as well as slope information are used to classify the buildings per type. The buildings are then reconstructed using three parametric building models (flat, gabled, hipped).<sup id="cite_ref-37" class="reference"><a href="#cite_note-37">&#91;37&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Acquisition_from_on-site_sensors">Acquisition from on-site sensors</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=18" title="Edit section: Acquisition from on-site sensors"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Lidar and other terrestrial laser scanning technology<sup id="cite_ref-38" class="reference"><a href="#cite_note-38">&#91;38&#93;</a></sup> offers the fastest, automated way to collect height or distance information. lidar or laser for height measurement of buildings is becoming very promising.<sup id="cite_ref-39" class="reference"><a href="#cite_note-39">&#91;39&#93;</a></sup> Commercial applications of both airborne lidar and ground laser scanning technology have proven to be fast and accurate methods for building height extraction. The building extraction task is needed to determine building locations, ground elevation, orientations, building size, rooftop heights, etc. Most buildings are described to sufficient details in terms of general polyhedra, i.e., their boundaries can be represented by a set of planar surfaces and straight lines. Further processing such as expressing building footprints as polygons is used for data storing in GIS databases.
</p><p>Using laser scans and images taken from ground level and a bird's-eye perspective, Fruh and Zakhor present an approach to automatically create textured 3D city models. This approach involves registering and merging the detailed facade models with a complementary airborne model. The airborne modeling process generates a half-meter resolution model with a bird's-eye view of the entire area, containing terrain profile and building tops. Ground-based modeling process results in a detailed model of the building facades. Using the DSM obtained from airborne laser scans, they localize the acquisition vehicle and register the ground-based facades to the airborne model by means of Monte Carlo localization (MCL). Finally, the two models are merged with different resolutions to obtain a 3D model.
</p><p>Using an airborne laser altimeter, Haala, Brenner and Anders combined height data with the existing ground plans of buildings. The ground plans of buildings had already been acquired either in analog form by maps and plans or digitally in a 2D GIS. The project was done in order to enable an automatic data capture by the integration of these different types of information. Afterwards virtual reality city models are generated in the project by texture processing, e.g. by mapping of terrestrial images. The project demonstrated the feasibility of rapid acquisition of 3D urban GIS. Ground plans proved are another very important source of information for 3D building reconstruction. Compared to results of automatic procedures, these ground plans proved more reliable since they contain aggregated information which has been made explicit by human interpretation. For this reason, ground plans, can considerably reduce costs in a reconstruction project. An example of existing ground plan data usable in building reconstruction is the <a href="/wiki/Digital_Cadastral_DataBase" title="Digital Cadastral DataBase">Digital Cadastral map</a>, which provides information on the distribution of property, including the borders of all agricultural areas and the ground plans of existing buildings. Additionally information as street names and the usage of buildings (e.g. garage, residential building, office block, industrial building, church) is provided in the form of text symbols. At the moment the Digital Cadastral map is built up as a database covering an area, mainly composed by digitizing preexisting maps or plans.
</p>
<h3><span class="mw-headline" id="Cost">Cost</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=19" title="Edit section: Cost"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li>Terrestrial laser scan devices (pulse or phase devices) + processing software generally start at a price of €150,000. Some less precise devices (as the Trimble VX) cost around €75,000.</li>
<li>Terrestrial lidar systems cost around €300,000.</li>
<li>Systems using regular still cameras mounted on RC helicopters (<a href="/wiki/Photogrammetry" title="Photogrammetry">Photogrammetry</a>) are also possible, and cost around €25,000. Systems that use still cameras with balloons are even cheaper (around €2,500), but require additional manual processing. As the manual processing takes around one month of labor for every day of taking pictures, this is still an expensive solution in the long run.</li>
<li>Obtaining satellite images is also an expensive endeavor. High resolution stereo images (0.5&#160;m resolution) cost around €11,000. Image satellites include Quikbird, Ikonos. High resolution monoscopic images cost around €5,500. Somewhat lower resolution images (e.g. from the CORONA satellite; with a 2&#160;m resolution) cost around €1,000 per 2 images. Note that Google Earth images are too low in resolution to make an accurate 3D model.<sup id="cite_ref-40" class="reference"><a href="#cite_note-40">&#91;40&#93;</a></sup></li></ul>
<h2><span class="mw-headline" id="Reconstruction">Reconstruction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=20" title="Edit section: Reconstruction"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/3D_reconstruction" title="3D reconstruction">3D reconstruction</a></div>
<h3><span class="mw-headline" id="From_point_clouds">From point clouds</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=21" title="Edit section: From point clouds"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The <a href="/wiki/Point_cloud" title="Point cloud">point clouds</a> produced by 3D scanners and 3D imaging can be used directly for measurement and visualisation in the architecture and construction world.
</p>
<h3><span class="mw-headline" id="From_models">From models</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=22" title="Edit section: From models"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Most applications, however, use instead polygonal 3D models, <a href="/wiki/NURBS" class="mw-redirect" title="NURBS">NURBS</a> surface models, or editable feature-based CAD models (aka <a href="/wiki/Solid_modeling" title="Solid modeling">solid models</a>).
</p>
<ul><li><a href="/wiki/Polygon_mesh" title="Polygon mesh">Polygon mesh</a> models: In a polygonal representation of a shape, a curved surface is modeled as many small faceted flat surfaces (think of a sphere modeled as a disco ball). Polygon models—also called Mesh models, are useful for visualisation, for some <a href="/wiki/Computer-aided_manufacturing" title="Computer-aided manufacturing">CAM</a> (i.e., machining), but are generally "heavy" ( i.e., very large data sets), and are relatively un-editable in this form. Reconstruction to polygonal model involves finding and connecting adjacent points with straight lines in order to create a continuous surface. Many applications, both free and nonfree, are available for this purpose (e.g. <a href="/wiki/GigaMesh_Software_Framework" title="GigaMesh Software Framework">GigaMesh</a>, <a href="/wiki/MeshLab" title="MeshLab">MeshLab</a>, PointCab, kubit PointCloud for AutoCAD, <a rel="nofollow" class="external text" href="https://gexcel.it/it/software/reconstructor">Reconstructor</a>, imagemodel, PolyWorks, Rapidform, <a href="/wiki/Geomagic" title="Geomagic">Geomagic</a>, Imageware, <a href="/wiki/Rhino_3D" class="mw-redirect" title="Rhino 3D">Rhino 3D</a> etc.).</li>
<li><a href="/wiki/Freeform_surface_modelling" title="Freeform surface modelling">Surface models</a>: The next level of sophistication in modeling involves using a quilt of <i>curved</i> surface patches to model the shape. These might be NURBS, TSplines or other curved representations of curved topology. Using NURBS, the spherical shape becomes a true mathematical sphere. Some applications offer patch layout by hand but the best in class offer both automated patch layout and manual layout. These patches have the advantage of being lighter and more manipulable when exported to CAD. Surface models are somewhat editable, but only in a sculptural sense of pushing and pulling to deform the surface. This representation lends itself well to modelling organic and artistic shapes. Providers of surface modellers include Rapidform, <a href="/wiki/Geomagic" title="Geomagic">Geomagic</a>, <a href="/wiki/Rhino_3D" class="mw-redirect" title="Rhino 3D">Rhino 3D</a>, Maya, T Splines etc.</li>
<li><a href="/wiki/Solid_modelling" class="mw-redirect" title="Solid modelling">Solid CAD models</a>: From an engineering/manufacturing perspective, the ultimate representation of a digitised shape is the editable, parametric CAD model. In CAD, the sphere is described by parametric features which are easily edited by changing a value (e.g., centre point and radius).</li></ul>
<p>These CAD models describe not simply the envelope or shape of the object, but CAD models also embody the "design intent" (i.e., critical features and their relationship to other features). An example of design intent not evident in the shape alone might be a brake drum's lug bolts, which must be concentric with the hole in the centre of the drum. This knowledge would drive the sequence and method of creating the CAD model; a designer with an awareness of this relationship would not design the lug bolts referenced to the outside diameter, but instead, to the center. A modeler creating a CAD model will want to include both Shape and design intent in the complete CAD model.
</p><p>Vendors offer different approaches to getting to the parametric CAD model. Some export the NURBS surfaces and leave it to the CAD designer to complete the model in CAD (e.g., <a href="/wiki/Geomagic" title="Geomagic">Geomagic</a>, Imageware, <a href="/wiki/Rhino_3D" class="mw-redirect" title="Rhino 3D">Rhino 3D</a>). Others use the scan data to create an editable and verifiable feature based model that is imported into CAD with full feature tree intact, yielding a complete, native CAD model, capturing both shape and design intent (e.g. <a href="/wiki/Geomagic" title="Geomagic">Geomagic</a>, Rapidform). For instance, the market offers various plug-ins for established CAD-programs, such as SolidWorks. Xtract3D, DezignWorks and Geomagic for SolidWorks allow manipulating a 3D scan directly inside <a href="/wiki/SolidWorks" title="SolidWorks">SolidWorks</a>. Still other CAD applications are robust enough to manipulate limited points or polygon models within the CAD environment (e.g., <a href="/wiki/CATIA" title="CATIA">CATIA</a>, <a href="/wiki/AutoCAD" title="AutoCAD">AutoCAD</a>, <a href="/wiki/Revit" class="mw-redirect" title="Revit">Revit</a>).
</p>
<h3><span class="mw-headline" id="From_a_set_of_2D_slices">From a set of 2D slices</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=23" title="Edit section: From a set of 2D slices"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<figure class="mw-default-size mw-halign-right" typeof="mw:File/Thumb"><a href="/wiki/File:CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/d/d7/CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg/220px-CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg" decoding="async" width="220" height="200" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/d7/CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg/330px-CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/d7/CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg/440px-CT_Scan_of_Dale_Mahalko%27s_brain-skull.jpg 2x" data-file-width="994" data-file-height="904" /></a><figcaption>3D reconstruction of the brain and eyeballs from CT scanned DICOM images. In this image, areas with the density of bone or air were made transparent, and the slices stacked up in an approximate free-space alignment. The outer ring of material around the brain are the soft tissues of skin and muscle on the outside of the skull. A black box encloses the slices to provide the black background. Since these are simply 2D images stacked up, when viewed on edge the slices disappear since they have effectively zero thickness. Each DICOM scan represents about 5&#160;mm of material averaged into a thin slice.</figcaption></figure>
<p><a href="/wiki/X-ray_computed_tomography" class="mw-redirect" title="X-ray computed tomography">CT</a>, <a href="/wiki/Industrial_CT_scanning" class="mw-redirect" title="Industrial CT scanning">industrial CT</a>, <a href="/wiki/MRI" class="mw-redirect" title="MRI">MRI</a>, or <a href="/wiki/X-ray_microtomography" title="X-ray microtomography">micro-CT</a> scanners do not produce point clouds but a set of 2D slices (each termed a "tomogram") which are then 'stacked together' to produce a 3D representation. There are several ways to do this depending on the output required:
</p>
<ul><li><a href="/wiki/Volume_rendering" title="Volume rendering">Volume rendering</a>: Different parts of an object usually have different threshold values or greyscale densities. From this, a 3-dimensional model can be constructed and displayed on screen. Multiple models can be constructed from various thresholds, allowing different colours to represent each component of the object. Volume rendering is usually only used for visualisation of the scanned object.</li>
<li><a href="/wiki/Segmentation_(image_processing)" class="mw-redirect" title="Segmentation (image processing)">Image segmentation</a>: Where different structures have similar threshold/greyscale values, it can become impossible to separate them simply by adjusting volume rendering parameters. The solution is called segmentation, a manual or automatic procedure that can remove the unwanted structures from the image. Image segmentation software usually allows export of the segmented structures in CAD or STL format for further manipulation.</li>
<li><a href="/wiki/Image-based_meshing" title="Image-based meshing">Image-based meshing</a>: When using 3D image data for computational analysis (e.g. CFD and FEA), simply segmenting the data and meshing from CAD can become time-consuming, and virtually intractable for the complex topologies typical of image data. The solution is called image-based meshing, an automated process of generating an accurate and realistic geometrical description of the scan data.</li></ul>
<h3><span class="mw-headline" id="From_laser_scans">From laser scans</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=24" title="Edit section: From laser scans"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p><i><a href="/wiki/Laser_scanning" title="Laser scanning">Laser scanning</a></i> describes the general method to sample or scan a surface using <a href="/wiki/Laser" title="Laser">laser</a> technology. Several areas of application exist that mainly differ in the power of the lasers that are used, and in the results of the scanning process. Low laser power is used when the scanned surface doesn't have to be influenced, e.g. when it only has to be digitised. <a href="/wiki/Confocal" title="Confocal">Confocal</a> or <a href="/wiki/Three-dimensional_space" title="Three-dimensional space">3D</a> laser scanning are methods to get information about the scanned surface. Another low-power application uses structured light projection systems for solar cell flatness metrology,<sup id="cite_ref-41" class="reference"><a href="#cite_note-41">&#91;41&#93;</a></sup> enabling stress calculation throughout in excess of 2000 wafers per hour.<sup id="cite_ref-42" class="reference"><a href="#cite_note-42">&#91;42&#93;</a></sup>
</p><p>The laser power used for laser scanning equipment in industrial applications is typically less than 1W. The power level is usually on the order of 200&#160;mW or less but sometimes more.
</p>
<h3><span class="mw-headline" id="From_photographs">From photographs</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=25" title="Edit section: From photographs"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Photogrammetry" title="Photogrammetry">Photogrammetry</a></div>
<p>3D data acquisition and object reconstruction can be performed using stereo image pairs. Stereo photogrammetry or photogrammetry based on a block of overlapped images is the primary approach for 3D mapping and object reconstruction using 2D images. Close-range photogrammetry has also matured to the level where cameras or digital cameras can be used to capture the close-look images of objects, e.g., buildings, and reconstruct them using the very same theory as the aerial photogrammetry. An example of software which could do this is <a href="/wiki/Vexcel" class="mw-redirect" title="Vexcel">Vexcel</a> <a href="/w/index.php?title=FotoG&amp;action=edit&amp;redlink=1" class="new" title="FotoG (page does not exist)">FotoG</a> 5.<sup id="cite_ref-43" class="reference"><a href="#cite_note-43">&#91;43&#93;</a></sup><sup id="cite_ref-44" class="reference"><a href="#cite_note-44">&#91;44&#93;</a></sup> This software has now been replaced by Vexcel <a href="/wiki/GeoSynth" class="mw-redirect" title="GeoSynth">GeoSynth</a>.<sup id="cite_ref-45" class="reference"><a href="#cite_note-45">&#91;45&#93;</a></sup> Another similar software program is <a href="/wiki/Microsoft_Photosynth" class="mw-redirect" title="Microsoft Photosynth">Microsoft Photosynth</a>.<sup id="cite_ref-46" class="reference"><a href="#cite_note-46">&#91;46&#93;</a></sup><sup id="cite_ref-47" class="reference"><a href="#cite_note-47">&#91;47&#93;</a></sup>
</p><p>A semi-automatic method for acquiring 3D topologically structured data from 2D aerial stereo images has been presented by <a href="/wiki/Sisi_Zlatanova" title="Sisi Zlatanova">Sisi Zlatanova</a>.<sup id="cite_ref-48" class="reference"><a href="#cite_note-48">&#91;48&#93;</a></sup> The process involves the manual digitizing of a number of points necessary for automatically reconstructing the 3D objects. Each reconstructed object is validated by superimposition of its wire frame graphics in the stereo model. The topologically structured 3D data is stored in a database and are also used for visualization of the objects. Notable software used for 3D data acquisition using 2D images include e.g. <a href="/wiki/PhotoScan" class="mw-redirect" title="PhotoScan">Agisoft Metashape</a>,<sup id="cite_ref-49" class="reference"><a href="#cite_note-49">&#91;49&#93;</a></sup> <a href="/wiki/RealityCapture" title="RealityCapture">RealityCapture</a>,<sup id="cite_ref-50" class="reference"><a href="#cite_note-50">&#91;50&#93;</a></sup> and ENSAIS Engineering College TIPHON (Traitement d'Image et PHOtogrammétrie Numérique).<sup id="cite_ref-51" class="reference"><a href="#cite_note-51">&#91;51&#93;</a></sup>
</p><p>A method for semi-automatic building extraction together with a concept for storing building models alongside terrain and other topographic data in a topographical information system has been developed by Franz Rottensteiner. His approach was based on the integration of building parameter estimations into the photogrammetry process applying a hybrid modeling scheme. Buildings are decomposed into a set of simple primitives that are reconstructed individually and are then combined by Boolean operators. The internal data structure of both the primitives and the compound building models are based on the boundary representation methods<sup id="cite_ref-52" class="reference"><a href="#cite_note-52">&#91;52&#93;</a></sup><sup id="cite_ref-53" class="reference"><a href="#cite_note-53">&#91;53&#93;</a></sup>
</p><p>Multiple images are used in Zhang's<sup id="cite_ref-54" class="reference"><a href="#cite_note-54">&#91;54&#93;</a></sup> approach to surface reconstruction from multiple images. A central idea is to explore the integration of both 3D stereo data and 2D calibrated images. This approach is motivated by the fact that only robust and accurate feature points that survived the geometry scrutiny of multiple images are reconstructed in space. The density insufficiency and the inevitable holes in the stereo data should then be filled in by using information from multiple images. The idea is thus to first construct small surface patches from stereo points, then to progressively propagate only reliable patches in their neighborhood from images into the whole surface using a best-first strategy. The problem thus reduces to searching for an optimal local surface patch going through a given set of stereo points from images.
</p><p>Multi-spectral images are also used for 3D building detection. The first and last pulse data and the normalized difference vegetation index are used in the process.<sup id="cite_ref-55" class="reference"><a href="#cite_note-55">&#91;55&#93;</a></sup>
</p><p>New measurement techniques are also employed to obtain measurements of and between objects from single images by using the projection, or the shadow as well as their combination. This technology is gaining attention given its fast processing time, and far lower cost than stereo measurements.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (April 2019)">citation needed</span></a></i>&#93;</sup>
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=26" title="Edit section: Applications"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Space_experiments">Space experiments</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=27" title="Edit section: Space experiments"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>3D scanning technology has been used to scan space rocks for the <a href="/wiki/European_Space_Agency" title="European Space Agency">European Space Agency</a>.<sup id="cite_ref-56" class="reference"><a href="#cite_note-56">&#91;56&#93;</a></sup><sup id="cite_ref-57" class="reference"><a href="#cite_note-57">&#91;57&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Construction_industry_and_civil_engineering">Construction industry and civil engineering</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=28" title="Edit section: Construction industry and civil engineering"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li><a href="/wiki/Robotic_control" class="mw-redirect" title="Robotic control">Robotic control</a>: e.g. a laser scanner may function as the "eye" of a robot.<sup id="cite_ref-58" class="reference"><a href="#cite_note-58">&#91;58&#93;</a></sup><sup id="cite_ref-59" class="reference"><a href="#cite_note-59">&#91;59&#93;</a></sup></li>
<li>As-built drawings of bridges, industrial plants, and monuments</li>
<li>Documentation of historical sites<sup id="cite_ref-60" class="reference"><a href="#cite_note-60">&#91;60&#93;</a></sup></li>
<li>Site modelling and lay outing</li>
<li>Quality control</li>
<li>Quantity surveys</li>
<li>Payload monitoring <sup id="cite_ref-61" class="reference"><a href="#cite_note-61">&#91;61&#93;</a></sup></li>
<li>Freeway redesign</li>
<li>Establishing a bench mark of pre-existing shape/state in order to detect structural changes resulting from exposure to extreme loadings such as earthquake, vessel/truck impact or fire.</li>
<li>Create GIS (<a href="/wiki/Geographic_information_system" title="Geographic information system">geographic information system</a>) maps<sup id="cite_ref-Resources2012_62-0" class="reference"><a href="#cite_note-Resources2012-62">&#91;62&#93;</a></sup> and <a href="/wiki/Geomatics" title="Geomatics">geomatics</a>.</li>
<li>Subsurface laser scanning in mines and <a href="/wiki/Karst" title="Karst">karst</a> voids.<sup id="cite_ref-63" class="reference"><a href="#cite_note-63">&#91;63&#93;</a></sup></li>
<li>Forensic documentation<sup id="cite_ref-64" class="reference"><a href="#cite_note-64">&#91;64&#93;</a></sup></li></ul>
<h3><span class="mw-headline" id="Design_process">Design process</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=29" title="Edit section: Design process"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<ul><li>Increasing accuracy working with complex parts and shapes,</li>
<li>Coordinating product design using parts from multiple sources,</li>
<li>Updating old CD scans with those from more current technology,</li>
<li>Replacing missing or older parts,</li>
<li>Creating cost savings by allowing as-built design services, for example in automotive manufacturing plants,</li>
<li>"Bringing the plant to the engineers" with web shared scans, and</li>
<li>Saving travel costs.</li></ul>
<h3><span class="mw-headline" id="Entertainment">Entertainment</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=30" title="Edit section: Entertainment"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>3D scanners are used by the <a href="/wiki/Entertainment_industry" class="mw-redirect" title="Entertainment industry">entertainment industry</a> to create digital 3D models for <a href="/wiki/Movie" class="mw-redirect" title="Movie">movies</a>, <a href="/wiki/Video_game" title="Video game">video games</a> and leisure purposes.<sup id="cite_ref-65" class="reference"><a href="#cite_note-65">&#91;65&#93;</a></sup> They are heavily utilized in <a href="/wiki/Virtual_cinematography" title="Virtual cinematography">virtual cinematography</a>. In cases where a real-world equivalent of a model exists, it is much faster to scan the real-world object than to manually create a model using 3D modeling software. Frequently, artists sculpt physical models of what they want and scan them into digital form rather than directly creating digital models on a computer.
</p>
<h3><span class="mw-headline" id="3D_photography">3D photography</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=31" title="Edit section: 3D photography"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<figure typeof="mw:File/Thumb"><a href="/wiki/File:Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg/500px-Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg" decoding="async" width="500" height="143" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/76/Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg/750px-Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/76/Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg/1000px-Madurodam_Shapeways_3D_selfie_in_1_20_scale_after_a_second_spray_of_varnish_FRD.jpg 2x" data-file-width="6610" data-file-height="1887" /></a><figcaption><a href="/wiki/3D_selfie" title="3D selfie">3D selfie</a> in 1:20 scale printed by <a href="/wiki/Shapeways" title="Shapeways">Shapeways</a> using gypsum-based printing, created by <a href="/wiki/Madurodam" title="Madurodam">Madurodam</a> miniature park from 2D pictures taken at its Fantasitron photo booth</figcaption></figure>
<figure class="mw-default-size" typeof="mw:File/Thumb"><a href="/wiki/File:Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg" class="mw-file-description"><img src="//upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/220px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg" decoding="async" width="220" height="300" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/330px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/51/Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg/440px-Fantasitron_photo_booth_at_Madurodam_can_scan_up_to_two_people_at_a_time_IMG_3797_FRD.jpg 2x" data-file-width="2521" data-file-height="3435" /></a><figcaption>Fantasitron 3D photo booth at <a href="/wiki/Madurodam" title="Madurodam">Madurodam</a></figcaption></figure>
<p>3D scanners are evolving for the use of cameras to represent 3D objects in an accurate manner.<sup id="cite_ref-66" class="reference"><a href="#cite_note-66">&#91;66&#93;</a></sup> Companies are emerging since 2010 that create 3D portraits of people (3D figurines or <a href="/wiki/3D_selfie" title="3D selfie">3D selfie</a>).
</p><p>An augmented reality menu for the Madrid restaurant chain 80 Degrees<sup id="cite_ref-67" class="reference"><a href="#cite_note-67">&#91;67&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Law_enforcement">Law enforcement</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=32" title="Edit section: Law enforcement"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>3D laser scanning is used by the law enforcement agencies around the world. 3D models are used for on-site documentation of:<sup id="cite_ref-68" class="reference"><a href="#cite_note-68">&#91;68&#93;</a></sup>
</p>
<ul><li>Crime scenes</li>
<li>Bullet trajectories</li>
<li>Bloodstain pattern analysis</li>
<li>Accident reconstruction</li>
<li>Bombings</li>
<li>Plane crashes, and more</li></ul>
<h3><span class="mw-headline" id="Reverse_engineering">Reverse engineering</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=33" title="Edit section: Reverse engineering"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/Reverse_engineering" title="Reverse engineering">Reverse engineering</a> of a mechanical component requires a precise digital model of the objects to be reproduced. Rather than a set of points a precise digital model can be represented by a <a href="/wiki/Polygon_mesh" title="Polygon mesh">polygon mesh</a>, a set of flat or curved <a href="/wiki/NURBS" class="mw-redirect" title="NURBS">NURBS</a> surfaces, or ideally for mechanical components, a CAD solid model. A 3D scanner can be used to digitise free-form or gradually changing shaped components as well as prismatic geometries whereas a <a href="/wiki/Coordinate_measuring_machine" class="mw-redirect" title="Coordinate measuring machine">coordinate measuring machine</a> is usually used only to determine simple dimensions of a highly prismatic model. These data points are then processed to create a usable digital model, usually using specialized reverse engineering software.
</p>
<h3><span class="mw-headline" id="Real_estate">Real estate</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=34" title="Edit section: Real estate"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Land or buildings can be scanned into a 3D model, which allows buyers to tour and inspect the property remotely, anywhere, without having to be present at the property.<sup id="cite_ref-69" class="reference"><a href="#cite_note-69">&#91;69&#93;</a></sup> There is already at least one company providing 3D-scanned virtual real estate tours.<sup id="cite_ref-70" class="reference"><a href="#cite_note-70">&#91;70&#93;</a></sup> A typical <a rel="nofollow" class="external text" href="https://my.matterport.com/show/?m=xUYKqYCKQWp">virtual tour</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20170427005543/https://my.matterport.com/show/?m=xUYKqYCKQWp">Archived</a> 2017-04-27 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> would consist of dollhouse view,<sup id="cite_ref-71" class="reference"><a href="#cite_note-71">&#91;71&#93;</a></sup> inside view, as well as a floor plan.
</p>
<h3><span id="Virtual.2Fremote_tourism"></span><span class="mw-headline" id="Virtual/remote_tourism">Virtual/remote tourism</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=35" title="Edit section: Virtual/remote tourism"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The environment at a place of interest can be captured and converted into a 3D model. This model can then be explored by the public, either through a VR interface or a traditional "2D" interface. This allows the user to explore locations which are inconvenient for travel.<sup id="cite_ref-72" class="reference"><a href="#cite_note-72">&#91;72&#93;</a></sup> A group of history students at Vancouver iTech Preparatory Middle School created a Virtual Museum by 3D Scanning more than 100 artifacts.<sup id="cite_ref-73" class="reference"><a href="#cite_note-73">&#91;73&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Cultural_heritage">Cultural heritage</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=36" title="Edit section: Cultural heritage"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>There have been many research projects undertaken via the scanning of historical sites and artifacts both for documentation and analysis purposes.<sup id="cite_ref-74" class="reference"><a href="#cite_note-74">&#91;74&#93;</a></sup> The resulting models can be used for a variety of different analytical approaches.<sup id="cite_ref-75" class="reference"><a href="#cite_note-75">&#91;75&#93;</a></sup><sup id="cite_ref-76" class="reference"><a href="#cite_note-76">&#91;76&#93;</a></sup>
</p><p>The combined use of 3D scanning and <a href="/wiki/3D_printing" title="3D printing">3D printing</a> technologies allows the replication of real objects without the use of traditional <a href="/wiki/Plaster_cast" title="Plaster cast">plaster casting</a> techniques, that in many cases can be too <a href="https://en.wiktionary.org/wiki/invasive" class="extiw" title="wikt:invasive">invasive</a> for being performed on precious or delicate cultural heritage artifacts.<sup id="cite_ref-77" class="reference"><a href="#cite_note-77">&#91;77&#93;</a></sup> In an example of a typical application scenario, a <a href="/wiki/Gargoyle" title="Gargoyle">gargoyle</a> model was digitally acquired using a 3D scanner and the produced 3D data was processed using <a href="/wiki/MeshLab" title="MeshLab">MeshLab</a>. The resulting digital <a href="/wiki/3D_model" class="mw-redirect" title="3D model">3D model</a> was fed to a <a href="/wiki/Rapid_prototyping" title="Rapid prototyping">rapid prototyping</a> machine to create a real resin replica of the original object.
</p><p>Creation of 3D models for Museums and Archaeological artifacts<sup id="cite_ref-78" class="reference"><a href="#cite_note-78">&#91;78&#93;</a></sup><sup id="cite_ref-79" class="reference"><a href="#cite_note-79">&#91;79&#93;</a></sup><sup id="cite_ref-80" class="reference"><a href="#cite_note-80">&#91;80&#93;</a></sup>
</p>
<h4><span class="mw-headline" id="Michelangelo">Michelangelo</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=37" title="Edit section: Michelangelo"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In 1999, two different research groups started scanning Michelangelo's statues. <a href="/wiki/Stanford_University" title="Stanford University">Stanford University</a> with a group led by <a href="/wiki/Marc_Levoy" title="Marc Levoy">Marc Levoy</a><sup id="cite_ref-81" class="reference"><a href="#cite_note-81">&#91;81&#93;</a></sup> used a custom laser triangulation scanner built by <a href="/wiki/Cyberware_(company)" title="Cyberware (company)">Cyberware</a> to scan Michelangelo's statues in Florence, notably the <a href="/wiki/David_(Michelangelo)" title="David (Michelangelo)">David</a>, the Prigioni and the four statues in The Medici Chapel. The scans produced a data point density of one sample per 0.25&#160;mm, detailed enough to see Michelangelo's chisel marks. These detailed scans produced a large amount of data (up to 32 gigabytes) and processing the data from his scans took 5 months. Approximately in the same period a research group from <a href="/wiki/IBM" title="IBM">IBM</a>, led by <a href="/wiki/Holly_Rushmeier" title="Holly Rushmeier">H. Rushmeier</a> and F. Bernardini scanned the <a href="/wiki/The_Deposition_(Michelangelo)" title="The Deposition (Michelangelo)">Pietà of Florence</a> acquiring both geometric and colour details. The digital model, result of the Stanford scanning campaign, was thoroughly used in the 2004 subsequent restoration of the statue.<sup id="cite_ref-82" class="reference"><a href="#cite_note-82">&#91;82&#93;</a></sup>
</p>
<h4><span class="mw-headline" id="Monticello">Monticello</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=38" title="Edit section: Monticello"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In 2002, David Luebke, et al. scanned Thomas Jefferson's Monticello.<sup id="cite_ref-83" class="reference"><a href="#cite_note-83">&#91;83&#93;</a></sup> A commercial time of flight laser scanner, the DeltaSphere 3000, was used. The scanner data was later combined with colour data from digital photographs to create the Virtual Monticello, and the Jefferson's Cabinet exhibits in the New Orleans Museum of Art in 2003. The Virtual Monticello exhibit simulated a window looking into Jefferson's Library. The exhibit consisted of a rear projection display on a wall and a pair of stereo glasses for the viewer. The glasses, combined with polarised projectors, provided a 3D effect. Position tracking hardware on the glasses allowed the display to adapt as the viewer moves around, creating the illusion that the display is actually a hole in the wall looking into Jefferson's Library. The Jefferson's Cabinet exhibit was a barrier stereogram (essentially a non-active hologram that appears different from different angles) of Jefferson's Cabinet.
</p>
<h4><span class="mw-headline" id="Cuneiform_tablets">Cuneiform tablets</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=39" title="Edit section: Cuneiform tablets"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The first 3D models of <a href="/wiki/Cuneiform" title="Cuneiform">cuneiform</a> tablets were acquired in Germany in 2000.<sup id="cite_ref-hetiter3d_84-0" class="reference"><a href="#cite_note-hetiter3d-84">&#91;84&#93;</a></sup> In 2003 the so-called <i>Digital <a href="/wiki/Hammurabi" title="Hammurabi">Hammurabi</a> project</i> acquired cuneiform tablets with a laser triangulation scanner using a regular grid pattern having a resolution of 0.025&#160;mm (0.00098&#160;in).<sup id="cite_ref-DigitalHammurabi_85-0" class="reference"><a href="#cite_note-DigitalHammurabi-85">&#91;85&#93;</a></sup> With the use of high-resolution 3D-scanners by the <a href="/wiki/Heidelberg_University" title="Heidelberg University">Heidelberg University</a> for tablet acquisition in 2009 the development of the <a href="/wiki/GigaMesh_Software_Framework" title="GigaMesh Software Framework">GigaMesh Software Framework</a> began to visualize and extract cuneiform characters from 3D-models.<sup id="cite_ref-GigaMesh_2010_86-0" class="reference"><a href="#cite_note-GigaMesh_2010-86">&#91;86&#93;</a></sup> It was used to process ca. 2.000 3D-digitized tablets of the <a href="/w/index.php?title=Hilprecht_Collection&amp;action=edit&amp;redlink=1" class="new" title="Hilprecht Collection (page does not exist)">Hilprecht Collection</a> in <a href="/wiki/Jena" title="Jena">Jena</a> to create an Open Access benchmark dataset<sup id="cite_ref-HeiCuBeDa_Hilprecht_87-0" class="reference"><a href="#cite_note-HeiCuBeDa_Hilprecht-87">&#91;87&#93;</a></sup> and an annotated collection<sup id="cite_ref-HeiCu3Da_Hilprecht_88-0" class="reference"><a href="#cite_note-HeiCu3Da_Hilprecht-88">&#91;88&#93;</a></sup> of 3D-models of tablets freely available under <a href="/wiki/CC_BY" class="mw-redirect" title="CC BY">CC BY</a> licenses.<sup id="cite_ref-ICDAR19_89-0" class="reference"><a href="#cite_note-ICDAR19-89">&#91;89&#93;</a></sup>
</p>
<h4><span class="mw-headline" id="Kasubi_Tombs">Kasubi Tombs</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=40" title="Edit section: Kasubi Tombs"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>A 2009 <a href="/wiki/CyArk" title="CyArk">CyArk</a> 3D scanning project at Uganda's historic <a href="/wiki/Kasubi_Tombs" title="Kasubi Tombs">Kasubi Tombs</a>, a <a href="/wiki/UNESCO_World_Heritage_Site" class="mw-redirect" title="UNESCO World Heritage Site">UNESCO World Heritage Site</a>, using a Leica HDS 4500, produced detailed architectural models of Muzibu Azaala Mpanga, the main building at the complex and tomb of the <a href="/wiki/Kabaka_of_Buganda" title="Kabaka of Buganda">Kabakas</a> (Kings) of Uganda. A fire on March 16, 2010, burned down much of the Muzibu Azaala Mpanga structure, and reconstruction work is likely to lean heavily upon the dataset produced by the 3D scan mission.<sup id="cite_ref-90" class="reference"><a href="#cite_note-90">&#91;90&#93;</a></sup>
</p>
<h4><span id=".22Plastico_di_Roma_antica.22"></span><span class="mw-headline" id="&quot;Plastico_di_Roma_antica&quot;">"Plastico di Roma antica"</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=41" title="Edit section: &quot;Plastico di Roma antica&quot;"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>In 2005, Gabriele Guidi, et al. scanned the "Plastico di Roma antica",<sup id="cite_ref-91" class="reference"><a href="#cite_note-91">&#91;91&#93;</a></sup> a model of Rome created in the last century. Neither the triangulation method, nor the time of flight method satisfied the requirements of this project because the item to be scanned was both large and contained small details. They found though, that a modulated light scanner was able to provide both the ability to scan an object the size of the model and the accuracy that was needed. The modulated light scanner was supplemented by a triangulation scanner which was used to scan some parts of the model.
</p>
<h4><span class="mw-headline" id="Other_projects">Other projects</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=42" title="Edit section: Other projects"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The 3D Encounters Project at the <a href="/wiki/Petrie_Museum_of_Egyptian_Archaeology" title="Petrie Museum of Egyptian Archaeology">Petrie Museum of Egyptian Archaeology</a> aims to use 3D laser scanning to create a high quality 3D image library of artefacts and enable digital travelling exhibitions of fragile Egyptian artefacts, <a href="/wiki/English_Heritage" title="English Heritage">English Heritage</a> has investigated the use of 3D laser scanning for a wide range of applications to gain archaeological and condition data, and the <a href="/wiki/National_Conservation_Centre" title="National Conservation Centre">National Conservation Centre</a> in Liverpool has also produced 3D laser scans on commission, including portable object and in situ scans of archaeological sites.<sup id="cite_ref-92" class="reference"><a href="#cite_note-92">&#91;92&#93;</a></sup> The <a href="/wiki/Smithsonian_Institution" title="Smithsonian Institution">Smithsonian Institution</a> has a project called <a rel="nofollow" class="external text" href="http://3d.si.edu/">Smithsonian X 3D</a> notable for the breadth of types of 3D objects they are attempting to scan. These include small objects such as insects and flowers, to human sized objects such as <a href="/wiki/Amelia_Earhart" title="Amelia Earhart">Amelia Earhart</a>'s Flight Suit to room sized objects such as the <a href="/wiki/USS_Philadelphia_(1776)" title="USS Philadelphia (1776)">Gunboat Philadelphia</a> to historic sites such as <a href="/wiki/Liang_Bua" title="Liang Bua">Liang Bua</a> in Indonesia. Also of note the data from these scans is being made available to the public for free and downloadable in several data formats.
</p>
<h3><span id="Medical_CAD.2FCAM"></span><span class="mw-headline" id="Medical_CAD/CAM">Medical CAD/CAM</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=43" title="Edit section: Medical CAD/CAM"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>3D scanners are used to capture the 3D shape of a patient in <a href="/wiki/Orthotics" title="Orthotics">orthotics</a> and <a href="/wiki/Dentistry" title="Dentistry">dentistry</a>. It gradually supplants tedious plaster cast. CAD/CAM software are then used to design and manufacture the <a href="/wiki/Orthosis" class="mw-redirect" title="Orthosis">orthosis</a>, <a href="/wiki/Prosthesis" title="Prosthesis">prosthesis</a><sup id="cite_ref-93" class="reference"><a href="#cite_note-93">&#91;93&#93;</a></sup> or <a href="/wiki/Dental_implants" class="mw-redirect" title="Dental implants">dental implants</a>.
</p><p>Many chairside dental CAD/CAM systems and dental laboratory CAD/CAM systems use 3D scanner technologies to capture the 3D surface of a dental preparation (either <i>in vivo</i> or <i>in vitro</i>), in order to produce a restoration digitally using CAD software and ultimately produce the final restoration using a CAM technology (such as a CNC milling machine, or 3D printer). The chairside systems are designed to facilitate the 3D scanning of a preparation <i>in vivo</i> and produce the restoration (such as a Crown, Onlay, Inlay or Veneer).
</p><p>Creation of 3D models for anatomy and biology education<sup id="cite_ref-94" class="reference"><a href="#cite_note-94">&#91;94&#93;</a></sup><sup id="cite_ref-95" class="reference"><a href="#cite_note-95">&#91;95&#93;</a></sup> and  cadaver models for educational <a href="/wiki/Neurosurgery" title="Neurosurgery">neurosurgical</a> simulations.<sup id="cite_ref-96" class="reference"><a href="#cite_note-96">&#91;96&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Quality_assurance_and_industrial_metrology">Quality assurance and industrial metrology</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=44" title="Edit section: Quality assurance and industrial metrology"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h3>
<p>The digitalisation of real-world objects is of vital importance in various application domains. This method is especially applied in industrial quality assurance to measure the geometric dimension accuracy. Industrial processes such as assembly are complex, highly automated and typically based on CAD (computer-aided design) data. The problem is that the same degree of automation is also required for quality assurance. It is, for example, a very complex task to assemble a modern car, since it consists of many parts that must fit together at the very end of the production line. The optimal performance of this process is guaranteed by quality assurance systems. Especially the geometry of the metal parts must be checked in order to assure that they have the correct dimensions, fit together and finally work reliably.
</p><p>Within highly automated processes, the resulting geometric measures are transferred to machines that manufacture the desired objects. Due to mechanical uncertainties and abrasions, the result may differ from its digital nominal. In order to automatically capture and evaluate these deviations, the manufactured part must be digitised as well. For this purpose, 3D scanners are applied to generate point samples from the object's surface which are finally compared against the nominal data.<sup id="cite_ref-97" class="reference"><a href="#cite_note-97">&#91;97&#93;</a></sup>
</p><p>The process of comparing 3D data against a CAD model is referred to as CAD-Compare, and can be a useful technique for applications such as determining wear patterns on moulds and tooling, determining accuracy of final build, analysing gap and flush, or analysing highly complex sculpted surfaces. At present, laser triangulation scanners, structured light and contact scanning are the predominant technologies employed for industrial purposes, with contact scanning remaining the slowest, but overall most accurate option. Nevertheless, 3D scanning technology offers distinct advantages compared to traditional touch probe measurements. White-light or laser scanners accurately digitize objects all around, capturing fine details and freeform surfaces without reference points or spray. The entire surface is covered at record speed without the risk of damaging the part. Graphic comparison charts illustrate geometric deviations of full object level, providing deeper insights into potential causes.<sup id="cite_ref-98" class="reference"><a href="#cite_note-98">&#91;98&#93;</a></sup>
<sup id="cite_ref-99" class="reference"><a href="#cite_note-99">&#91;99&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Object_reconstruction">Object reconstruction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=45" title="Edit section: Object reconstruction"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/3D_reconstruction" title="3D reconstruction">3D reconstruction</a></div>
<link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1033289096"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/3D_reconstruction_from_multiple_images" title="3D reconstruction from multiple images">3D reconstruction from multiple images</a></div>
<p>After the data has been collected, the acquired (and sometimes already processed) data from images or sensors needs to be reconstructed. This may be done in the same program or in some cases, the 3D data needs to be exported and imported into another program for further refining, and/or to add additional data. Such additional data could be GPS-location data. After the reconstruction, the data might be directly implemented into a local (GIS) map<sup id="cite_ref-100" class="reference"><a href="#cite_note-100">&#91;100&#93;</a></sup><sup id="cite_ref-101" class="reference"><a href="#cite_note-101">&#91;101&#93;</a></sup> or a worldwide map such as <a href="/wiki/Google_Earth" title="Google Earth">Google Earth</a> or <a href="/wiki/Flyover_(Apple_Maps)" title="Flyover (Apple Maps)">Apple Maps</a>.
</p>
<h2><span class="mw-headline" id="Software">Software</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=46" title="Edit section: Software"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Several software packages are used in which the acquired (and sometimes already processed) data from images or sensors is imported. Notable software packages include:<sup id="cite_ref-102" class="reference"><a href="#cite_note-102">&#91;102&#93;</a></sup>
</p>
<ul><li><a href="/wiki/Qlone_(software)" class="mw-redirect" title="Qlone (software)">Qlone</a></li>
<li><a href="/wiki/3DF_Zephyr" title="3DF Zephyr">3DF Zephyr</a></li>
<li><a href="/wiki/Canoma" title="Canoma">Canoma</a></li>
<li><a href="/wiki/Leica_Photogrammetry_Suite" class="mw-redirect" title="Leica Photogrammetry Suite">Leica Photogrammetry Suite</a></li>
<li><a href="/wiki/MeshLab" title="MeshLab">MeshLab</a></li>
<li><a href="/wiki/MountainsMap" title="MountainsMap"> MountainsMap SEM</a> (microscopy applications only)</li>
<li><a href="/wiki/PhotoModeler" title="PhotoModeler">PhotoModeler</a></li>
<li><a href="/wiki/SketchUp" title="SketchUp">SketchUp</a></li>
<li><a href="/wiki/Tomviz" title="Tomviz">tomviz</a></li></ul>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=47" title="Edit section: See also"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/3D_computer_graphics_software" class="mw-redirect" title="3D computer graphics software">3D computer graphics software</a></li>
<li><a href="/wiki/3D_printing" title="3D printing">3D printing</a></li>
<li><a href="/wiki/3D_reconstruction" title="3D reconstruction">3D reconstruction</a></li>
<li><a href="/wiki/3D_selfie" title="3D selfie">3D selfie</a></li>
<li><a href="/wiki/Angle-sensitive_pixel" title="Angle-sensitive pixel">Angle-sensitive pixel</a></li>
<li><a href="/wiki/Depth_map" title="Depth map">Depth map</a></li>
<li><a href="/wiki/Digitization" title="Digitization">Digitization</a></li>
<li><a href="/wiki/Epipolar_geometry" title="Epipolar geometry">Epipolar geometry</a></li>
<li><a href="/wiki/Full_body_scanner" title="Full body scanner">Full body scanner</a></li>
<li><a href="/wiki/Image_reconstruction" class="mw-redirect" title="Image reconstruction">Image reconstruction</a></li>
<li><a href="/wiki/Light-field_camera" class="mw-redirect" title="Light-field camera">Light-field camera</a></li>
<li><a href="/wiki/Photogrammetry" title="Photogrammetry">Photogrammetry</a></li>
<li><a href="/wiki/Range_imaging" title="Range imaging">Range imaging</a></li>
<li><a href="/wiki/Remote_sensing" title="Remote sensing">Remote sensing</a></li>
<li><a href="/wiki/Replicator_(Star_Trek)" title="Replicator (Star Trek)">Replicator</a></li>
<li><a href="/wiki/Structured-light_3D_scanner" title="Structured-light 3D scanner">Structured-light 3D scanner</a></li>
<li><a href="/wiki/Thingiverse" title="Thingiverse">Thingiverse</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=3D_scanning&amp;action=edit&amp;section=48" title="Edit section: References"><span>edit</span></a><span class="mw-editsection-bracket">]</span></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1217336898">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class="reflist reflist-columns references-column-width" style="column-width: 30em;">
<ol class="references">
<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><style data-mw-deduplicate="TemplateStyles:r1215172403">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a{background-size:contain}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a{background-size:contain}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a{background-size:contain}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:#d33}.mw-parser-output .cs1-visible-error{color:#d33}.mw-parser-output .cs1-maint{display:none;color:#2C882D;margin-left:0.3em}.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911F}html.skin-theme-clientpref-night .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-night .mw-parser-output .cs1-hidden-error{color:#f8a397}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-visible-error,html.skin-theme-clientpref-os .mw-parser-output .cs1-hidden-error{color:#f8a397}html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911F}}</style><cite id="CITEREFIzadiDavisonFitzgibbonKim2011" class="citation book cs1">Izadi, Shahram; Davison, Andrew; Fitzgibbon, Andrew; Kim, David; Hilliges, Otmar; Molyneaux, David; Newcombe, Richard; Kohli, Pushmeet; Shotton, Jamie; Hodges, Steve; Freeman, Dustin (2011). "Kinect <i>Fusion</i>". <i>Proceedings of the 24th annual ACM symposium on User interface software and technology - UIST '11</i>. p.&#160;559. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F2047196.2047270">10.1145/2047196.2047270</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781450307161" title="Special:BookSources/9781450307161"><bdi>9781450307161</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:3345516">3345516</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Kinect+Fusion&amp;rft.btitle=Proceedings+of+the+24th+annual+ACM+symposium+on+User+interface+software+and+technology+-+UIST+%2711&amp;rft.pages=559&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A3345516%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F2047196.2047270&amp;rft.isbn=9781450307161&amp;rft.aulast=Izadi&amp;rft.aufirst=Shahram&amp;rft.au=Davison%2C+Andrew&amp;rft.au=Fitzgibbon%2C+Andrew&amp;rft.au=Kim%2C+David&amp;rft.au=Hilliges%2C+Otmar&amp;rft.au=Molyneaux%2C+David&amp;rft.au=Newcombe%2C+Richard&amp;rft.au=Kohli%2C+Pushmeet&amp;rft.au=Shotton%2C+Jamie&amp;rft.au=Hodges%2C+Steve&amp;rft.au=Freeman%2C+Dustin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMoeslundGranum2001" class="citation journal cs1">Moeslund, Thomas B.; Granum, Erik (1 March 2001). "A Survey of Computer Vision-Based Human Motion Capture". <i>Computer Vision and Image Understanding</i>. <b>81</b> (3): 231–268. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.108.203">10.1.1.108.203</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1006%2Fcviu.2000.0897">10.1006/cviu.2000.0897</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Vision+and+Image+Understanding&amp;rft.atitle=A+Survey+of+Computer+Vision-Based+Human+Motion+Capture&amp;rft.volume=81&amp;rft.issue=3&amp;rft.pages=231-268&amp;rft.date=2001-03-01&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.108.203%23id-name%3DCiteSeerX&amp;rft_id=info%3Adoi%2F10.1006%2Fcviu.2000.0897&amp;rft.aulast=Moeslund&amp;rft.aufirst=Thomas+B.&amp;rft.au=Granum%2C+Erik&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWandAdamsOvsjanikovBerner2009" class="citation journal cs1">Wand, Michael; Adams, Bart; Ovsjanikov, Maksim; Berner, Alexander; Bokeloh, Martin; Jenke, Philipp; Guibas, Leonidas; Seidel, Hans-Peter; Schilling, Andreas (April 2009). "Efficient reconstruction of nonrigid shape and motion from real-time 3D scanner data". <i>ACM Transactions on Graphics</i>. <b>28</b> (2): 1–15. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.230.1675">10.1.1.230.1675</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1516522.1516526">10.1145/1516522.1516526</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:9881027">9881027</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Transactions+on+Graphics&amp;rft.atitle=Efficient+reconstruction+of+nonrigid+shape+and+motion+from+real-time+3D+scanner+data&amp;rft.volume=28&amp;rft.issue=2&amp;rft.pages=1-15&amp;rft.date=2009-04&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.230.1675%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A9881027%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F1516522.1516526&amp;rft.aulast=Wand&amp;rft.aufirst=Michael&amp;rft.au=Adams%2C+Bart&amp;rft.au=Ovsjanikov%2C+Maksim&amp;rft.au=Berner%2C+Alexander&amp;rft.au=Bokeloh%2C+Martin&amp;rft.au=Jenke%2C+Philipp&amp;rft.au=Guibas%2C+Leonidas&amp;rft.au=Seidel%2C+Hans-Peter&amp;rft.au=Schilling%2C+Andreas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBiswasBasu2011" class="citation book cs1">Biswas, K. K.; Basu, Saurav Kumar (2011). "Gesture recognition using Microsoft Kinect®". <i>The 5th International Conference on Automation, Robotics and Applications</i>. pp.&#160;100–103. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICARA.2011.6144864">10.1109/ICARA.2011.6144864</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4577-0330-0" title="Special:BookSources/978-1-4577-0330-0"><bdi>978-1-4577-0330-0</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:8464855">8464855</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Gesture+recognition+using+Microsoft+Kinect%C2%AE&amp;rft.btitle=The+5th+International+Conference+on+Automation%2C+Robotics+and+Applications&amp;rft.pages=100-103&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8464855%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FICARA.2011.6144864&amp;rft.isbn=978-1-4577-0330-0&amp;rft.aulast=Biswas&amp;rft.aufirst=K.+K.&amp;rft.au=Basu%2C+Saurav+Kumar&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKimChenCho2018" class="citation journal cs1">Kim, Pileun; Chen, Jingdao; Cho, Yong K. (May 2018). <a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.autcon.2018.01.009">"SLAM-driven robotic mapping and registration of 3D point clouds"</a>. <i>Automation in Construction</i>. <b>89</b>: 38–48. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.autcon.2018.01.009">10.1016/j.autcon.2018.01.009</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Automation+in+Construction&amp;rft.atitle=SLAM-driven+robotic+mapping+and+registration+of+3D+point+clouds&amp;rft.volume=89&amp;rft.pages=38-48&amp;rft.date=2018-05&amp;rft_id=info%3Adoi%2F10.1016%2Fj.autcon.2018.01.009&amp;rft.aulast=Kim&amp;rft.aufirst=Pileun&amp;rft.au=Chen%2C+Jingdao&amp;rft.au=Cho%2C+Yong+K.&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1016%252Fj.autcon.2018.01.009&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFScott2018" class="citation web cs1">Scott, Clare (2018-04-19). <a rel="nofollow" class="external text" href="https://3dprint.com/210822/thor3d-scanner-facial-prosthetics/">"3D Scanning and 3D Printing Allow for Production of Lifelike Facial Prosthetics"</a>. <i>3DPrint.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=3DPrint.com&amp;rft.atitle=3D+Scanning+and+3D+Printing+Allow+for+Production+of+Lifelike+Facial+Prosthetics&amp;rft.date=2018-04-19&amp;rft.aulast=Scott&amp;rft.aufirst=Clare&amp;rft_id=https%3A%2F%2F3dprint.com%2F210822%2Fthor3d-scanner-facial-prosthetics%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFO&#39;Neal2015" class="citation web cs1">O'Neal, Bridget (2015-02-19). <a rel="nofollow" class="external text" href="https://3dprint.com/45659/cyark-500-challenge-artec-scan/">"CyArk 500 Challenge Gains Momentum in Preserving Cultural Heritage with Artec 3D Scanning Technology"</a>. <i>3DPrint.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=3DPrint.com&amp;rft.atitle=CyArk+500+Challenge+Gains+Momentum+in+Preserving+Cultural+Heritage+with+Artec+3D+Scanning+Technology&amp;rft.date=2015-02-19&amp;rft.aulast=O%27Neal&amp;rft.aufirst=Bridget&amp;rft_id=https%3A%2F%2F3dprint.com%2F45659%2Fcyark-500-challenge-artec-scan%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFausto_Bernardini,_Holly_E._Rushmeier2002" class="citation journal cs1">Fausto Bernardini, <a href="/wiki/Holly_Rushmeier" title="Holly Rushmeier">Holly E. Rushmeier</a> (2002). "The 3D Model Acquisition Pipeline". <i>Computer Graphics Forum</i>. <b>21</b> (2): 149–172. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.94.7486">10.1.1.94.7486</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1111%2F1467-8659.00574">10.1111/1467-8659.00574</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:15779281">15779281</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Graphics+Forum&amp;rft.atitle=The+3D+Model+Acquisition+Pipeline&amp;rft.volume=21&amp;rft.issue=2&amp;rft.pages=149-172&amp;rft.date=2002&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.94.7486%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A15779281%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1111%2F1467-8659.00574&amp;rft.au=Fausto+Bernardini%2C+Holly+E.+Rushmeier&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://matterandform.net/blog/how-do-3d-scanners-work">"Matter and Form - 3D Scanning Hardware &amp; Software"</a>. <i>matterandform.net</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2020-04-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=matterandform.net&amp;rft.atitle=Matter+and+Form+-+3D+Scanning+Hardware+%26+Software&amp;rft_id=https%3A%2F%2Fmatterandform.net%2Fblog%2Fhow-do-3d-scanners-work&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFOR3D" class="citation web cs1">OR3D. <a rel="nofollow" class="external text" href="https://www.or3d.co.uk/knowledge-base/what-is-3d-scanning/">"What is 3D Scanning? - Scanning Basics and Devices"</a>. <i>OR3D</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2020-04-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=OR3D&amp;rft.atitle=What+is+3D+Scanning%3F+-+Scanning+Basics+and+Devices&amp;rft.au=OR3D&amp;rft_id=https%3A%2F%2Fwww.or3d.co.uk%2Fknowledge-base%2Fwhat-is-3d-scanning%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span><span class="cs1-maint citation-comment"><code class="cs1-code">{{<a href="/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: numeric names: authors list (<a href="/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">link</a>)</span></span>
</li>
<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.aniwaa.com/best-3d-scanner/">"3D scanning technologies - what is 3D scanning and how does it work?"</a>. <i>Aniwaa</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2020-04-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aniwaa&amp;rft.atitle=3D+scanning+technologies+-+what+is+3D+scanning+and+how+does+it+work%3F&amp;rft_id=https%3A%2F%2Fwww.aniwaa.com%2Fbest-3d-scanner%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.laserdesign.com/what-is-3d-scanning">"what is 3d scanning"</a>. <i>laserdesign.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=laserdesign.com&amp;rft.atitle=what+is+3d+scanning&amp;rft_id=https%3A%2F%2Fwww.laserdesign.com%2Fwhat-is-3d-scanning&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHammoudi2011" class="citation thesis cs1">Hammoudi, Karim (2011). <a rel="nofollow" class="external text" href="https://tel.archives-ouvertes.fr/tel-00682442"><i>Contributions to the 3D city modeling&#160;: 3D polyhedral building model reconstruction from aerial images and 3D facade modeling from terrestrial 3D point cloud and images</i></a> (Thesis). <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.472.8586">10.1.1.472.8586</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Contributions+to+the+3D+city+modeling+%3A+3D+polyhedral+building+model+reconstruction+from+aerial+images+and+3D+facade+modeling+from+terrestrial+3D+point+cloud+and+images&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.472.8586%23id-name%3DCiteSeerX&amp;rft.aulast=Hammoudi&amp;rft.aufirst=Karim&amp;rft_id=https%3A%2F%2Ftel.archives-ouvertes.fr%2Ftel-00682442&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPinggera,_P.Breckon,_T.P.Bischof,_H.2012" class="citation book cs1">Pinggera, P.; Breckon, T.P.; Bischof, H. (September 2012). <a rel="nofollow" class="external text" href="https://breckon.org/toby/publications/papers/pinggera12crossspectral.pdf">"On Cross-Spectral Stereo Matching using Dense Gradient Features"</a> <span class="cs1-format">(PDF)</span>. <i>Proc. British Machine Vision Conference</i>. pp.&#160;526.1–526.12. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.5244%2FC.26.103">10.5244/C.26.103</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-901725-46-9" title="Special:BookSources/978-1-901725-46-9"><bdi>978-1-901725-46-9</bdi></a><span class="reference-accessdate">. Retrieved <span class="nowrap">8 March</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=On+Cross-Spectral+Stereo+Matching+using+Dense+Gradient+Features&amp;rft.btitle=Proc.+British+Machine+Vision+Conference&amp;rft.pages=526.1-526.12&amp;rft.date=2012-09&amp;rft_id=info%3Adoi%2F10.5244%2FC.26.103&amp;rft.isbn=978-1-901725-46-9&amp;rft.au=Pinggera%2C+P.&amp;rft.au=Breckon%2C+T.P.&amp;rft.au=Bischof%2C+H.&amp;rft_id=https%3A%2F%2Fbreckon.org%2Ftoby%2Fpublications%2Fpapers%2Fpinggera12crossspectral.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20160303194833/http://www.georgedreher.com/3D_Seismic.html">"Seismic 3D data acquisition"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.georgedreher.com/3D_Seismic.html">the original</a> on 2016-03-03<span class="reference-accessdate">. Retrieved <span class="nowrap">2021-01-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Seismic+3D+data+acquisition&amp;rft_id=http%3A%2F%2Fwww.georgedreher.com%2F3D_Seismic.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20090903062318/http://www.lr.tudelft.nl/live/pagina.jsp?id=17783744-e048-4707-a38a-b3b9e2574d03&amp;lang=en">"Optical and laser remote sensing"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.lr.tudelft.nl/live/pagina.jsp?id=17783744-e048-4707-a38a-b3b9e2574d03&amp;lang=en">the original</a> on 2009-09-03<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Optical+and+laser+remote+sensing&amp;rft_id=http%3A%2F%2Fwww.lr.tudelft.nl%2Flive%2Fpagina.jsp%3Fid%3D17783744-e048-4707-a38a-b3b9e2574d03%26lang%3Den&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBrian_Curless2000" class="citation journal cs1">Brian Curless (November 2000). <a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F345370.345399">"From range scans to 3D models"</a>. <i>ACM SIGGRAPH Computer Graphics</i>. <b>33</b> (4): 38–41. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F345370.345399">10.1145/345370.345399</a></span>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:442358">442358</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+SIGGRAPH+Computer+Graphics&amp;rft.atitle=From+range+scans+to+3D+models&amp;rft.volume=33&amp;rft.issue=4&amp;rft.pages=38-41&amp;rft.date=2000-11&amp;rft_id=info%3Adoi%2F10.1145%2F345370.345399&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A442358%23id-name%3DS2CID&amp;rft.au=Brian+Curless&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1145%252F345370.345399&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFCuiSchuonChanThrun2010" class="citation book cs1">Cui, Yan; Schuon, Sebastian; Chan, Derek; Thrun, Sebastian; Theobalt, Christian (2010). "3D shape scanning with a time-of-flight camera". <i>2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition</i>. pp.&#160;1173–1180. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FCVPR.2010.5540082">10.1109/CVPR.2010.5540082</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4244-6984-0" title="Special:BookSources/978-1-4244-6984-0"><bdi>978-1-4244-6984-0</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:2084943">2084943</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=3D+shape+scanning+with+a+time-of-flight+camera&amp;rft.btitle=2010+IEEE+Computer+Society+Conference+on+Computer+Vision+and+Pattern+Recognition&amp;rft.pages=1173-1180&amp;rft.date=2010&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A2084943%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FCVPR.2010.5540082&amp;rft.isbn=978-1-4244-6984-0&amp;rft.aulast=Cui&amp;rft.aufirst=Yan&amp;rft.au=Schuon%2C+Sebastian&amp;rft.au=Chan%2C+Derek&amp;rft.au=Thrun%2C+Sebastian&amp;rft.au=Theobalt%2C+Christian&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFrancaGazziroIdeSaito2005" class="citation book cs1">Franca, J.G.D.M.; Gazziro, M.A.; Ide, A.N.; Saito, J.H. (2005). "A 3D scanning system based on laser triangulation and variable field of view". <i>IEEE International Conference on Image Processing 2005</i>. pp.&#160;I-425. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICIP.2005.1529778">10.1109/ICIP.2005.1529778</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7803-9134-5" title="Special:BookSources/978-0-7803-9134-5"><bdi>978-0-7803-9134-5</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:17914887">17914887</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=A+3D+scanning+system+based+on+laser+triangulation+and+variable+field+of+view&amp;rft.btitle=IEEE+International+Conference+on+Image+Processing+2005&amp;rft.pages=I-425&amp;rft.date=2005&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A17914887%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FICIP.2005.1529778&amp;rft.isbn=978-0-7803-9134-5&amp;rft.aulast=Franca&amp;rft.aufirst=J.G.D.M.&amp;rft.au=Gazziro%2C+M.A.&amp;rft.au=Ide%2C+A.N.&amp;rft.au=Saito%2C+J.H.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFFrançois_BlaisMichel_PicardGuy_Godin2004" class="citation conference cs1">François Blais; Michel Picard; Guy Godin (6–9 September 2004). "Accurate 3D acquisition of freely moving objects". <i>2nd International Symposium on 3D Data Processing, Visualisation, and Transmission, 3DPVT 2004, Thessaloniki, Greece</i>. Los Alamitos, CA: IEEE Computer Society. pp.&#160;422–9. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-7695-2223-8" title="Special:BookSources/0-7695-2223-8"><bdi>0-7695-2223-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Accurate+3D+acquisition+of+freely+moving+objects&amp;rft.btitle=2nd+International+Symposium+on+3D+Data+Processing%2C+Visualisation%2C+and+Transmission%2C+3DPVT+2004%2C+Thessaloniki%2C+Greece&amp;rft.place=Los+Alamitos%2C+CA&amp;rft.pages=422-9&amp;rft.pub=IEEE+Computer+Society&amp;rft.date=2004-09-06%2F2004-09-09&amp;rft.isbn=0-7695-2223-8&amp;rft.au=Fran%C3%A7ois+Blais&amp;rft.au=Michel+Picard&amp;rft.au=Guy+Godin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGoelLohani2014" class="citation journal cs1">Goel, Salil; Lohani, Bharat (January 2014). "A Motion Correction Technique for Laser Scanning of Moving Objects". <i>IEEE Geoscience and Remote Sensing Letters</i>. <b>11</b> (1): 225–228. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2014IGRSL..11..225G">2014IGRSL..11..225G</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FLGRS.2013.2253444">10.1109/LGRS.2013.2253444</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:20531808">20531808</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Geoscience+and+Remote+Sensing+Letters&amp;rft.atitle=A+Motion+Correction+Technique+for+Laser+Scanning+of+Moving+Objects&amp;rft.volume=11&amp;rft.issue=1&amp;rft.pages=225-228&amp;rft.date=2014-01&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A20531808%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FLGRS.2013.2253444&amp;rft_id=info%3Abibcode%2F2014IGRSL..11..225G&amp;rft.aulast=Goel&amp;rft.aufirst=Salil&amp;rft.au=Lohani%2C+Bharat&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-22"><span class="mw-cite-backlink"><b><a href="#cite_ref-22">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20201208181115/https://virtualtechnology.tech/understanding-technology-how-do-3d-scanners-work/">"Understanding Technology: How Do 3D Scanners Work?"</a>. <i>Virtual Technology</i>. Archived from <a rel="nofollow" class="external text" href="https://virtualtechnology.tech/understanding-technology-how-do-3d-scanners-work/">the original</a> on 8 December 2020<span class="reference-accessdate">. Retrieved <span class="nowrap">8 November</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Virtual+Technology&amp;rft.atitle=Understanding+Technology%3A+How+Do+3D+Scanners+Work%3F&amp;rft_id=https%3A%2F%2Fvirtualtechnology.tech%2Funderstanding-technology-how-do-3d-scanners-work%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFSiratPsaltis1985" class="citation journal cs1">Sirat, Gabriel; Psaltis, Demetri (1 January 1985). <a rel="nofollow" class="external text" href="https://infoscience.epfl.ch/record/158563/files/OL_10_4_Jan1985.pdf">"Conoscopic holography"</a> <span class="cs1-format">(PDF)</span>. <i>Optics Letters</i>. <b>10</b> (1): 4–6. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/1985OptL...10....4S">1985OptL...10....4S</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOL.10.000004">10.1364/OL.10.000004</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/19724327">19724327</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Optics+Letters&amp;rft.atitle=Conoscopic+holography&amp;rft.volume=10&amp;rft.issue=1&amp;rft.pages=4-6&amp;rft.date=1985-01-01&amp;rft_id=info%3Apmid%2F19724327&amp;rft_id=info%3Adoi%2F10.1364%2FOL.10.000004&amp;rft_id=info%3Abibcode%2F1985OptL...10....4S&amp;rft.aulast=Sirat&amp;rft.aufirst=Gabriel&amp;rft.au=Psaltis%2C+Demetri&amp;rft_id=https%3A%2F%2Finfoscience.epfl.ch%2Frecord%2F158563%2Ffiles%2FOL_10_4_Jan1985.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFStroblMairBodenmullerKielhofer2009" class="citation book cs1">Strobl, K. H.; Mair, E.; Bodenmuller, T.; Kielhofer, S.; Sepp, W.; Suppa, M.; Burschka, D.; Hirzinger, G. (2009). "The self-referenced DLR 3D-modeler". <i>2009 IEEE/RSJ International Conference on Intelligent Robots and Systems</i>. pp.&#160;21–28. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FIROS.2009.5354708">10.1109/IROS.2009.5354708</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4244-3803-7" title="Special:BookSources/978-1-4244-3803-7"><bdi>978-1-4244-3803-7</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:3576337">3576337</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=The+self-referenced+DLR+3D-modeler&amp;rft.btitle=2009+IEEE%2FRSJ+International+Conference+on+Intelligent+Robots+and+Systems&amp;rft.pages=21-28&amp;rft.date=2009&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A3576337%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FIROS.2009.5354708&amp;rft.isbn=978-1-4244-3803-7&amp;rft.aulast=Strobl&amp;rft.aufirst=K.+H.&amp;rft.au=Mair%2C+E.&amp;rft.au=Bodenmuller%2C+T.&amp;rft.au=Kielhofer%2C+S.&amp;rft.au=Sepp%2C+W.&amp;rft.au=Suppa%2C+M.&amp;rft.au=Burschka%2C+D.&amp;rft.au=Hirzinger%2C+G.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFStroblMairHirzinger2011" class="citation book cs1">Strobl, Klaus H.; Mair, Elmar; Hirzinger, Gerd (2011). <a rel="nofollow" class="external text" href="https://elib.dlr.de/69848/1/strobl_2011icra.pdf">"Image-based pose estimation for 3-D modeling in rapid, hand-held motion"</a> <span class="cs1-format">(PDF)</span>. <i>2011 IEEE International Conference on Robotics and Automation</i>. pp.&#160;2593–2600. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICRA.2011.5979944">10.1109/ICRA.2011.5979944</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-61284-386-5" title="Special:BookSources/978-1-61284-386-5"><bdi>978-1-61284-386-5</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:2921156">2921156</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Image-based+pose+estimation+for+3-D+modeling+in+rapid%2C+hand-held+motion&amp;rft.btitle=2011+IEEE+International+Conference+on+Robotics+and+Automation&amp;rft.pages=2593-2600&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A2921156%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FICRA.2011.5979944&amp;rft.isbn=978-1-61284-386-5&amp;rft.aulast=Strobl&amp;rft.aufirst=Klaus+H.&amp;rft.au=Mair%2C+Elmar&amp;rft.au=Hirzinger%2C+Gerd&amp;rft_id=https%3A%2F%2Felib.dlr.de%2F69848%2F1%2Fstrobl_2011icra.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text">Trost, D. (1999). U.S. Patent No. 5,957,915. Washington, DC: U.S. Patent and Trademark Office.</span>
</li>
<li id="cite_note-27"><span class="mw-cite-backlink"><b><a href="#cite_ref-27">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMoranoOzturkConnDubin1998" class="citation journal cs1">Morano, R.A.; Ozturk, C.; Conn, R.; Dubin, S.; Zietz, S.; Nissano, J. (March 1998). "Structured light using pseudorandom codes". <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>20</b> (3): 322–327. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F34.667888">10.1109/34.667888</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=Structured+light+using+pseudorandom+codes&amp;rft.volume=20&amp;rft.issue=3&amp;rft.pages=322-327&amp;rft.date=1998-03&amp;rft_id=info%3Adoi%2F10.1109%2F34.667888&amp;rft.aulast=Morano&amp;rft.aufirst=R.A.&amp;rft.au=Ozturk%2C+C.&amp;rft.au=Conn%2C+R.&amp;rft.au=Dubin%2C+S.&amp;rft.au=Zietz%2C+S.&amp;rft.au=Nissano%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-28">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHuang2006" class="citation journal cs1">Huang, Peisen S. (1 December 2006). "High-resolution, real-time three-dimensional shape measurement". <i>Optical Engineering</i>. <b>45</b> (12): 123601. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2006OptEn..45l3601Z">2006OptEn..45l3601Z</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1117%2F1.2402128">10.1117/1.2402128</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Optical+Engineering&amp;rft.atitle=High-resolution%2C+real-time+three-dimensional+shape+measurement&amp;rft.volume=45&amp;rft.issue=12&amp;rft.pages=123601&amp;rft.date=2006-12-01&amp;rft_id=info%3Adoi%2F10.1117%2F1.2402128&amp;rft_id=info%3Abibcode%2F2006OptEn..45l3601Z&amp;rft.aulast=Huang&amp;rft.aufirst=Peisen+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-29">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLiuWangLauHao2010" class="citation journal cs1">Liu, Kai; Wang, Yongchang; Lau, Daniel L.; Hao, Qi; Hassebrook, Laurence G. (1 March 2010). <a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOE.18.005229">"Dual-frequency pattern scheme for high-speed 3-D shape measurement"</a>. <i>Optics Express</i>. <b>18</b> (5): 5229–5244. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2010OExpr..18.5229L">2010OExpr..18.5229L</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOE.18.005229">10.1364/OE.18.005229</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/20389536">20389536</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Optics+Express&amp;rft.atitle=Dual-frequency+pattern+scheme+for+high-speed+3-D+shape+measurement&amp;rft.volume=18&amp;rft.issue=5&amp;rft.pages=5229-5244&amp;rft.date=2010-03-01&amp;rft_id=info%3Apmid%2F20389536&amp;rft_id=info%3Adoi%2F10.1364%2FOE.18.005229&amp;rft_id=info%3Abibcode%2F2010OExpr..18.5229L&amp;rft.aulast=Liu&amp;rft.aufirst=Kai&amp;rft.au=Wang%2C+Yongchang&amp;rft.au=Lau%2C+Daniel+L.&amp;rft.au=Hao%2C+Qi&amp;rft.au=Hassebrook%2C+Laurence+G.&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1364%252FOE.18.005229&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-30">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZhangVan_Der_WeideOliver2010" class="citation journal cs1">Zhang, Song; Van Der Weide, Daniel; Oliver, James (26 April 2010). <a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOE.18.009684">"Superfast phase-shifting method for 3-D shape measurement"</a>. <i>Optics Express</i>. <b>18</b> (9): 9684–9689. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2010OExpr..18.9684Z">2010OExpr..18.9684Z</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOE.18.009684">10.1364/OE.18.009684</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/20588818">20588818</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Optics+Express&amp;rft.atitle=Superfast+phase-shifting+method+for+3-D+shape+measurement&amp;rft.volume=18&amp;rft.issue=9&amp;rft.pages=9684-9689&amp;rft.date=2010-04-26&amp;rft_id=info%3Apmid%2F20588818&amp;rft_id=info%3Adoi%2F10.1364%2FOE.18.009684&amp;rft_id=info%3Abibcode%2F2010OExpr..18.9684Z&amp;rft.aulast=Zhang&amp;rft.aufirst=Song&amp;rft.au=Van+Der+Weide%2C+Daniel&amp;rft.au=Oliver%2C+James&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1364%252FOE.18.009684&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-31"><span class="mw-cite-backlink"><b><a href="#cite_ref-31">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWangZhang2011" class="citation journal cs1">Wang, Yajun; Zhang, Song (14 March 2011). <a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOE.19.005149">"Superfast multifrequency phase-shifting technique with optimal pulse width modulation"</a>. <i>Optics Express</i>. <b>19</b> (6): 5149–5155. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2011OExpr..19.5149W">2011OExpr..19.5149W</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1364%2FOE.19.005149">10.1364/OE.19.005149</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/21445150">21445150</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Optics+Express&amp;rft.atitle=Superfast+multifrequency+phase-shifting+technique+with+optimal+pulse+width+modulation&amp;rft.volume=19&amp;rft.issue=6&amp;rft.pages=5149-5155&amp;rft.date=2011-03-14&amp;rft_id=info%3Apmid%2F21445150&amp;rft_id=info%3Adoi%2F10.1364%2FOE.19.005149&amp;rft_id=info%3Abibcode%2F2011OExpr..19.5149W&amp;rft.aulast=Wang&amp;rft.aufirst=Yajun&amp;rft.au=Zhang%2C+Song&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1364%252FOE.19.005149&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-32"><span class="mw-cite-backlink"><b><a href="#cite_ref-32">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20080920173058/http://www.cogs.susx.ac.uk/users/davidy/teachvision/vision5.html">"Sussex Computer Vision: TEACH VISION5"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.cogs.susx.ac.uk/users/davidy/teachvision/vision5.html">the original</a> on 2008-09-20.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Sussex+Computer+Vision%3A+TEACH+VISION5&amp;rft_id=http%3A%2F%2Fwww.cogs.susx.ac.uk%2Fusers%2Fdavidy%2Fteachvision%2Fvision5.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.geodetic.com/">"Geodetic Systems, Inc"</a>. <i>www.geodetic.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2020-03-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.geodetic.com&amp;rft.atitle=Geodetic+Systems%2C+Inc&amp;rft_id=https%3A%2F%2Fwww.geodetic.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://80.lv/articles/what-camera-should-you-use-for-photogrammetry/">"What Camera Should You Use for Photogrammetry?"</a>. <i>80.lv</i>. 2019-07-15<span class="reference-accessdate">. Retrieved <span class="nowrap">2020-03-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=80.lv&amp;rft.atitle=What+Camera+Should+You+Use+for+Photogrammetry%3F&amp;rft.date=2019-07-15&amp;rft_id=https%3A%2F%2F80.lv%2Farticles%2Fwhat-camera-should-you-use-for-photogrammetry%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20200322193509/https://www.gentlegiantstudios.com/services/3d-scanning-and-design/">"3D Scanning and Design"</a>. <i>Gentle Giant Studios</i>. Archived from <a rel="nofollow" class="external text" href="https://www.gentlegiantstudios.com/services/3d-scanning-and-design/">the original</a> on 2020-03-22<span class="reference-accessdate">. Retrieved <span class="nowrap">2020-03-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Gentle+Giant+Studios&amp;rft.atitle=3D+Scanning+and+Design&amp;rft_id=https%3A%2F%2Fwww.gentlegiantstudios.com%2Fservices%2F3d-scanning-and-design%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-36"><span class="mw-cite-backlink"><b><a href="#cite_ref-36">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.gisdevelopment.net/application/urban/products/mi08_226.htm">Semi-Automatic building extraction from LIDAR Data and High-Resolution Image</a></span>
</li>
<li id="cite_note-37"><span class="mw-cite-backlink"><b><a href="#cite_ref-37">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation report cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20200914235505/http://www.grc.missouri.edu/icrestprojarchive/NASA/FeatureExtraction-buildings/Building%20Extraction.pdf">1Automated Building Extraction and Reconstruction from LIDAR Data</a> <span class="cs1-format">(PDF)</span> (Report). p.&#160;11. Archived from <a rel="nofollow" class="external text" href="http://www.grc.missouri.edu/icrestprojarchive/NASA/FeatureExtraction-buildings/Building%20Extraction.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 14 September 2020<span class="reference-accessdate">. Retrieved <span class="nowrap">9 September</span> 2019</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=1Automated+Building+Extraction+and+Reconstruction+from+LIDAR+Data&amp;rft.pages=11&amp;rft_id=http%3A%2F%2Fwww.grc.missouri.edu%2Ficrestprojarchive%2FNASA%2FFeatureExtraction-buildings%2FBuilding%2520Extraction.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-38"><span class="mw-cite-backlink"><b><a href="#cite_ref-38">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20090511125642/http://geoweb.ugent.be/3dda/areas/">"Terrestrial laser scanning"</a>. Archived from <a rel="nofollow" class="external text" href="http://geoweb.ugent.be/3dda/areas/">the original</a> on 2009-05-11<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Terrestrial+laser+scanning&amp;rft_id=http%3A%2F%2Fgeoweb.ugent.be%2F3dda%2Fareas%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-39"><span class="mw-cite-backlink"><b><a href="#cite_ref-39">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFHaalaBrennerAnders1998" class="citation web cs1">Haala, Norbert; Brenner, Claus; Anders, Karl-Heinrich (1998). <a rel="nofollow" class="external text" href="https://ifpwww.ifp.uni-stuttgart.de/publications/1998/ohio_laser.pdf">"3D Urban GIS from Laser Altimeter and 2D Map Data"</a> <span class="cs1-format">(PDF)</span>. <i>Institute for Photogrammetry (IFP)</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Institute+for+Photogrammetry+%28IFP%29&amp;rft.atitle=3D+Urban+GIS+from+Laser+Altimeter+and+2D+Map+Data&amp;rft.date=1998&amp;rft.aulast=Haala&amp;rft.aufirst=Norbert&amp;rft.au=Brenner%2C+Claus&amp;rft.au=Anders%2C+Karl-Heinrich&amp;rft_id=https%3A%2F%2Fifpwww.ifp.uni-stuttgart.de%2Fpublications%2F1998%2Fohio_laser.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-40"><span class="mw-cite-backlink"><b><a href="#cite_ref-40">^</a></b></span> <span class="reference-text">Ghent University, Department of Geography</span>
</li>
<li id="cite_note-41"><span class="mw-cite-backlink"><b><a href="#cite_ref-41">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://arrival3d.com/glossary/#letter-m">"Glossary of 3d technology terms"</a>. 23 April 2018.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Glossary+of+3d+technology+terms&amp;rft.date=2018-04-23&amp;rft_id=https%3A%2F%2Farrival3d.com%2Fglossary%2F%23letter-m&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-42"><span class="mw-cite-backlink"><b><a href="#cite_ref-42">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFW._J._WaleckiF._SzondyM._M._Hilali2008" class="citation journal cs1">W. J. Walecki; F. Szondy; M. M. Hilali (2008). "Fast in-line surface topography metrology enabling stress calculation for solar cell manufacturing allowing throughput in excess of 2000 wafers per hour". <i>Meas. Sci. Technol</i>. <b>19</b> (2): 025302. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1088%2F0957-0233%2F19%2F2%2F025302">10.1088/0957-0233/19/2/025302</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:121768537">121768537</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Meas.+Sci.+Technol.&amp;rft.atitle=Fast+in-line+surface+topography+metrology+enabling+stress+calculation+for+solar+cell+manufacturing+allowing+throughput+in+excess+of+2000+wafers+per+hour&amp;rft.volume=19&amp;rft.issue=2&amp;rft.pages=025302&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1088%2F0957-0233%2F19%2F2%2F025302&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A121768537%23id-name%3DS2CID&amp;rft.au=W.+J.+Walecki&amp;rft.au=F.+Szondy&amp;rft.au=M.+M.+Hilali&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-43"><span class="mw-cite-backlink"><b><a href="#cite_ref-43">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20121026132954/http://www.highbeam.com/doc/1G1-88825431.html">Vexcel FotoG</a></span>
</li>
<li id="cite_note-44"><span class="mw-cite-backlink"><b><a href="#cite_ref-44">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20061018212928/http://www.directionsmag.com/article.php?article_id=628">"3D data acquisition"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.directionsmag.com/article.php?article_id=628">the original</a> on 2006-10-18<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=3D+data+acquisition&amp;rft_id=http%3A%2F%2Fwww.directionsmag.com%2Farticle.php%3Farticle_id%3D628&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-45"><span class="mw-cite-backlink"><b><a href="#cite_ref-45">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20091004101204/http://www.vexcel.com/geospatial/geosynth/index.asp">"Vexcel GeoSynth"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.vexcel.com/geospatial/geosynth/index.asp">the original</a> on 2009-10-04<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-10-31</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Vexcel+GeoSynth&amp;rft_id=http%3A%2F%2Fwww.vexcel.com%2Fgeospatial%2Fgeosynth%2Findex.asp&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-46"><span class="mw-cite-backlink"><b><a href="#cite_ref-46">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20170205005245/https://photosynth.net/about.aspx">"Photosynth"</a>. Archived from <a rel="nofollow" class="external text" href="http://photosynth.net/about.aspx">the original</a> on 2017-02-05<span class="reference-accessdate">. Retrieved <span class="nowrap">2021-01-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Photosynth&amp;rft_id=http%3A%2F%2Fphotosynth.net%2Fabout.aspx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-47"><span class="mw-cite-backlink"><b><a href="#cite_ref-47">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://grail.cs.washington.edu/rome/">3D data acquisition and object reconstruction using photos</a></span>
</li>
<li id="cite_note-48"><span class="mw-cite-backlink"><b><a href="#cite_ref-48">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation thesis cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20110724152353/http://www.gdmc.nl/zlatanova/thesis/html/refer/ps/sz_jp_kt98.pdf"><i>3D Object Reconstruction From Aerial Stereo Images</i></a> <span class="cs1-format">(PDF)</span> (Thesis). Archived from <a rel="nofollow" class="external text" href="http://www.gdmc.nl/zlatanova/thesis/html/refer/ps/sz_jp_kt98.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2011-07-24<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=3D+Object+Reconstruction+From+Aerial+Stereo+Images&amp;rft_id=http%3A%2F%2Fwww.gdmc.nl%2Fzlatanova%2Fthesis%2Fhtml%2Frefer%2Fps%2Fsz_jp_kt98.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-49"><span class="mw-cite-backlink"><b><a href="#cite_ref-49">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.agisoft.com/">"Agisoft Metashape"</a>. <i>www.agisoft.com</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-03-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.agisoft.com&amp;rft.atitle=Agisoft+Metashape&amp;rft_id=http%3A%2F%2Fwww.agisoft.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-50"><span class="mw-cite-backlink"><b><a href="#cite_ref-50">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.capturingreality.com/">"RealityCapture"</a>. <i>www.capturingreality.com/</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2017-03-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.capturingreality.com%2F&amp;rft.atitle=RealityCapture&amp;rft_id=https%3A%2F%2Fwww.capturingreality.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-51"><span class="mw-cite-backlink"><b><a href="#cite_ref-51">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20110719111451/http://www.ifp.uni-stuttgart.de/publications/commIV/koehl2neu.pdf">"3D data acquisition and modeling in a Topographic Information System"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://www.ifp.uni-stuttgart.de/publications/commIV/koehl2neu.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2011-07-19<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=3D+data+acquisition+and+modeling+in+a+Topographic+Information+System&amp;rft_id=http%3A%2F%2Fwww.ifp.uni-stuttgart.de%2Fpublications%2FcommIV%2Fkoehl2neu.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-52"><span class="mw-cite-backlink"><b><a href="#cite_ref-52">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20071220154004/http://www.commission3.isprs.org/pia/papers/pia03_s2p1.pdf">"Performance evaluation of a system for semi-automatic building extraction using adaptable primitives"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://www.commission3.isprs.org/pia/papers/pia03_s2p1.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2007-12-20<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Performance+evaluation+of+a+system+for+semi-automatic+building+extraction+using+adaptable+primitives&amp;rft_id=http%3A%2F%2Fwww.commission3.isprs.org%2Fpia%2Fpapers%2Fpia03_s2p1.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-53"><span class="mw-cite-backlink"><b><a href="#cite_ref-53">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRottensteiner2001" class="citation book cs1">Rottensteiner, Franz (2001). <i>Semi-automatic extraction of buildings based on hybrid adjustment using 3D surface models and management of building data in a TIS</i>. Inst. für Photogrammetrie u. Fernerkundung d. Techn. Univ. Wien. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<a rel="nofollow" class="external text" href="https://hdl.handle.net/20.500.12708%2F373">20.500.12708/373</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-9500791-3-5" title="Special:BookSources/978-3-9500791-3-5"><bdi>978-3-9500791-3-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Semi-automatic+extraction+of+buildings+based+on+hybrid+adjustment+using+3D+surface+models+and+management+of+building+data+in+a+TIS&amp;rft.pub=Inst.+f%C3%BCr+Photogrammetrie+u.+Fernerkundung+d.+Techn.+Univ.+Wien&amp;rft.date=2001&amp;rft_id=info%3Ahdl%2F20.500.12708%2F373&amp;rft.isbn=978-3-9500791-3-5&amp;rft.aulast=Rottensteiner&amp;rft.aufirst=Franz&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-54"><span class="mw-cite-backlink"><b><a href="#cite_ref-54">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZhang1999" class="citation book cs1">Zhang, Zhengyou (September 1999). <a rel="nofollow" class="external text" href="https://ieeexplore.ieee.org/document/791289">"Flexible camera calibration by viewing a plane from unknown orientations"</a>. <i>Proceedings of the Seventh IEEE International Conference on Computer Vision</i>. Vol.&#160;1. pp.&#160;666–673. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICCV.1999.791289">10.1109/ICCV.1999.791289</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-7695-0164-8" title="Special:BookSources/0-7695-0164-8"><bdi>0-7695-0164-8</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:206769306">206769306</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Flexible+camera+calibration+by+viewing+a+plane+from+unknown+orientations&amp;rft.btitle=Proceedings+of+the+Seventh+IEEE+International+Conference+on+Computer+Vision&amp;rft.pages=666-673&amp;rft.date=1999-09&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A206769306%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FICCV.1999.791289&amp;rft.isbn=0-7695-0164-8&amp;rft.aulast=Zhang&amp;rft.aufirst=Zhengyou&amp;rft_id=https%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F791289&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-55"><span class="mw-cite-backlink"><b><a href="#cite_ref-55">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20110706113813/http://www.cmis.csiro.au/Hugues.Talbot/dicta2003/cdrom/pdf/0673.pdf">"Multi-spectral images for 3D building detection"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://www.cmis.csiro.au/Hugues.Talbot/dicta2003/cdrom/pdf/0673.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2011-07-06<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Multi-spectral+images+for+3D+building+detection&amp;rft_id=http%3A%2F%2Fwww.cmis.csiro.au%2FHugues.Talbot%2Fdicta2003%2Fcdrom%2Fpdf%2F0673.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-56"><span class="mw-cite-backlink"><b><a href="#cite_ref-56">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://blogs.esa.int/caves/2020/01/03/science-of-tele-robotic-rock-collection/">"Science of tele-robotic rock collection"</a>. European Space Agency<span class="reference-accessdate">. Retrieved <span class="nowrap">2020-01-03</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Science+of+tele-robotic+rock+collection&amp;rft.pub=European+Space+Agency&amp;rft_id=https%3A%2F%2Fblogs.esa.int%2Fcaves%2F2020%2F01%2F03%2Fscience-of-tele-robotic-rock-collection%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-57"><span class="mw-cite-backlink"><b><a href="#cite_ref-57">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation cs2"><a rel="nofollow" class="external text" href="https://www.youtube.com/watch?v=gollw6WX5YU"><i>Scanning rocks</i></a><span class="reference-accessdate">, retrieved <span class="nowrap">2021-12-08</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Scanning+rocks&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dgollw6WX5YU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-58"><span class="mw-cite-backlink"><b><a href="#cite_ref-58">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLarssonKjellander2006" class="citation journal cs1">Larsson, Sören; Kjellander, J.A.P. (2006). "Motion control and data capturing for laser scanning with an industrial robot". <i>Robotics and Autonomous Systems</i>. <b>54</b> (6): 453–460. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.robot.2006.02.002">10.1016/j.robot.2006.02.002</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Robotics+and+Autonomous+Systems&amp;rft.atitle=Motion+control+and+data+capturing+for+laser+scanning+with+an+industrial+robot&amp;rft.volume=54&amp;rft.issue=6&amp;rft.pages=453-460&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1016%2Fj.robot.2006.02.002&amp;rft.aulast=Larsson&amp;rft.aufirst=S%C3%B6ren&amp;rft.au=Kjellander%2C+J.A.P.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-59"><span class="mw-cite-backlink"><b><a href="#cite_ref-59">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://ceit.aut.ac.ir/~shiry/publications/Matthias-icmtpaper_fin.pdf">Landmark detection by a rotary laser scanner for autonomous robot navigation in sewer pipes</a> <a rel="nofollow" class="external text" href="https://web.archive.org/web/20110717212430/http://ceit.aut.ac.ir/~shiry/publications/Matthias-icmtpaper_fin.pdf">Archived</a> 2011-07-17 at the <a href="/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Matthias Dorn et al., Proceedings of the ICMIT 2003, the second International Conference on Mechatronics and Information Technology, pp. 600- 604, Jecheon, Korea, Dec. 2003</span>
</li>
<li id="cite_note-60"><span class="mw-cite-backlink"><b><a href="#cite_ref-60">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRemondino2011" class="citation journal cs1">Remondino, Fabio (June 2011). <a rel="nofollow" class="external text" href="https://doi.org/10.3390%2Frs3061104">"Heritage Recording and 3D Modeling with Photogrammetry and 3D Scanning"</a>. <i>Remote Sensing</i>. <b>3</b> (6): 1104–1138. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2011RemS....3.1104R">2011RemS....3.1104R</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.3390%2Frs3061104">10.3390/rs3061104</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Remote+Sensing&amp;rft.atitle=Heritage+Recording+and+3D+Modeling+with+Photogrammetry+and+3D+Scanning&amp;rft.volume=3&amp;rft.issue=6&amp;rft.pages=1104-1138&amp;rft.date=2011-06&amp;rft_id=info%3Adoi%2F10.3390%2Frs3061104&amp;rft_id=info%3Abibcode%2F2011RemS....3.1104R&amp;rft.aulast=Remondino&amp;rft.aufirst=Fabio&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.3390%252Frs3061104&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-61"><span class="mw-cite-backlink"><b><a href="#cite_ref-61">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFBewleyShekharLeonardUpcroft2011" class="citation book cs1">Bewley, Alex; Shekhar, Rajiv; Leonard, Sam; Upcroft, Ben; Lever, Paul (2011). <a rel="nofollow" class="external text" href="https://eprints.qut.edu.au/42029/1/Bewley2011_ICRA.pdf">"Real-time volume estimation of a dragline payload"</a> <span class="cs1-format">(PDF)</span>. <i>2011 IEEE International Conference on Robotics and Automation</i>. pp.&#160;1571–1576. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICRA.2011.5979898">10.1109/ICRA.2011.5979898</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-61284-386-5" title="Special:BookSources/978-1-61284-386-5"><bdi>978-1-61284-386-5</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:8147627">8147627</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Real-time+volume+estimation+of+a+dragline+payload&amp;rft.btitle=2011+IEEE+International+Conference+on+Robotics+and+Automation&amp;rft.pages=1571-1576&amp;rft.date=2011&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8147627%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FICRA.2011.5979898&amp;rft.isbn=978-1-61284-386-5&amp;rft.aulast=Bewley&amp;rft.aufirst=Alex&amp;rft.au=Shekhar%2C+Rajiv&amp;rft.au=Leonard%2C+Sam&amp;rft.au=Upcroft%2C+Ben&amp;rft.au=Lever%2C+Paul&amp;rft_id=https%3A%2F%2Feprints.qut.edu.au%2F42029%2F1%2FBewley2011_ICRA.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-Resources2012-62"><span class="mw-cite-backlink"><b><a href="#cite_ref-Resources2012_62-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMenPochiraju2012" class="citation book cs1">Men, Hao; Pochiraju, Kishore (2012). "Algorithms for 3D Map Segment Registration". In Khosrow-Pour, Mehdi (ed.). <i>Geographic Information Systems: Concepts, Methodologies, Tools, and Applications: Concepts, Methodologies, Tools, and Applications</i>. Vol.&#160;I. IGI Global. p.&#160;502. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-4666-2039-1" title="Special:BookSources/978-1-4666-2039-1"><bdi>978-1-4666-2039-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Algorithms+for+3D+Map+Segment+Registration&amp;rft.btitle=Geographic+Information+Systems%3A+Concepts%2C+Methodologies%2C+Tools%2C+and+Applications%3A+Concepts%2C+Methodologies%2C+Tools%2C+and+Applications&amp;rft.pages=502&amp;rft.pub=IGI+Global&amp;rft.date=2012&amp;rft.isbn=978-1-4666-2039-1&amp;rft.aulast=Men&amp;rft.aufirst=Hao&amp;rft.au=Pochiraju%2C+Kishore&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-63"><span class="mw-cite-backlink"><b><a href="#cite_ref-63">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMurphy" class="citation web cs1">Murphy, Liam. <a rel="nofollow" class="external text" href="https://web.archive.org/web/20120418190611/http://subsurfacelaserscanning.com/portfolio_1/case-study-old-mine-workings/">"Case Study: Old Mine Workings"</a>. <i>Subsurface Laser Scanning Case Studies</i>. Liam Murphy. Archived from <a rel="nofollow" class="external text" href="http://subsurfacelaserscanning.com/portfolio_1/case-study-old-mine-workings/">the original</a> on 2012-04-18<span class="reference-accessdate">. Retrieved <span class="nowrap">11 January</span> 2012</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Subsurface+Laser+Scanning+Case+Studies&amp;rft.atitle=Case+Study%3A+Old+Mine+Workings&amp;rft.aulast=Murphy&amp;rft.aufirst=Liam&amp;rft_id=http%3A%2F%2Fsubsurfacelaserscanning.com%2Fportfolio_1%2Fcase-study-old-mine-workings%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-64"><span class="mw-cite-backlink"><b><a href="#cite_ref-64">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20130522210549/http://www.leica-geosystems.us/forensic/">"Forensics &amp; Public Safety"</a>. Archived from <a rel="nofollow" class="external text" href="http://www.leica-geosystems.us/forensic/">the original</a> on 2013-05-22<span class="reference-accessdate">. Retrieved <span class="nowrap">2012-01-11</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Forensics+%26+Public+Safety&amp;rft_id=http%3A%2F%2Fwww.leica-geosystems.us%2Fforensic%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-65"><span class="mw-cite-backlink"><b><a href="#cite_ref-65">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation news cs1"><a rel="nofollow" class="external text" href="https://garagefarm.net/blog/the-future-of-3d-modeling">"The Future of 3D Modeling"</a>. <i>GarageFarm</i>. 2017-05-28<span class="reference-accessdate">. Retrieved <span class="nowrap">2017-05-28</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=GarageFarm&amp;rft.atitle=The+Future+of+3D+Modeling&amp;rft.date=2017-05-28&amp;rft_id=https%3A%2F%2Fgaragefarm.net%2Fblog%2Fthe-future-of-3d-modeling&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-66"><span class="mw-cite-backlink"><b><a href="#cite_ref-66">^</a></b></span> <span class="reference-text">Curless, B., &amp; Seitz, S. (2000). 3D Photography. Course Notes for SIGGRAPH 2000.</span>
</li>
<li id="cite_note-67"><span class="mw-cite-backlink"><b><a href="#cite_ref-67">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1 cs1-prop-foreign-lang-source"><a rel="nofollow" class="external text" href="https://www.lavanguardia.com/comer/tendencias/20210207/6224861/codigos-qr-realidad-aumentada-evolucion-cartas-llego-covid-19.html">"Códigos QR y realidad aumentada: la evolución de las cartas en los restaurantes"</a>. <i>La Vanguardia</i> (in Spanish). 2021-02-07<span class="reference-accessdate">. Retrieved <span class="nowrap">2021-11-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=La+Vanguardia&amp;rft.atitle=C%C3%B3digos+QR+y+realidad+aumentada%3A+la+evoluci%C3%B3n+de+las+cartas+en+los+restaurantes&amp;rft.date=2021-02-07&amp;rft_id=https%3A%2F%2Fwww.lavanguardia.com%2Fcomer%2Ftendencias%2F20210207%2F6224861%2Fcodigos-qr-realidad-aumentada-evolucion-cartas-llego-covid-19.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-68"><span class="mw-cite-backlink"><b><a href="#cite_ref-68">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.fbi.gov/services/laboratory/forensic-response/crime-scene-documentation">"Crime Scene Documentation"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Crime+Scene+Documentation&amp;rft_id=https%3A%2F%2Fwww.fbi.gov%2Fservices%2Flaboratory%2Fforensic-response%2Fcrime-scene-documentation&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-69"><span class="mw-cite-backlink"><b><a href="#cite_ref-69">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLamine_MahdjoubiCletus_MoobelaRichard_Laing2013" class="citation journal cs1">Lamine Mahdjoubi; Cletus Moobela; Richard Laing (December 2013). "Providing real-estate services through the integration of 3D laser scanning and building information modelling". <i>Computers in Industry</i>. <b>64</b> (9): 1272. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.compind.2013.09.003">10.1016/j.compind.2013.09.003</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computers+in+Industry&amp;rft.atitle=Providing+real-estate+services+through+the+integration+of+3D+laser+scanning+and+building+information+modelling&amp;rft.volume=64&amp;rft.issue=9&amp;rft.pages=1272&amp;rft.date=2013-12&amp;rft_id=info%3Adoi%2F10.1016%2Fj.compind.2013.09.003&amp;rft.au=Lamine+Mahdjoubi&amp;rft.au=Cletus+Moobela&amp;rft.au=Richard+Laing&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-70"><span class="mw-cite-backlink"><b><a href="#cite_ref-70">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.marketwatch.com/story/matterport-surpasses-70-million-global-visits-and-celebrates-explosive-growth-of-3d-and-virtual-reality-spaces-2016-09-20-10160559">"Matterport Surpasses 70 Million Global Visits and Celebrates Explosive Growth of 3D and Virtual Reality Spaces"</a>. <i>Market Watch</i><span class="reference-accessdate">. Retrieved <span class="nowrap">19 December</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Market+Watch&amp;rft.atitle=Matterport+Surpasses+70+Million+Global+Visits+and+Celebrates+Explosive+Growth+of+3D+and+Virtual+Reality+Spaces&amp;rft_id=http%3A%2F%2Fwww.marketwatch.com%2Fstory%2Fmatterport-surpasses-70-million-global-visits-and-celebrates-explosive-growth-of-3d-and-virtual-reality-spaces-2016-09-20-10160559&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-71"><span class="mw-cite-backlink"><b><a href="#cite_ref-71">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.vrglossary.org/glossary/dollhouse-view/">"The VR Glossary"</a>. 29 August 2016<span class="reference-accessdate">. Retrieved <span class="nowrap">26 April</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+VR+Glossary&amp;rft.date=2016-08-29&amp;rft_id=http%3A%2F%2Fwww.vrglossary.org%2Fglossary%2Fdollhouse-view%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-72"><span class="mw-cite-backlink"><b><a href="#cite_ref-72">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDaniel_A._Guttentag2010" class="citation journal cs1">Daniel A. Guttentag (October 2010). "Virtual reality: Applications and implications for tourism". <i>Tourism Management</i>. <b>31</b> (5): 637–651. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.tourman.2009.07.003">10.1016/j.tourman.2009.07.003</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Tourism+Management&amp;rft.atitle=Virtual+reality%3A+Applications+and+implications+for+tourism&amp;rft.volume=31&amp;rft.issue=5&amp;rft.pages=637-651&amp;rft.date=2010-10&amp;rft_id=info%3Adoi%2F10.1016%2Fj.tourman.2009.07.003&amp;rft.au=Daniel+A.+Guttentag&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-73"><span class="mw-cite-backlink"><b><a href="#cite_ref-73">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGillespie2018" class="citation web cs1">Gillespie, Katie (May 11, 2018). <a rel="nofollow" class="external text" href="https://www.columbian.com/news/2018/may/11/virtual-reality-translates-into-real-history-for-itech-prep-students/">"Virtual reality translates into real history for iTech Prep students"</a>. <i>The Columbian</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2021-12-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Columbian&amp;rft.atitle=Virtual+reality+translates+into+real+history+for+iTech+Prep+students&amp;rft.date=2018-05-11&amp;rft.aulast=Gillespie&amp;rft.aufirst=Katie&amp;rft_id=https%3A%2F%2Fwww.columbian.com%2Fnews%2F2018%2Fmay%2F11%2Fvirtual-reality-translates-into-real-history-for-itech-prep-students%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-74"><span class="mw-cite-backlink"><b><a href="#cite_ref-74">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFCignoniScopigno2008" class="citation journal cs1">Cignoni, Paolo; Scopigno, Roberto (18 June 2008). "Sampled 3D models for CH applications: A viable and enabling new medium or just a technological exercise?". <i>Journal on Computing and Cultural Heritage</i>. <b>1</b> (1): 2:1–2:23. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F1367080.1367082">10.1145/1367080.1367082</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:16510261">16510261</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+on+Computing+and+Cultural+Heritage&amp;rft.atitle=Sampled+3D+models+for+CH+applications%3A+A+viable+and+enabling+new+medium+or+just+a+technological+exercise%3F&amp;rft.volume=1&amp;rft.issue=1&amp;rft.pages=2%3A1-2%3A23&amp;rft.date=2008-06-18&amp;rft_id=info%3Adoi%2F10.1145%2F1367080.1367082&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A16510261%23id-name%3DS2CID&amp;rft.aulast=Cignoni&amp;rft.aufirst=Paolo&amp;rft.au=Scopigno%2C+Roberto&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-75"><span class="mw-cite-backlink"><b><a href="#cite_ref-75">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFWyatt-Spratt2022" class="citation journal cs1">Wyatt-Spratt, Simon (2022-11-04). <a rel="nofollow" class="external text" href="https://doi.org/10.5334%2Fjcaa.103">"After the Revolution: A Review of 3D Modelling as a Tool for Stone Artefact Analysis"</a>. <i>Journal of Computer Applications in Archaeology</i>. <b>5</b> (1): 215–237. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.5334%2Fjcaa.103">10.5334/jcaa.103</a></span>. <a href="/wiki/Hdl_(identifier)" class="mw-redirect" title="Hdl (identifier)">hdl</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://hdl.handle.net/2123%2F30230">2123/30230</a></span>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:253353315">253353315</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Computer+Applications+in+Archaeology&amp;rft.atitle=After+the+Revolution%3A+A+Review+of+3D+Modelling+as+a+Tool+for+Stone+Artefact+Analysis&amp;rft.volume=5&amp;rft.issue=1&amp;rft.pages=215-237&amp;rft.date=2022-11-04&amp;rft_id=info%3Ahdl%2F2123%2F30230&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A253353315%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.5334%2Fjcaa.103&amp;rft.aulast=Wyatt-Spratt&amp;rft.aufirst=Simon&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.5334%252Fjcaa.103&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-76"><span class="mw-cite-backlink"><b><a href="#cite_ref-76">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMagnaniDouglassSchroderReeves2020" class="citation journal cs1">Magnani, Matthew; Douglass, Matthew; Schroder, Whittaker; Reeves, Jonathan; Braun, David R. (October 2020). <a rel="nofollow" class="external text" href="https://digitalcommons.library.umaine.edu/cgi/viewcontent.cgi?article=1060&amp;context=ant_facpub">"The Digital Revolution to Come: Photogrammetry in Archaeological Practice"</a>. <i>American Antiquity</i>. <b>85</b> (4): 737–760. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1017%2Faaq.2020.59">10.1017/aaq.2020.59</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:225390638">225390638</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=American+Antiquity&amp;rft.atitle=The+Digital+Revolution+to+Come%3A+Photogrammetry+in+Archaeological+Practice&amp;rft.volume=85&amp;rft.issue=4&amp;rft.pages=737-760&amp;rft.date=2020-10&amp;rft_id=info%3Adoi%2F10.1017%2Faaq.2020.59&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A225390638%23id-name%3DS2CID&amp;rft.aulast=Magnani&amp;rft.aufirst=Matthew&amp;rft.au=Douglass%2C+Matthew&amp;rft.au=Schroder%2C+Whittaker&amp;rft.au=Reeves%2C+Jonathan&amp;rft.au=Braun%2C+David+R.&amp;rft_id=https%3A%2F%2Fdigitalcommons.library.umaine.edu%2Fcgi%2Fviewcontent.cgi%3Farticle%3D1060%26context%3Dant_facpub&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-77"><span class="mw-cite-backlink"><b><a href="#cite_ref-77">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFScopignoCignoniPietroniCallieri2017" class="citation journal cs1">Scopigno, R.; Cignoni, P.; Pietroni, N.; Callieri, M.; Dellepiane, M. (January 2017). "Digital Fabrication Techniques for Cultural Heritage: A Survey: Fabrication Techniques for Cultural Heritage". <i>Computer Graphics Forum</i>. <b>36</b> (1): 6–21. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1111%2Fcgf.12781">10.1111/cgf.12781</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:26690232">26690232</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer+Graphics+Forum&amp;rft.atitle=Digital+Fabrication+Techniques+for+Cultural+Heritage%3A+A+Survey%3A+Fabrication+Techniques+for+Cultural+Heritage&amp;rft.volume=36&amp;rft.issue=1&amp;rft.pages=6-21&amp;rft.date=2017-01&amp;rft_id=info%3Adoi%2F10.1111%2Fcgf.12781&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A26690232%23id-name%3DS2CID&amp;rft.aulast=Scopigno&amp;rft.aufirst=R.&amp;rft.au=Cignoni%2C+P.&amp;rft.au=Pietroni%2C+N.&amp;rft.au=Callieri%2C+M.&amp;rft.au=Dellepiane%2C+M.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-78"><span class="mw-cite-backlink"><b><a href="#cite_ref-78">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFLewisOswald2019" class="citation journal cs1">Lewis, M.; Oswald, C. (2019). <a rel="nofollow" class="external text" href="https://doi.org/10.5194%2Fisprs-archives-XLII-2-W10-107-2019">"Can an Inexpensive Phone App Compare to Other Methods when It Comes to 3D Digitization of Ship Models"</a>. <i>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</i>. <b>4210</b>: 107–111. <a href="/wiki/Bibcode_(identifier)" class="mw-redirect" title="Bibcode (identifier)">Bibcode</a>:<a rel="nofollow" class="external text" href="https://ui.adsabs.harvard.edu/abs/2019ISPAr4210..107L">2019ISPAr4210..107L</a>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.5194%2Fisprs-archives-XLII-2-W10-107-2019">10.5194/isprs-archives-XLII-2-W10-107-2019</a></span>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:146021711">146021711</a>. <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><a href="/wiki/ProQuest_(identifier)" class="mw-redirect" title="ProQuest (identifier)">ProQuest</a>&#160;<a rel="nofollow" class="external text" href="https://search.proquest.com/docview/2585423206">2585423206</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+International+Archives+of+the+Photogrammetry%2C+Remote+Sensing+and+Spatial+Information+Sciences&amp;rft.atitle=Can+an+Inexpensive+Phone+App+Compare+to+Other+Methods+when+It+Comes+to+3D+Digitization+of+Ship+Models&amp;rft.volume=4210&amp;rft.pages=107-111&amp;rft.date=2019&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A146021711%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.5194%2Fisprs-archives-XLII-2-W10-107-2019&amp;rft_id=info%3Abibcode%2F2019ISPAr4210..107L&amp;rft.aulast=Lewis&amp;rft.aufirst=M.&amp;rft.au=Oswald%2C+C.&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.5194%252Fisprs-archives-XLII-2-W10-107-2019&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-79"><span class="mw-cite-backlink"><b><a href="#cite_ref-79">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.imaginedmuseum.uk/submit-your-artefact">"Submit your artefact"</a>. <i>www.imaginedmuseum.uk</i><span class="reference-accessdate">. Retrieved <span class="nowrap">2021-11-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.imaginedmuseum.uk&amp;rft.atitle=Submit+your+artefact&amp;rft_id=https%3A%2F%2Fwww.imaginedmuseum.uk%2Fsubmit-your-artefact&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span><sup class="noprint Inline-Template"><span style="white-space: nowrap;">&#91;<i><a href="/wiki/Wikipedia:Link_rot" title="Wikipedia:Link rot"><span title="&#160;Dead link tagged April 2023">permanent dead link</span></a></i>&#93;</span></sup></span>
</li>
<li id="cite_note-80"><span class="mw-cite-backlink"><b><a href="#cite_ref-80">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://digitalorientalist.com/2018/12/03/scholarship-in-3d-3d-scanning-and-printing-at-asor-2018/">"Scholarship in 3D: 3D scanning and printing at ASOR 2018"</a>. <i>The Digital Orientalist</i>. 2018-12-03<span class="reference-accessdate">. Retrieved <span class="nowrap">2021-11-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Digital+Orientalist&amp;rft.atitle=Scholarship+in+3D%3A+3D+scanning+and+printing+at+ASOR+2018&amp;rft.date=2018-12-03&amp;rft_id=https%3A%2F%2Fdigitalorientalist.com%2F2018%2F12%2F03%2Fscholarship-in-3d-3d-scanning-and-printing-at-asor-2018%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-81"><span class="mw-cite-backlink"><b><a href="#cite_ref-81">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMarc_LevoyKari_PulliBrian_CurlessSzymon_Rusinkiewicz2000" class="citation conference cs1">Marc Levoy; Kari Pulli; Brian Curless; Szymon Rusinkiewicz; David Koller; Lucas Pereira; Matt Ginzton; Sean Anderson; James Davis; Jeremy Ginsberg; Jonathan Shade; Duane Fulk (2000). <a rel="nofollow" class="external text" href="http://graphics.stanford.edu/papers/dmich-sig00/">"The Digital Michelangelo Project: 3D Scanning of Large Statues"</a> <span class="cs1-format">(PDF)</span>. <i>Proceedings of the 27th annual conference on Computer graphics and interactive techniques</i>. pp.&#160;131–144.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=The+Digital+Michelangelo+Project%3A+3D+Scanning+of+Large+Statues&amp;rft.btitle=Proceedings+of+the+27th+annual+conference+on+Computer+graphics+and+interactive+techniques&amp;rft.pages=131-144&amp;rft.date=2000&amp;rft.au=Marc+Levoy&amp;rft.au=Kari+Pulli&amp;rft.au=Brian+Curless&amp;rft.au=Szymon+Rusinkiewicz&amp;rft.au=David+Koller&amp;rft.au=Lucas+Pereira&amp;rft.au=Matt+Ginzton&amp;rft.au=Sean+Anderson&amp;rft.au=James+Davis&amp;rft.au=Jeremy+Ginsberg&amp;rft.au=Jonathan+Shade&amp;rft.au=Duane+Fulk&amp;rft_id=http%3A%2F%2Fgraphics.stanford.edu%2Fpapers%2Fdmich-sig00%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-82"><span class="mw-cite-backlink"><b><a href="#cite_ref-82">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFRoberto_ScopignoSusanna_BracciFalletti,_FrancaMauro_Matteini2004" class="citation book cs1">Roberto Scopigno; Susanna Bracci; Falletti, Franca; Mauro Matteini (2004). <i>Exploring David. Diagnostic Tests and State of Conservation</i>. Gruppo Editoriale Giunti. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-88-09-03325-2" title="Special:BookSources/978-88-09-03325-2"><bdi>978-88-09-03325-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Exploring+David.+Diagnostic+Tests+and+State+of+Conservation.&amp;rft.pub=Gruppo+Editoriale+Giunti&amp;rft.date=2004&amp;rft.isbn=978-88-09-03325-2&amp;rft.au=Roberto+Scopigno&amp;rft.au=Susanna+Bracci&amp;rft.au=Falletti%2C+Franca&amp;rft.au=Mauro+Matteini&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-83"><span class="mw-cite-backlink"><b><a href="#cite_ref-83">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFDavid_LuebkeChristopher_LutzRui_WangCliff_Woolley2002" class="citation web cs1">David Luebke; Christopher Lutz; Rui Wang; Cliff Woolley (2002). <a rel="nofollow" class="external text" href="http://www.cs.virginia.edu/Monticello">"Scanning Monticello"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Scanning+Monticello&amp;rft.date=2002&amp;rft.au=David+Luebke&amp;rft.au=Christopher+Lutz&amp;rft.au=Rui+Wang&amp;rft.au=Cliff+Woolley&amp;rft_id=http%3A%2F%2Fwww.cs.virginia.edu%2FMonticello&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-hetiter3d-84"><span class="mw-cite-backlink"><b><a href="#cite_ref-hetiter3d_84-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1 cs1-prop-foreign-lang-source"><a rel="nofollow" class="external text" href="http://www.hethport.uni-wuerzburg.de/3d/">"Tontafeln 3D, Hetitologie Portal, Mainz, Germany"</a> (in German)<span class="reference-accessdate">. Retrieved <span class="nowrap">2019-06-23</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Tontafeln+3D%2C+Hetitologie+Portal%2C+Mainz%2C+Germany&amp;rft_id=http%3A%2F%2Fwww.hethport.uni-wuerzburg.de%2F3d%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-DigitalHammurabi-85"><span class="mw-cite-backlink"><b><a href="#cite_ref-DigitalHammurabi_85-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFKumarSnyderDuncanCohen2003" class="citation book cs1">Kumar, S.; Snyder, D.; Duncan, D.; Cohen, J.; Cooper, J. (2003). "Digital preservation of ancient Cuneiform tablets using 3D-scanning". <i>Fourth International Conference on 3-D Digital Imaging and Modeling, 2003. 3DIM 2003. Proceedings</i>. pp.&#160;326–333. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FIM.2003.1240266">10.1109/IM.2003.1240266</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-7695-1991-3" title="Special:BookSources/978-0-7695-1991-3"><bdi>978-0-7695-1991-3</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:676588">676588</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Digital+preservation+of+ancient+Cuneiform+tablets+using+3D-scanning&amp;rft.btitle=Fourth+International+Conference+on+3-D+Digital+Imaging+and+Modeling%2C+2003.+3DIM+2003.+Proceedings&amp;rft.pages=326-333&amp;rft.date=2003&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A676588%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FIM.2003.1240266&amp;rft.isbn=978-0-7695-1991-3&amp;rft.aulast=Kumar&amp;rft.aufirst=S.&amp;rft.au=Snyder%2C+D.&amp;rft.au=Duncan%2C+D.&amp;rft.au=Cohen%2C+J.&amp;rft.au=Cooper%2C+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-GigaMesh_2010-86"><span class="mw-cite-backlink"><b><a href="#cite_ref-GigaMesh_2010_86-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMaraKrömkerJakobBreuckmann2010" class="citation book cs1">Mara, Hubert; Krömker, Susanne; Jakob, Stefan; Breuckmann, Bernd (2010). "GigaMesh and Gilgamesh 3D Multiscale Integral Invariant Cuneiform Character Extraction". <i>Vast: International Symposium on Virtual Reality</i>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.2312%2FVAST%2FVAST10%2F131-138">10.2312/VAST/VAST10/131-138</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-905674-29-3" title="Special:BookSources/978-3-905674-29-3"><bdi>978-3-905674-29-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=GigaMesh+and+Gilgamesh+3D+Multiscale+Integral+Invariant+Cuneiform+Character+Extraction&amp;rft.btitle=Vast%3A+International+Symposium+on+Virtual+Reality&amp;rft.date=2010&amp;rft_id=info%3Adoi%2F10.2312%2FVAST%2FVAST10%2F131-138&amp;rft.isbn=978-3-905674-29-3&amp;rft.aulast=Mara&amp;rft.aufirst=Hubert&amp;rft.au=Kr%C3%B6mker%2C+Susanne&amp;rft.au=Jakob%2C+Stefan&amp;rft.au=Breuckmann%2C+Bernd&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-HeiCuBeDa_Hilprecht-87"><span class="mw-cite-backlink"><b><a href="#cite_ref-HeiCuBeDa_Hilprecht_87-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMara2019" class="citation cs2">Mara, Hubert (2019-06-07), <i>HeiCuBeDa Hilprecht – Heidelberg Cuneiform Benchmark Dataset for the Hilprecht Collection</i>, heiDATA – institutional repository for research data of Heidelberg University, <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.11588%2Fdata%2FIE8CCN">10.11588/data/IE8CCN</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=HeiCuBeDa+Hilprecht+%E2%80%93+Heidelberg+Cuneiform+Benchmark+Dataset+for+the+Hilprecht+Collection&amp;rft.pub=heiDATA+%E2%80%93+institutional+repository+for+research+data+of+Heidelberg+University&amp;rft.date=2019-06-07&amp;rft_id=info%3Adoi%2F10.11588%2Fdata%2FIE8CCN&amp;rft.aulast=Mara&amp;rft.aufirst=Hubert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-HeiCu3Da_Hilprecht-88"><span class="mw-cite-backlink"><b><a href="#cite_ref-HeiCu3Da_Hilprecht_88-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMara2019" class="citation cs2">Mara, Hubert (2019-06-07), <i>HeiCu3Da Hilprecht – Heidelberg Cuneiform 3D Database - Hilprecht Collection</i>, heidICON – Die Heidelberger Objekt- und Multimediadatenbank, <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.11588%2Fheidicon.hilprecht">10.11588/heidicon.hilprecht</a></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=HeiCu3Da+Hilprecht+%E2%80%93+Heidelberg+Cuneiform+3D+Database+-+Hilprecht+Collection&amp;rft.pub=heidICON+%E2%80%93+Die+Heidelberger+Objekt-+und+Multimediadatenbank&amp;rft.date=2019-06-07&amp;rft_id=info%3Adoi%2F10.11588%2Fheidicon.hilprecht&amp;rft.aulast=Mara&amp;rft.aufirst=Hubert&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-ICDAR19-89"><span class="mw-cite-backlink"><b><a href="#cite_ref-ICDAR19_89-0">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFMaraBogacz2019" class="citation book cs1">Mara, Hubert; Bogacz, Bartosz (2019). "Breaking the Code on Broken Tablets: The Learning Challenge for Annotated Cuneiform Script in Normalized 2D and 3D Datasets". <i>2019 International Conference on Document Analysis and Recognition (ICDAR)</i>. pp.&#160;148–153. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FICDAR.2019.00032">10.1109/ICDAR.2019.00032</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-7281-3014-9" title="Special:BookSources/978-1-7281-3014-9"><bdi>978-1-7281-3014-9</bdi></a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:211026941">211026941</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Breaking+the+Code+on+Broken+Tablets%3A+The+Learning+Challenge+for+Annotated+Cuneiform+Script+in+Normalized+2D+and+3D+Datasets&amp;rft.btitle=2019+International+Conference+on+Document+Analysis+and+Recognition+%28ICDAR%29&amp;rft.pages=148-153&amp;rft.date=2019&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A211026941%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1109%2FICDAR.2019.00032&amp;rft.isbn=978-1-7281-3014-9&amp;rft.aulast=Mara&amp;rft.aufirst=Hubert&amp;rft.au=Bogacz%2C+Bartosz&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-90"><span class="mw-cite-backlink"><b><a href="#cite_ref-90">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFScott_Cedarleaf_(2010)" class="citation news cs1">Scott Cedarleaf (2010). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20100330085531/http://archive.cyark.org/royal-kasubi-tombs-destroyed-in-fire-blog">"Royal Kasubi Tombs Destroyed in Fire"</a>. <a href="/wiki/CyArk" title="CyArk">CyArk</a> Blog. Archived from <a rel="nofollow" class="external text" href="http://archive.cyark.org/royal-kasubi-tombs-destroyed-in-fire-blog">the original</a> on 2010-03-30<span class="reference-accessdate">. Retrieved <span class="nowrap">2010-04-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Royal+Kasubi+Tombs+Destroyed+in+Fire&amp;rft.au=Scott+Cedarleaf+%282010%29&amp;rft_id=http%3A%2F%2Farchive.cyark.org%2Froyal-kasubi-tombs-destroyed-in-fire-blog&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span><span class="cs1-maint citation-comment"><code class="cs1-code">{{<a href="/wiki/Template:Cite_news" title="Template:Cite news">cite news</a>}}</code>:  CS1 maint: numeric names: authors list (<a href="/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">link</a>)</span></span>
</li>
<li id="cite_note-91"><span class="mw-cite-backlink"><b><a href="#cite_ref-91">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGabriele_GuidiLaura_MicoliMichele_RussoBernard_Frischer2005" class="citation conference cs1">Gabriele Guidi; Laura Micoli; Michele Russo; Bernard Frischer; Monica De Simone; Alessandro Spinetti; Luca Carosso (13–16 June 2005). "3D digitisation of a large model of imperial Rome". <i>5th international conference on 3-D digital imaging and modeling&#160;: 3DIM 2005, Ottawa, Ontario, Canada</i>. Los Alamitos, CA: IEEE Computer Society. pp.&#160;565–572. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-7695-2327-7" title="Special:BookSources/0-7695-2327-7"><bdi>0-7695-2327-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=3D+digitisation+of+a+large+model+of+imperial+Rome&amp;rft.btitle=5th+international+conference+on+3-D+digital+imaging+and+modeling+%3A+3DIM+2005%2C+Ottawa%2C+Ontario%2C+Canada&amp;rft.place=Los+Alamitos%2C+CA&amp;rft.pages=565-572&amp;rft.pub=IEEE+Computer+Society&amp;rft.date=2005-06-13%2F2005-06-16&amp;rft.isbn=0-7695-2327-7&amp;rft.au=Gabriele+Guidi&amp;rft.au=Laura+Micoli&amp;rft.au=Michele+Russo&amp;rft.au=Bernard+Frischer&amp;rft.au=Monica+De+Simone&amp;rft.au=Alessandro+Spinetti&amp;rft.au=Luca+Carosso&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-92"><span class="mw-cite-backlink"><b><a href="#cite_ref-92">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFPayne,_Emma_Marie2012" class="citation journal cs1">Payne, Emma Marie (2012). <a rel="nofollow" class="external text" href="http://discovery.ucl.ac.uk/1443164/1/56-566-2-PB.pdf">"Imaging Techniques in Conservation"</a> <span class="cs1-format">(PDF)</span>. <i>Journal of Conservation and Museum Studies</i>. <b>10</b> (2). <a href="/wiki/Ubiquity_Press" title="Ubiquity Press">Ubiquity Press</a>: 17–29. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="id-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.5334%2Fjcms.1021201">10.5334/jcms.1021201</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Conservation+and+Museum+Studies&amp;rft.atitle=Imaging+Techniques+in+Conservation&amp;rft.volume=10&amp;rft.issue=2&amp;rft.pages=17-29&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.5334%2Fjcms.1021201&amp;rft.au=Payne%2C+Emma+Marie&amp;rft_id=http%3A%2F%2Fdiscovery.ucl.ac.uk%2F1443164%2F1%2F56-566-2-PB.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-93"><span class="mw-cite-backlink"><b><a href="#cite_ref-93">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://www.3d-scantech.com/3d-body-scanning/">"3D Body Scanner for Body Scanning in Medicine Field | Scantech"</a>. 2020-08-27<span class="reference-accessdate">. Retrieved <span class="nowrap">2023-11-15</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=3D+Body+Scanner+for+Body+Scanning+in+Medicine+Field+%7C+Scantech&amp;rft.date=2020-08-27&amp;rft_id=https%3A%2F%2Fwww.3d-scantech.com%2F3d-body-scanning%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-94"><span class="mw-cite-backlink"><b><a href="#cite_ref-94">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFIwanagaTeradaKimTabira2021" class="citation journal cs1">Iwanaga, Joe; Terada, Satoshi; Kim, Hee-Jin; Tabira, Yoko; Arakawa, Takamitsu; Watanabe, Koichi; Dumont, Aaron S.; Tubbs, R. Shane (September 2021). "Easy three-dimensional scanning technology for anatomy education using a free cellphone app". <i>Clinical Anatomy</i>. <b>34</b> (6): 910–918. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1002%2Fca.23753">10.1002/ca.23753</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/33984162">33984162</a>. <a href="/wiki/S2CID_(identifier)" class="mw-redirect" title="S2CID (identifier)">S2CID</a>&#160;<a rel="nofollow" class="external text" href="https://api.semanticscholar.org/CorpusID:234497497">234497497</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Clinical+Anatomy&amp;rft.atitle=Easy+three-dimensional+scanning+technology+for+anatomy+education+using+a+free+cellphone+app&amp;rft.volume=34&amp;rft.issue=6&amp;rft.pages=910-918&amp;rft.date=2021-09&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A234497497%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F33984162&amp;rft_id=info%3Adoi%2F10.1002%2Fca.23753&amp;rft.aulast=Iwanaga&amp;rft.aufirst=Joe&amp;rft.au=Terada%2C+Satoshi&amp;rft.au=Kim%2C+Hee-Jin&amp;rft.au=Tabira%2C+Yoko&amp;rft.au=Arakawa%2C+Takamitsu&amp;rft.au=Watanabe%2C+Koichi&amp;rft.au=Dumont%2C+Aaron+S.&amp;rft.au=Tubbs%2C+R.+Shane&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-95"><span class="mw-cite-backlink"><b><a href="#cite_ref-95">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREF竹下2021" class="citation journal cs1 cs1-prop-foreign-lang-source">竹下, 俊治 (19 March 2021). "生物の形態観察における3Dスキャンアプリの活用" &#91;Utilization of 3D scanning application for morphological observation of organisms&#93;. <i>学校教育実践学研究</i> (in Japanese). <b>27</b>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.15027%2F50609">10.15027/50609</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=%E5%AD%A6%E6%A0%A1%E6%95%99%E8%82%B2%E5%AE%9F%E8%B7%B5%E5%AD%A6%E7%A0%94%E7%A9%B6&amp;rft.atitle=%E7%94%9F%E7%89%A9%E3%81%AE%E5%BD%A2%E6%85%8B%E8%A6%B3%E5%AF%9F%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B3D%E3%82%B9%E3%82%AD%E3%83%A3%E3%83%B3%E3%82%A2%E3%83%97%E3%83%AA%E3%81%AE%E6%B4%BB%E7%94%A8&amp;rft.volume=27&amp;rft.date=2021-03-19&amp;rft_id=info%3Adoi%2F10.15027%2F50609&amp;rft.aulast=%E7%AB%B9%E4%B8%8B&amp;rft.aufirst=%E4%BF%8A%E6%B2%BB&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-96"><span class="mw-cite-backlink"><b><a href="#cite_ref-96">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFGursesGungorHanaliogluYaltirik2021" class="citation journal cs1">Gurses, Muhammet Enes; Gungor, Abuzer; Hanalioglu, Sahin; Yaltirik, Cumhur Kaan; Postuk, Hasan Cagri; Berker, Mustafa; Türe, Uğur (December 2021). "Qlone®: A Simple Method to Create 360-Degree Photogrammetry-Based 3-Dimensional Model of Cadaveric Specimens". <i>Operative Neurosurgery</i>. <b>21</b> (6): E488–E493. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Fons%2Fopab355">10.1093/ons/opab355</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="https://pubmed.ncbi.nlm.nih.gov/34662905">34662905</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Operative+Neurosurgery&amp;rft.atitle=Qlone%C2%AE%3A+A+Simple+Method+to+Create+360-Degree+Photogrammetry-Based+3-Dimensional+Model+of+Cadaveric+Specimens&amp;rft.volume=21&amp;rft.issue=6&amp;rft.pages=E488-E493&amp;rft.date=2021-12&amp;rft_id=info%3Adoi%2F10.1093%2Fons%2Fopab355&amp;rft_id=info%3Apmid%2F34662905&amp;rft.aulast=Gurses&amp;rft.aufirst=Muhammet+Enes&amp;rft.au=Gungor%2C+Abuzer&amp;rft.au=Hanalioglu%2C+Sahin&amp;rft.au=Yaltirik%2C+Cumhur+Kaan&amp;rft.au=Postuk%2C+Hasan+Cagri&amp;rft.au=Berker%2C+Mustafa&amp;rft.au=T%C3%BCre%2C+U%C4%9Fur&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-97"><span class="mw-cite-backlink"><b><a href="#cite_ref-97">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFChristian_Teutsch2007" class="citation thesis cs1">Christian Teutsch (2007). <i>Model-based Analysis and Evaluation of Point Sets from Optical 3D Laser Scanners</i> (PhD thesis).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Adissertation&amp;rft.title=Model-based+Analysis+and+Evaluation+of+Point+Sets+from+Optical+3D+Laser+Scanners&amp;rft.degree=PhD&amp;rft.date=2007&amp;rft.au=Christian+Teutsch&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-98"><span class="mw-cite-backlink"><b><a href="#cite_ref-98">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="http://www.argon-ms.com/3d-measurement-services/3d-scanning/">"3D scanning technologies"</a><span class="reference-accessdate">. Retrieved <span class="nowrap">2016-09-15</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=3D+scanning+technologies.&amp;rft_id=http%3A%2F%2Fwww.argon-ms.com%2F3d-measurement-services%2F3d-scanning%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-99"><span class="mw-cite-backlink"><b><a href="#cite_ref-99">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://scantech-international.com/blog/timeline-of-3d-laser-scanners/">Timeline of 3D Laser Scanners</a></span>
</li>
<li id="cite_note-100"><span class="mw-cite-backlink"><b><a href="#cite_ref-100">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite class="citation web cs1"><a rel="nofollow" class="external text" href="https://web.archive.org/web/20030506080319/http://www.geo.tudelft.nl/frs/papers/2001/ildi_manchester.pdf">"Implementing data to GIS map"</a> <span class="cs1-format">(PDF)</span>. Archived from <a rel="nofollow" class="external text" href="http://www.geo.tudelft.nl/frs/papers/2001/ildi_manchester.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 2003-05-06<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Implementing+data+to+GIS+map&amp;rft_id=http%3A%2F%2Fwww.geo.tudelft.nl%2Ffrs%2Fpapers%2F2001%2Fildi_manchester.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
<li id="cite_note-101"><span class="mw-cite-backlink"><b><a href="#cite_ref-101">^</a></b></span> <span class="reference-text"><a rel="nofollow" class="external text" href="http://www.itc.nl/personal/vosselman/papers/suveg2001.bmvc.pdf">3D data implementation to GIS maps</a></span>
</li>
<li id="cite_note-102"><span class="mw-cite-backlink"><b><a href="#cite_ref-102">^</a></b></span> <span class="reference-text"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1215172403"><cite id="CITEREFZlatanova2008" class="citation book cs1">Zlatanova, Sisi (2008). "Working Group II — Acquisition — Position Paper: Data collection and 3D reconstruction". <i>Advances in 3D Geoinformation Systems</i>. Lecture Notes in Geoinformation and Cartography. pp.&#160;425–428. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-540-72135-2_24">10.1007/978-3-540-72135-2_24</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-72134-5" title="Special:BookSources/978-3-540-72134-5"><bdi>978-3-540-72134-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Working+Group+II+%E2%80%94+Acquisition+%E2%80%94+Position+Paper%3A+Data+collection+and+3D+reconstruction&amp;rft.btitle=Advances+in+3D+Geoinformation+Systems&amp;rft.series=Lecture+Notes+in+Geoinformation+and+Cartography&amp;rft.pages=425-428&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-540-72135-2_24&amp;rft.isbn=978-3-540-72134-5&amp;rft.aulast=Zlatanova&amp;rft.aufirst=Sisi&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3A3D+scanning" class="Z3988"></span></span>
</li>
</ol></div>
<div class="navbox-styles"><style data-mw-deduplicate="TemplateStyles:r1129693374">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:": "}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:" · ";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:" (";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:")";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:" "counter(listitem)"\a0 "}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:" ("counter(listitem)"\a0 "}</style><style data-mw-deduplicate="TemplateStyles:r1061467846">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}</style></div><div role="navigation" class="navbox" aria-labelledby="Lasers" style="padding:3px"><table class="nowraplinks hlist mw-collapsible mw-collapsed navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r1129693374"><style data-mw-deduplicate="TemplateStyles:r1063604349">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:"[ "}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:" ]"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}</style><div class="navbar plainlinks hlist navbar-mini"><ul><li class="nv-view"><a href="/wiki/Template:Lasers" title="Template:Lasers"><abbr title="View this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Lasers" title="Template talk:Lasers"><abbr title="Discuss this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">t</abbr></a></li><li class="nv-edit"><a href="/wiki/Special:EditPage/Template:Lasers" title="Special:EditPage/Template:Lasers"><abbr title="Edit this template" style=";;background:none transparent;border:none;box-shadow:none;padding:0;">e</abbr></a></li></ul></div><div id="Lasers" style="font-size:114%;margin:0 4em"><a href="/wiki/Laser" title="Laser">Lasers</a></div></th></tr><tr><td class="navbox-abovebelow" colspan="2"><div>
<ul><li><a href="/wiki/List_of_laser_articles" title="List of laser articles">List of laser articles</a></li>
<li><a href="/wiki/List_of_laser_types" title="List of laser types">List of laser types</a></li>
<li><a href="/wiki/List_of_laser_applications" title="List of laser applications">List of laser applications</a></li>
<li><a href="/wiki/Laser_acronyms" title="Laser acronyms">Laser acronyms</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Types of lasers</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Chemical_laser" title="Chemical laser">Chemical laser</a></li>
<li><a href="/wiki/Dye_laser" title="Dye laser">Dye laser</a>
<ul><li><a href="/wiki/Bubble_laser" title="Bubble laser">Bubble</a></li>
<li><a href="/wiki/Liquid-crystal_laser" title="Liquid-crystal laser">Liquid-crystal</a></li></ul></li>
<li><a href="/wiki/Gas_laser" title="Gas laser">Gas laser</a>
<ul><li><a href="/wiki/Carbon_dioxide_laser" class="mw-redirect" title="Carbon dioxide laser">Carbon dioxide</a></li>
<li><a href="/wiki/Excimer_laser" title="Excimer laser">Excimer</a></li>
<li><a href="/wiki/Helium%E2%80%93neon_laser" title="Helium–neon laser">Helium–neon</a></li>
<li><a href="/wiki/Ion_laser" title="Ion laser">Ion</a></li>
<li><a href="/wiki/Nitrogen_laser" title="Nitrogen laser">Nitrogen</a></li></ul></li>
<li><a href="/wiki/Free-electron_laser" title="Free-electron laser">Free-electron laser</a></li>
<li><a href="/wiki/Laser_diode" title="Laser diode">Laser diode</a></li>
<li><a href="/wiki/Solid-state_laser" title="Solid-state laser">Solid-state laser</a>
<ul><li><a href="/wiki/Er:YAG_laser" title="Er:YAG laser">Er:YAG</a></li>
<li><a href="/wiki/Nd:YAG_laser" title="Nd:YAG laser">Nd:YAG</a></li>
<li><a href="/wiki/Raman_laser" title="Raman laser">Raman</a></li>
<li><a href="/wiki/Ruby_laser" title="Ruby laser">Ruby</a></li>
<li><a href="/wiki/Ti-sapphire_laser" title="Ti-sapphire laser">Ti-sapphire</a></li></ul></li>
<li><a href="/wiki/X-ray_laser" title="X-ray laser">X-ray laser</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Laser_science" title="Laser science">Laser physics</a></th><td class="navbox-list-with-group navbox-list navbox-even" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Active_laser_medium" title="Active laser medium">Active laser medium</a></li>
<li><a href="/wiki/Amplified_spontaneous_emission" title="Amplified spontaneous emission">Amplified spontaneous emission</a></li>
<li><a href="/wiki/Continuous_wave" title="Continuous wave">Continuous wave</a></li>
<li><a href="/wiki/Laser_ablation" title="Laser ablation">Laser ablation</a></li>
<li><a href="/wiki/Laser_linewidth" title="Laser linewidth">Laser linewidth</a></li>
<li><a href="/wiki/Lasing_threshold" title="Lasing threshold">Lasing threshold</a></li>
<li><a href="/wiki/Population_inversion" title="Population inversion">Population inversion</a></li>
<li><a href="/wiki/Ultrashort_pulse_laser" title="Ultrashort pulse laser">Ultrashort pulse</a></li></ul>
</div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Laser optics</th><td class="navbox-list-with-group navbox-list navbox-odd" style="width:100%;padding:0"><div style="padding:0 0.25em">
<ul><li><a href="/wiki/Beam_expander" title="Beam expander">Beam expander</a></li>
<li><a href="/wiki/Beam_homogenizer" title="Beam homogenizer">Beam homogenizer</a></li>
<li><a href="/wiki/Chirped_pulse_amplification" title="Chirped pulse amplification">Chirped pulse amplification</a></li>
<li><a href="/wiki/Gain-switching" title="Gain-switching">Gain-switching</a></li>
<li><a href="/wiki/Gaussian_beam" title="Gaussian beam">Gaussian beam</a></li>
<li><a href="/wiki/Injection_seeder" title="Injection seeder">Injection seeder</a></li>
<li><a href="/wiki/Laser_beam_profiler" title="Laser beam profiler">Laser beam profiler</a></li>
<li><a href="/wiki/M_squared" title="M squared">M squared</a></li>
<li><a href="/wiki/Mode_locking" title="Mode locking">Mode locking</a></li>
<li><a href="/wiki/Multiple-prism_grating_laser_oscillator" title="Multiple-prism grating laser oscillator">Multiple-prism grating laser oscillator</a></li>
<li><a href="/wiki/Optical_amplifier" title="Optical amplifier">Optical amplifier</a></li>
<li><a href="/wiki/Optical_cavity" title="Optical cavity">Optical cavity</a></li>
<li><a href="/wiki/Optical_isolator" title="Optical isolator">Optical isolator</a></li>
<li><a href="/wiki/Output_coupler" title="Output coupler">Output coupler</a></li>
<li><a href="/wiki/Q-switching" title="Q-switching">Q-switching</a></li></ul>
</div></td></tr><tr><td class="navbox-abovebelow" colspan="2" style="font-weight: bold;"><div>
<ul><li><span class="noviewer" typeof="mw:File"><span title="Category"><img alt="" src="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png" decoding="async" width="16" height="16" class="mw-file-element" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x" data-file-width="180" data-file-height="185" /></span></span> <a href="/wiki/Category:Lasers" title="Category:Lasers">Category</a></li></ul>
</div></td></tr></tbody></table></div>
<!-- 
NewPP limit report
Parsed by mw‐web.codfw.main‐6b6f4c49c‐p7rbx
Cached time: 20240406192439
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.007 seconds
Real time usage: 1.196 seconds
Preprocessor visited node count: 5370/1000000
Post‐expand include size: 200464/2097152 bytes
Template argument size: 2387/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 373046/5000000 bytes
Lua time usage: 0.676/10.000 seconds
Lua memory usage: 8370723/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1000.184      1 -total
 67.15%  671.636      1 Template:Reflist
 19.88%  198.863     16 Template:Cite_book
 16.12%  161.201     26 Template:Cite_journal
 16.10%  161.074     39 Template:Cite_web
  8.23%   82.266      1 Template:Lasers
  7.97%   79.677      1 Template:Navbox
  7.53%   75.264      1 Template:Short_description
  4.67%   46.713      1 Template:Expand_section
  4.29%   42.949      2 Template:Pagetype
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:2714255-0!canonical and timestamp 20240406192439 and revision id 1217300576. Rendering was triggered because: page-view
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> --><noscript><img src="https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" width="1" height="1" style="border: none; position: absolute;"></noscript>
<div class="printfooter" data-nosnippet="">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=3D_scanning&amp;oldid=1217300576">https://en.wikipedia.org/w/index.php?title=3D_scanning&amp;oldid=1217300576</a>"</div></div>
					<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:3D_scanners" title="Category:3D scanners">3D scanners</a></li><li><a href="/wiki/Category:Geodesy" title="Category:Geodesy">Geodesy</a></li><li><a href="/wiki/Category:Surveying" title="Category:Surveying">Surveying</a></li><li><a href="/wiki/Category:Cartography" title="Category:Cartography">Cartography</a></li><li><a href="/wiki/Category:Measurement" title="Category:Measurement">Measurement</a></li><li><a href="/wiki/Category:Computer_vision" title="Category:Computer vision">Computer vision</a></li><li><a href="/wiki/Category:3D_graphics_software" title="Category:3D graphics software">3D graphics software</a></li><li><a href="/wiki/Category:3D_computer_graphics" title="Category:3D computer graphics">3D computer graphics</a></li><li><a href="/wiki/Category:3D_imaging" title="Category:3D imaging">3D imaging</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">CS1 maint: numeric names: authors list</a></li><li><a href="/wiki/Category:Webarchive_template_wayback_links" title="Category:Webarchive template wayback links">Webarchive template wayback links</a></li><li><a href="/wiki/Category:CS1_Spanish-language_sources_(es)" title="Category:CS1 Spanish-language sources (es)">CS1 Spanish-language sources (es)</a></li><li><a href="/wiki/Category:All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="/wiki/Category:Articles_with_dead_external_links_from_April_2023" title="Category:Articles with dead external links from April 2023">Articles with dead external links from April 2023</a></li><li><a href="/wiki/Category:Articles_with_permanently_dead_external_links" title="Category:Articles with permanently dead external links">Articles with permanently dead external links</a></li><li><a href="/wiki/Category:CS1_German-language_sources_(de)" title="Category:CS1 German-language sources (de)">CS1 German-language sources (de)</a></li><li><a href="/wiki/Category:CS1_Japanese-language_sources_(ja)" title="Category:CS1 Japanese-language sources (ja)">CS1 Japanese-language sources (ja)</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Short_description_is_different_from_Wikidata" title="Category:Short description is different from Wikidata">Short description is different from Wikidata</a></li><li><a href="/wiki/Category:Articles_to_be_expanded_from_March_2020" title="Category:Articles to be expanded from March 2020">Articles to be expanded from March 2020</a></li><li><a href="/wiki/Category:All_articles_to_be_expanded" title="Category:All articles to be expanded">All articles to be expanded</a></li><li><a href="/wiki/Category:Articles_using_small_message_boxes" title="Category:Articles using small message boxes">Articles using small message boxes</a></li><li><a href="/wiki/Category:All_articles_with_unsourced_statements" title="Category:All articles with unsourced statements">All articles with unsourced statements</a></li><li><a href="/wiki/Category:Articles_with_unsourced_statements_from_April_2019" title="Category:Articles with unsourced statements from April 2019">Articles with unsourced statements from April 2019</a></li><li><a href="/wiki/Category:Articles_containing_video_clips" title="Category:Articles containing video clips">Articles containing video clips</a></li></ul></div></div>
				</div>
			</main>
			
		</div>
		<div class="mw-footer-container">
			
<footer id="footer" class="mw-footer" role="contentinfo" >
	<ul id="footer-info">
	<li id="footer-info-lastmod"> This page was last edited on 5 April 2024, at 00:49<span class="anonymous-show">&#160;(UTC)</span>.</li>
	<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License">Creative Commons Attribution-ShareAlike License 4.0</a><a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License" style="display:none;"></a>;
additional terms may apply. By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
</ul>

	<ul id="footer-places">
	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy">Privacy policy</a></li>
	<li id="footer-places-about"><a href="/wiki/Wikipedia:About">About Wikipedia</a></li>
	<li id="footer-places-disclaimers"><a href="/wiki/Wikipedia:General_disclaimer">Disclaimers</a></li>
	<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
	<li id="footer-places-wm-codeofconduct"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct">Code of Conduct</a></li>
	<li id="footer-places-developers"><a href="https://developer.wikimedia.org">Developers</a></li>
	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement">Cookie statement</a></li>
	<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=3D_scanning&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
</ul>

	<ul id="footer-icons" class="noprint">
	<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy" /></a></li>
	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/footer/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"></a></li>
</ul>

</footer>

		</div>
	</div> 
</div> 
<div class="vector-settings" id="p-dock-bottom">
	<ul>
		<li>
		<button class="cdx-button cdx-button--icon-only vector-limited-width-toggle" id=""><span class="vector-icon mw-ui-icon-fullScreen mw-ui-icon-wikimedia-fullScreen"></span>

<span>Toggle limited content width</span>
</button>
</li>
	</ul>
</div>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgHostname":"mw-web.eqiad.main-7f5bb5b669-k7jrb","wgBackendResponseTime":198,"wgPageParseReport":{"limitreport":{"cputime":"1.007","walltime":"1.196","ppvisitednodes":{"value":5370,"limit":1000000},"postexpandincludesize":{"value":200464,"limit":2097152},"templateargumentsize":{"value":2387,"limit":2097152},"expansiondepth":{"value":17,"limit":100},"expensivefunctioncount":{"value":8,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":373046,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00% 1000.184      1 -total"," 67.15%  671.636      1 Template:Reflist"," 19.88%  198.863     16 Template:Cite_book"," 16.12%  161.201     26 Template:Cite_journal"," 16.10%  161.074     39 Template:Cite_web","  8.23%   82.266      1 Template:Lasers","  7.97%   79.677      1 Template:Navbox","  7.53%   75.264      1 Template:Short_description","  4.67%   46.713      1 Template:Expand_section","  4.29%   42.949      2 Template:Pagetype"]},"scribunto":{"limitreport-timeusage":{"value":"0.676","limit":"10.000"},"limitreport-memusage":{"value":8370723,"limit":52428800}},"cachereport":{"origin":"mw-web.codfw.main-6b6f4c49c-p7rbx","timestamp":"20240406192439","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"3D scanning","url":"https:\/\/en.wikipedia.org\/wiki\/3D_scanning","sameAs":"http:\/\/www.wikidata.org\/entity\/Q94701573","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q94701573","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2005-09-20T10:07:19Z","dateModified":"2024-04-05T00:49:09Z","image":"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/26\/VIUscan_handheld_3D_scanner_in_use.jpg","headline":"analyzing a real-world object or environment to collect data on its shape and possibly its appearance (e.g. colour)"}</script>
</body>
</html>